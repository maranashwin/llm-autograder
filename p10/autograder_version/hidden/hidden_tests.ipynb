{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b1b2de0",
   "metadata": {},
   "source": [
    "# Hidden Tests\n",
    "\n",
    "In this file, the hidden tests for all the rubric points are to be described. The tests for the individual rubric points are enclosed within `# BEGIN <rubric_point>` and `# END <rubric_point>` NBConvert cells. `hidden_tests.py` works by executing the contents of those cells between those two tags for each `<rubric_point>`. In order to initialize variables, `hidden_tests.py` also executes all code within `BEGIN` and `END` tags that appear before the `original` test.\n",
    "\n",
    "Code that is not enclosed within `BEGIN` and `END` tags are not executed by `hidden_tests.py`. They are used for generating the hidden datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e8dd714",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hidden_tests import *\n",
    "import otter_tests.gen_public_tests as gen_public_tests\n",
    "import os, csv, json, copy, shutil\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef81058a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRECTORY = '..'\n",
    "FILE = 'p10.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f614845",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4b15ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "deductions = {}\n",
    "rubric = parse_rubric_file(os.path.join(DIRECTORY, \"rubric.md\"))\n",
    "directories = get_directories(rubric)\n",
    "comments = get_all_comments(directories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efe76361",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_readme(data, write_path):\n",
    "    \"\"\"write_readme(data, write_path) writes the contents of `data` into the README.txt file `write_path`\"\"\"\n",
    "    f = open(write_path, encoding='utf-8')\n",
    "    rubric_point = f.read().split(\"\\n\")[0].strip(\" \\n\")\n",
    "    f.close()\n",
    "    \n",
    "    f = open(write_path, 'w', encoding='utf-8')\n",
    "    f.write(rubric_point + \"\\n\\n\" + data)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85f6dde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_copy(src, dst):\n",
    "    if os.path.exists(dst):\n",
    "        os.remove(dst)\n",
    "    shutil.copy(src, dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00eb6362",
   "metadata": {},
   "source": [
    "## Variables\n",
    "\n",
    "Useful variables that are used by many rubric tests can be stored here. The contents of this tag will be executed before each rubric test, so these variables get initialized before each rubric test."
   ]
  },
  {
   "cell_type": "raw",
   "id": "c9d7477c",
   "metadata": {},
   "source": [
    "# BEGIN variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86eafaee",
   "metadata": {},
   "source": [
    "`verify_fn_defn` defines the function `verify_fn` which is used for verifying if the function `expected` and `actual` have the same outputs for all permutations of inputs from `var_lists`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "475a0f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "verify_fn_defn = \"\"\"\n",
    "def verify_fn(expected, actual, var_inputs, test_format):\n",
    "    for var in var_inputs:\n",
    "        try:\n",
    "            actual_val = actual(*var)\n",
    "        except Exception as e:\n",
    "            output = \"%s results: \" % actual.__name__\n",
    "            output += \"%s error enountered on %s%s\" % (type(e).__name__, actual.__name__, repr(var))\n",
    "            return output\n",
    "        expected_val = expected(*var)\n",
    "        check = public_tests.compare(expected_val, actual_val, test_format)\n",
    "        if check != public_tests.PASS:\n",
    "            output = \"%s results: \" % actual.__name__\n",
    "            output += \"%s%s output: %s\" % (actual.__name__, repr(var), check)\n",
    "            return output\n",
    "    return \"%s results: All test cases passed!\" % actual.__name__\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f689911b",
   "metadata": {},
   "source": [
    "`function_dependencies_functions` stores the previously defined functions that each function definition invokes. This variable is used for rubric points that the logical correctness of functions as well as those that check whether a required function is used. For these rubric points, when we test a particular function, we use `function_dependencies_functions` to ensure that all the functions that it depends on are replaced with logically correct versions. This helps isolate the issue with the functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "307ebda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "function_dependencies_functions = {}\n",
    "function_dependencies_functions['star_cell'] = []\n",
    "function_dependencies_functions['get_stars'] = ['star_cell']\n",
    "function_dependencies_functions['planet_cell'] = []\n",
    "function_dependencies_functions['get_planets'] = ['planet_cell']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7153663c",
   "metadata": {},
   "source": [
    "`function_dependencies_data_structures` stores the previously defined data structures that each function definition invokes. This variable is used for rubric points that the logical correctness of functions as well as those that check whether a required function is used. For these rubric points, when we test a particular function, we use `function_dependencies_data_structures` to ensure that all the data structures that it depends on are replaced with logically correct versions. This helps isolate the issue with the functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "935aaa01",
   "metadata": {},
   "outputs": [],
   "source": [
    "function_dependencies_data_structures = {}\n",
    "function_dependencies_data_structures['star_cell'] = []\n",
    "function_dependencies_data_structures['get_stars'] = ['Star']\n",
    "function_dependencies_data_structures['planet_cell'] = []\n",
    "function_dependencies_data_structures['get_planets'] = ['Planet']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bed966",
   "metadata": {},
   "source": [
    "`data_structure_dependencies_functions` stores the previously defined functions that each data structure definition invokes. This variable is used for rubric points that the logical correctness of functions as well as those that check whether a required data structure is used. For these rubric points, when we test a particular data structure, we use `data_structure_dependencies_functions` to ensure that all the functions that it depends on are replaced with logically correct versions. This helps isolate the issue with the data structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e015b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_structure_dependencies_functions = {}\n",
    "data_structure_dependencies_functions['Star'] = []\n",
    "data_structure_dependencies_functions['stars_dict'] = ['star_cell', 'get_stars']\n",
    "data_structure_dependencies_functions['Planet'] = []\n",
    "data_structure_dependencies_functions['planets_list'] = ['planet_cell', 'get_planets']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61bdf98",
   "metadata": {},
   "source": [
    "`data_structure_dependencies_data_structures` stores the previously defined data structures that each data structure definition accesses. This variable is used for rubric points that the logical correctness of data structures as well as those that check whether a required data structure is used. For these rubric points, when we test a particular data structure, we use `data_structure_dependencies_data_structures` to ensure that all the data structures that it depends on are replaced with logically correct versions. This helps isolate the issue with the data structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3db1a4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_structure_dependencies_data_structures = {}\n",
    "data_structure_dependencies_data_structures['Star'] = []\n",
    "data_structure_dependencies_data_structures['stars_dict'] = ['Star']\n",
    "data_structure_dependencies_data_structures['Planet'] = []\n",
    "data_structure_dependencies_data_structures['planets_list'] = ['Planet'] "
   ]
  },
  {
   "cell_type": "raw",
   "id": "9fc84609",
   "metadata": {},
   "source": [
    "# END variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc9aa19",
   "metadata": {},
   "source": [
    "## Functions\n",
    "\n",
    "Useful functions that are used by many rubric tests can be stored here. The contents of this tag will be executed before each rubric test, so these function definitions get initialized before each rubric test."
   ]
  },
  {
   "cell_type": "raw",
   "id": "94d33069",
   "metadata": {},
   "source": [
    "# BEGIN functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdc1d3f",
   "metadata": {},
   "source": [
    "`replace_with_false_function` replaces the given `function` with the **false version** of the function, and also replaces all **dependent** functions and data structures with their **true versions**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a16ad9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_with_false_function(nb, function, false_function):\n",
    "    nb = replace_defn(nb, function, false_function)\n",
    "    \n",
    "    for dependent in function_dependencies_functions.get(function, []):\n",
    "        nb = replace_defn(nb, dependent, true_functions[dependent])\n",
    "    for dependent in function_dependencies_data_structures.get(function, []):\n",
    "        idx = find_all_cell_indices(nb, \"code\", \"grader.check('%s')\" % (dependent))[-1]\n",
    "        if idx == None:\n",
    "            idx = find_all_cell_indices(nb, \"markdown\", \"**Question 1:**\")[-1]\n",
    "        nb = inject_code(nb, idx, true_data_structures[dependent])\n",
    "        nb = remove_initializations(nb, dependent, start=idx+1)\n",
    "    return nb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6ae4bd",
   "metadata": {},
   "source": [
    "`replace_with_false_data_structure` replaces the given `data_structure` with the **false** version of the data structure, and also replaces all **dependent** functions and data structures with their **true versions**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc6f4937",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_with_false_data_structure(nb, data_structure, false_data_structure):\n",
    "    idx = find_all_cell_indices(nb, \"code\", \"grader.check('%s')\" % (data_structure))[-1]\n",
    "    if idx == None:\n",
    "        idx = find_all_cell_indices(nb, \"markdown\", \"**Question 1:**\")[-1]\n",
    "    nb = inject_code(nb, idx, false_data_structure)\n",
    "    nb = remove_initializations(nb, data_structure, start=idx+1)\n",
    "    \n",
    "    for dependent in data_structure_dependencies_functions.get(data_structure, []):\n",
    "        nb = replace_defn(nb, dependent, true_functions[dependent])\n",
    "    for dependent in data_structure_dependencies_data_structures.get(data_structure, []):\n",
    "        idx = find_all_cell_indices(nb, \"code\", \"grader.check('%s')\" % (dependent))[-1]\n",
    "        if idx == None:\n",
    "            idx = find_all_cell_indices(nb, \"markdown\", \"**Question 1:**\")[-1]\n",
    "        nb = inject_code(nb, idx, true_data_structures[dependent])\n",
    "        nb = remove_initializations(nb, dependent, start=idx+1)\n",
    "    return nb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b8aa45",
   "metadata": {},
   "source": [
    "`get_test_text` returns test code that can be readily injected into the notebook. The input should be some code that updates the variable `test_output` and sets its value to be `\"All test cases passed!\"` when the conditions for passing the rubric test are met. This function will place this code inside a wrapper than ensures that it does not crash the student notebook during execution and also makes the output parsable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b561fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_text(qnum, test_code):\n",
    "    test_text = \"\\\"\\\"\\\"grader.check('%s')\\\"\\\"\\\"\\n\\n\" % (qnum)\n",
    "    test_text += \"test_output = '%s results: Test crashed!'\\n\" % (qnum)\n",
    "    test_text += add_try_except(test_code)\n",
    "    test_text += \"\\nprint(test_output)\"\n",
    "    return test_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba932dd",
   "metadata": {},
   "source": [
    "`inject_function_logic_check` injects code into the `nb` that detects whether `function` outputs the same as the **true version** of that function (all dependent functions and data structures are also replaced with their **true versions**) on all combinations of inputs from `var_lists`. The comparison between the outputs is performed assuming that the format of the answers is `test_format`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0529145",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inject_function_logic_check(nb, function, var_inputs_code, test_format=\"TEXT_FORMAT\"):\n",
    "    for dependent in function_dependencies_functions.get(function, []):\n",
    "        nb = replace_defn(nb, dependent, true_functions[dependent])\n",
    "    for dependent in function_dependencies_data_structures.get(function, []):\n",
    "        idx = find_all_cell_indices(nb, \"code\", \"grader.check('%s')\" % (dependent))[-1]\n",
    "        if idx == None:\n",
    "            idx = find_all_cell_indices(nb, \"markdown\", \"**Question 1:**\")[-1]\n",
    "        nb = inject_code(nb, idx, true_data_structures[dependent])\n",
    "        nb = remove_initializations(nb, dependent, start=idx+1)\n",
    "        \n",
    "    code = replace_call(true_functions[function], function, \"true_\"+function)\n",
    "    code += \"\\n\\n\" + verify_fn_defn\n",
    "    nb = inject_code(nb, len(nb['cells']), code)\n",
    "    test_code = var_inputs_code + \"\\n\"\n",
    "    test_code += \"test_output = verify_fn(true_%s, %s, var_inputs, '%s')\" % (function, function, test_format)\n",
    "    code = get_test_text(function, test_code)\n",
    "    nb = inject_code(nb, len(nb['cells']), code)\n",
    "    return nb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc43cf8",
   "metadata": {},
   "source": [
    "`inject_data_structure_check` injects code into the `nb` that detects whether `data_structure` has the same value as the **true version** of that data structure (all dependent functions and data structures are also replaced with their **true versions**). The comparison between the outputs is performed assuming that the format of the answers is `test_format`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a17b0fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inject_data_structure_check(nb, data_structure, test_format=\"TEXT_FORMAT\"):\n",
    "    for dependent in data_structure_dependencies_functions.get(data_structure, []):\n",
    "        nb = replace_defn(nb, dependent, true_functions[dependent])\n",
    "    for dependent in data_structure_dependencies_data_structures.get(data_structure, []):\n",
    "        idx = find_all_cell_indices(nb, \"code\", \"grader.check('%s')\" % (dependent))[-1]\n",
    "        if idx == None:\n",
    "            idx = find_all_cell_indices(nb, \"markdown\", \"**Question 1:**\")[-1]\n",
    "        nb = inject_code(nb, idx, true_data_structures[dependent])\n",
    "        nb = remove_initializations(nb, dependent, start=idx+1)\n",
    "        \n",
    "    code = \"import copy\\n%s = copy.deepcopy(%s)\\n\\n\" % (data_structure, data_structure)\n",
    "    code += replace_variable(true_data_structures[data_structure], data_structure, \"true_\"+data_structure)\n",
    "    nb = inject_code(nb, len(nb['cells']), code)\n",
    "    \n",
    "    test_code = \"test_output = '%s results: '\" % (data_structure)\n",
    "    test_code += \"+ public_tests.compare(true_%s, %s, '%s')\" % (data_structure, data_structure, test_format)\n",
    "    code = get_test_text(data_structure, test_code)\n",
    "    nb = inject_code(nb, len(nb['cells']), code)\n",
    "    return nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "015d559f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_clean_nb(nb):\n",
    "    return replace_slashes(clean_nb(nb))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9952fe4c",
   "metadata": {},
   "source": [
    "# END functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95789537",
   "metadata": {},
   "source": [
    "## Random Data Generation\n",
    "\n",
    "Here, functions are defined that can generate **random** data that is in the correct format.\n",
    "\n",
    "**Warning:** This is the most complex function in the file, and is likely to have some bugs in it. So, **verify** this function **carefully**. The following **requirements** for this function **will not** be met by the function generated by GPT, it is **your responsibility** to modify the function so as to meet these requirements. Otherwise, the datasets are unlikely to produce interesting outputs for the project questions.\n",
    "\n",
    "* To the file `stars_1.csv`, a star named `DP Leo` must be added.\n",
    "* To one of the file `stars_1.csv`, ..., `stars_5.csv`, a star named `Kepler-220` must be added.\n",
    "* To each of the files `stars_1.csv`, ..., `stars_5.csv`, stars whose name starts with `Kepler` must be added.\n",
    "* To one of the files `planets_1.csv`, ..., `planets_4.csv`, a planet named `TOI-2202 c` must be added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3adf05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import csv\n",
    "import random\n",
    "import string\n",
    "from shutil import rmtree\n",
    "\n",
    "def random_data(directory, n=200, num_files=5):\n",
    "    \"\"\"\n",
    "    Generates random datasets inside the given directory.\n",
    "\n",
    "    :param directory: The path to the project directory.\n",
    "    :param n: The number of data rows to generate for each file. Default 100.\n",
    "    \"\"\"\n",
    "    # Helper functions\n",
    "    def normal_distribution_random(min_value, max_value, center, spread, lower_bound, upper_bound):\n",
    "        while True:\n",
    "            # Generate a random number with a normal distribution\n",
    "            num = random.normalvariate(center, spread)\n",
    "            # Check if number is within the expected 90% range\n",
    "            if lower_bound <= num <= upper_bound:\n",
    "                return num\n",
    "            # If not, regenerate limited to min and max\n",
    "            if min_value <= num <= max_value:\n",
    "                return num\n",
    "\n",
    "    # Create base directories if not there\n",
    "    data_dir = os.path.join(directory, 'data')\n",
    "\n",
    "    # Spectral types for use in random choice\n",
    "    spectral_letters = ['A', 'B', 'D', 'F', 'G', 'K', 'L', 'M', 'T', 'W']\n",
    "    spectral_numbers = [f'{float(num/4):g}' for num in range(0, 40)] + ['']*4\n",
    "    spectral_romans = ['', '', '', 'I', 'II', 'III', 'IV', 'V', 'VI']\n",
    "    spectral_types = [f\"{letter}{number}{roman}\" for letter in spectral_letters for number in spectral_numbers for roman in spectral_romans]\n",
    "    random.shuffle(spectral_types)\n",
    "    spectral_types = spectral_types[:(n*num_files)//2]\n",
    "\n",
    "    slash_types_1 = [f\"{type_1}/{type_2}\" for type_1 in spectral_types for type_2 in spectral_types]\n",
    "    random.shuffle(slash_types_1)\n",
    "    slash_types_1 = slash_types_1[:len(spectral_types)//8]\n",
    "\n",
    "    slash_types_2 = [f\"{type_1}/{roman}\" for type_1 in spectral_types for roman in spectral_romans]\n",
    "    random.shuffle(slash_types_2)\n",
    "    slash_types_2 = slash_types_2[:len(spectral_types)//8]\n",
    "\n",
    "    hyphen_types_1 = [f\"{type_1}-{type_2}\" for type_1 in spectral_types for type_2 in spectral_types]\n",
    "    random.shuffle(hyphen_types_1)\n",
    "    hyphen_types_1 = hyphen_types_1[:len(spectral_types)//8]\n",
    "\n",
    "    hyphen_types_2 = [f\"{type_1}-{roman}\" for type_1 in spectral_types for roman in spectral_romans]\n",
    "    random.shuffle(hyphen_types_2)\n",
    "    hyphen_types_2 = hyphen_types_2[:len(spectral_types)//8]\n",
    "\n",
    "    spectral_types.extend(slash_types_1)\n",
    "    spectral_types.extend(hyphen_types_1)\n",
    "    spectral_types.extend(slash_types_2)\n",
    "    spectral_types.extend(hyphen_types_2)\n",
    "    \n",
    "    # Discovery methods for use in random choice\n",
    "    discovery_methods = ['Astrometry', 'Disk Kinematics', 'Eclipse Timing Variations', 'Imaging', 'Microlensing',\n",
    "                         'Orbital Brightness Modulation', 'Pulsar Timing', 'Pulsation Timing Variations',\n",
    "                         'Radial Velocity', 'Transit', 'Transit Timing Variations']\n",
    "    \n",
    "    # Generate star and planet names\n",
    "    star_types = ['Kepler', 'TOI', '2MASS', 'HD', 'GJ', 'BD', 'CoRoT', 'EPIC', 'WASP', 'DP'] * 20\n",
    "    star_types.extend(['alf', 'bet', 'eps', 'gam', 'gam1', 'iot', 'kap', 'mu', 'mu2', 'nu', 'ome', 'omi', 'psi1', 'rho',\n",
    "                       'tau', 'ups', 'xi'])\n",
    "    star_numbers = list(range(1, 100))*1000\n",
    "    star_numbers.extend(list(range(1, 10000))*100)\n",
    "    star_numbers.extend(list(range(1, 100000)))\n",
    "    random.shuffle(star_numbers)\n",
    "    star_numbers = star_numbers[:(n*num_files)]\n",
    "    star_names = [f\"{star_type}{separator}{number}\" for star_type in star_types for separator in [\"-\", \" \"] for number in star_numbers]\n",
    "    random.shuffle(star_names)\n",
    "    star_names = list(set(star_names))[:n*num_files]\n",
    "    \n",
    "    star_names[random.randint(0, n-1)] = 'DP Leo'\n",
    "    if 'Kepler-220' in star_names:\n",
    "        star_names[star_names.index('Kepler-220')] = 'KMT-220'\n",
    "    star_names[random.randint(0, n*(num_files-1)-1)] = 'Kepler-220'\n",
    "    if 'TOI-2202' in star_names:\n",
    "        star_names[star_names.index('TOI-2202')] = 'KMT-2202'\n",
    "    star_names[random.randint(2*n+1, n*(num_files-1)-1)] = 'TOI-2202'\n",
    "\n",
    "\n",
    "    # CSV file headers\n",
    "    stars_header = [\n",
    "        \"Star Name\", \"Spectral Type\", \"Stellar Effective Temperature [K]\",\n",
    "        \"Stellar Radius [Solar Radius]\", \"Stellar Mass [Solar mass]\",\n",
    "        \"Stellar Luminosity [log(Solar)]\", \"Stellar Surface Gravity [log10(cm/s**2)]\",\n",
    "        \"Stellar Age [Gyr]\"\n",
    "    ]\n",
    "    planets_header = [\n",
    "        \"Planet Name\", \"Discovery Method\", \"Discovery Year\", \"Controversial Flag\", \n",
    "        \"Orbital Period [days]\", \"Planet Radius [Earth Radius]\", \"Planet Mass [Earth Mass]\",\n",
    "        \"Orbit Semi-Major Axis [au]\", \"Eccentricity\", \"Equilibrium Temperature [K]\",\n",
    "        \"Insolation Flux [Earth Flux]\"\n",
    "    ]\n",
    "\n",
    "    # Generate five sets of stars and planets data\n",
    "    for i in range(1, num_files+1):\n",
    "        planet_mappings = {}\n",
    "\n",
    "        stars_path = os.path.join(data_dir, f\"stars_{i}.csv\")\n",
    "        planets_path = os.path.join(data_dir, f\"planets_{i}.csv\")\n",
    "        mapping_path = os.path.join(data_dir, f\"mapping_{i}.json\")\n",
    "\n",
    "        with open(stars_path, mode='w', encoding='utf-8', newline='') as stars_file, \\\n",
    "             open(planets_path, mode='w', encoding='utf-8', newline='') as planets_file:\n",
    "\n",
    "            stars_writer = csv.DictWriter(stars_file, fieldnames=stars_header)\n",
    "            planets_writer = csv.DictWriter(planets_file, fieldnames=planets_header)\n",
    "\n",
    "            stars_writer.writeheader()\n",
    "            planets_writer.writeheader()\n",
    "\n",
    "            for j in range(n):\n",
    "                # Generate star data\n",
    "                star_name = star_names[(i-1)*n+j]\n",
    "                star_data = {\n",
    "                    \"Star Name\": star_name,\n",
    "                    \"Spectral Type\": random.choice(spectral_types),\n",
    "                    \"Stellar Effective Temperature [K]\": normal_distribution_random(\n",
    "                        415.0, 57000.0, 5257.5, 1568.5, 2500.0, 10000.0),\n",
    "                    \"Stellar Radius [Solar Radius]\": normal_distribution_random(\n",
    "                        0.01, 110.0, 25.075, 14.9625, 0.15, 50.0),\n",
    "                    \"Stellar Mass [Solar mass]\": normal_distribution_random(\n",
    "                        0.01, 11.0, 2.505, 1.4975, 0.01, 5.0),\n",
    "                    \"Stellar Luminosity [log(Solar)]\": normal_distribution_random(\n",
    "                        -6.1, 3.8, -0.2, 1.4, -2.2, 2.2),\n",
    "                    \"Stellar Surface Gravity [log10(cm/s**2)]\": normal_distribution_random(\n",
    "                        0.5, 8.0, 3.35, 1.775, 1.5, 5.2),\n",
    "                    \"Stellar Age [Gyr]\": normal_distribution_random(\n",
    "                        0.0, 14.9, 7.001, 4.1995, 0.002, 14.0),\n",
    "                }\n",
    "                stars_writer.writerow(star_data)\n",
    "\n",
    "                # Generate planet data, linking planets to the star\n",
    "                if random.randint(1, 2) == 1 or star_name == 'TOI-2202':\n",
    "                    planet_identifiers = list(string.ascii_lowercase)[:i]\n",
    "                else:\n",
    "                    planet_identifiers = [str(num) for num in range(1, 27)][:i]\n",
    "                planet_names = [f\"{star_name} {identifier}\" for identifier in planet_identifiers]\n",
    "                for planet_name in planet_names:\n",
    "                    planet_mappings[planet_name] = star_name\n",
    "                    planet_data = {\n",
    "                        \"Planet Name\": planet_name,\n",
    "                        \"Discovery Method\": random.choice(discovery_methods),\n",
    "                        \"Discovery Year\": int(normal_distribution_random(\n",
    "                            1992, 2023, 2019, 2.4, 2015, 2023)),\n",
    "                        \"Controversial Flag\": random.choices([0, 1], weights=[75, 25])[0],\n",
    "                        \"Orbital Period [days]\": normal_distribution_random(\n",
    "                            0.09, 402000000, 500.045, 289.9725, 0.09, 1000),\n",
    "                        \"Planet Radius [Earth Radius]\": normal_distribution_random(\n",
    "                            0.3, 77.0, 11.175, 6.4625, 0.35, 22.0),\n",
    "                        \"Planet Mass [Earth Mass]\": normal_distribution_random(\n",
    "                            0.02, 239000, 5001.0, 2843.5, 0.02, 10000),\n",
    "                        \"Orbit Semi-Major Axis [au]\": normal_distribution_random(\n",
    "                            0.0044, 7500.0, 100.0022, 60.00165, 0.01, 200.0),\n",
    "                        \"Eccentricity\": normal_distribution_random(\n",
    "                            0.0, 0.95, 0.05, 0.0285, 0.0, 0.1),\n",
    "                        \"Equilibrium Temperature [K]\": normal_distribution_random(\n",
    "                            35.0, 4500.0, 1100.0, 637.5, 200.0, 2000.0),\n",
    "                        \"Insolation Flux [Earth Flux]\": normal_distribution_random(\n",
    "                            0.0, 44900.0, 1100.1, 635.0, 0.2, 2000.0),\n",
    "                    }\n",
    "\n",
    "                    planets_writer.writerow(planet_data)\n",
    "\n",
    "        with open(mapping_path, 'w', encoding='utf-8') as mapping_file:\n",
    "            json.dump(planet_mappings, mapping_file)\n",
    "\n",
    "    # Delete contents of \"mapping_5.json\"\n",
    "    mapping_5_path = os.path.join(data_dir, \"mapping_5.json\")\n",
    "    with open(mapping_5_path, 'w', encoding='utf-8') as target:\n",
    "        target.write('}:{')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c26c761",
   "metadata": {},
   "source": [
    "## True Functions\n",
    "\n",
    "Here, the **correct** versions of all functions that are defined in the notebook are stored. These functions are compared against the functions in the student notebook to check for their correctness."
   ]
  },
  {
   "cell_type": "raw",
   "id": "73308546",
   "metadata": {},
   "source": [
    "# BEGIN true_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "01a3e683",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_functions = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3e26a526",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_functions['star_cell'] = \"\"\"\n",
    "import os\n",
    "import csv\n",
    "\n",
    "def process_csv(filename):\n",
    "    csv_file = open(filename, encoding='utf-8')\n",
    "    csv_reader = csv.reader(csv_file)\n",
    "    csv_data = list(csv_reader)\n",
    "    csv_file.close()\n",
    "    return csv_data\n",
    "    \n",
    "stars_1_csv = process_csv(os.path.join('data', 'stars_1.csv'))\n",
    "stars_header = stars_1_csv[0]\n",
    "stars_1_rows = stars_1_csv[1:]\n",
    "\n",
    "def star_cell(row_idx, col_name, stars_rows, header=stars_header):\n",
    "    col_idx = header.index(col_name)\n",
    "    val = stars_rows[row_idx][col_idx]\n",
    "    if val == '':\n",
    "        return None\n",
    "    elif col_name in ['Stellar Effective Temperature [K]', 'Stellar Radius [Solar Radius]', 'Stellar Mass [Solar mass]', 'Stellar Luminosity [log(Solar)]', 'Stellar Surface Gravity [log10(cm/s**2)]', 'Stellar Age [Gyr]']:\n",
    "        return float(val)\n",
    "    else:\n",
    "        return val\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "571480f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_functions['get_stars'] = \"\"\"\n",
    "import os\n",
    "import csv\n",
    "\n",
    "def process_csv(filename):\n",
    "    csv_file = open(filename, encoding='utf-8')\n",
    "    csv_reader = csv.reader(csv_file)\n",
    "    csv_data = list(csv_reader)\n",
    "    csv_file.close()\n",
    "    return csv_data\n",
    "\n",
    "def get_stars(star_file):\n",
    "    stars_data = process_csv(star_file)\n",
    "    stars_header = stars_data[0]\n",
    "    stars_rows = stars_data[1:]\n",
    "    stars = {}\n",
    "    for row_idx in range(len(stars_rows)):\n",
    "        star_name = star_cell(row_idx, 'Star Name', stars_rows)\n",
    "        spectral_type = star_cell(row_idx, 'Spectral Type', stars_rows)\n",
    "        stellar_effective_temperature = star_cell(row_idx, 'Stellar Effective Temperature [K]', stars_rows)\n",
    "        stellar_radius = star_cell(row_idx, 'Stellar Radius [Solar Radius]', stars_rows)\n",
    "        stellar_mass = star_cell(row_idx, 'Stellar Mass [Solar mass]', stars_rows)\n",
    "        stellar_luminosity = star_cell(row_idx, 'Stellar Luminosity [log(Solar)]', stars_rows)\n",
    "        stellar_surface_gravity = star_cell(row_idx, 'Stellar Surface Gravity [log10(cm/s**2)]', stars_rows)\n",
    "        stellar_age = star_cell(row_idx, 'Stellar Age [Gyr]', stars_rows)\n",
    "        star = Star(spectral_type, stellar_effective_temperature, stellar_radius, stellar_mass, stellar_luminosity, stellar_surface_gravity, stellar_age)\n",
    "        stars[star_name] = star\n",
    "    return stars\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ced2080d",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_functions['planet_cell'] = \"\"\"\n",
    "import os\n",
    "import csv\n",
    "\n",
    "def process_csv(filename):\n",
    "    csv_file = open(filename, encoding='utf-8')\n",
    "    csv_reader = csv.reader(csv_file)\n",
    "    csv_data = list(csv_reader)\n",
    "    csv_file.close()\n",
    "    return csv_data\n",
    "    \n",
    "planets_1_csv = process_csv(os.path.join('data', 'planets_1.csv'))\n",
    "planets_header = planets_1_csv[0]\n",
    "planets_1_rows = planets_1_csv[1:]\n",
    "\n",
    "def planet_cell(row_idx, col_name, planets_rows, header=planets_header):\n",
    "    col_idx = header.index(col_name)\n",
    "    val = planets_rows[row_idx][col_idx]\n",
    "    if val == '':\n",
    "        return None\n",
    "    if col_name in ['Controversial Flag']:\n",
    "        if val == '1':\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    elif col_name in ['Discovery Year']:\n",
    "        return int(val)\n",
    "    elif col_name in ['Orbital Period [days]', 'Planet Radius [Earth Radius]', 'Planet Mass [Earth Mass]', 'Orbit Semi-Major Axis [au]', 'Eccentricity', 'Equilibrium Temperature [K]', 'Insolation Flux [Earth Flux]']:\n",
    "        return float(val)\n",
    "    else:\n",
    "        return val\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1d53a029",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_functions['get_planets'] = \"\"\"\n",
    "import os\n",
    "import csv\n",
    "import json\n",
    "\n",
    "def process_csv(filename):\n",
    "    csv_file = open(filename, encoding='utf-8')\n",
    "    csv_reader = csv.reader(csv_file)\n",
    "    csv_data = list(csv_reader)\n",
    "    csv_file.close()\n",
    "    return csv_data\n",
    "\n",
    "def read_json(path):\n",
    "    with open(path, encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def get_planets(planet_file, mapping_file):\n",
    "    planets = []\n",
    "    try:\n",
    "        mapping_dict = read_json(mapping_file)\n",
    "    except json.JSONDecodeError:\n",
    "        return []\n",
    "    planets_csv = process_csv(planet_file)\n",
    "    planets_header = planets_csv[0]\n",
    "    planets_rows = planets_csv[1:]\n",
    "    for row_idx in range(len(planets_rows)):\n",
    "        try:\n",
    "            planet_name = planet_cell(row_idx, 'Planet Name', planets_rows)\n",
    "            host_name = mapping_dict[planet_name]\n",
    "            discovery_method = planet_cell(row_idx, 'Discovery Method', planets_rows)\n",
    "            discovery_year = planet_cell(row_idx, 'Discovery Year', planets_rows)\n",
    "            controversial_flag = planet_cell(row_idx, 'Controversial Flag', planets_rows)\n",
    "            orbital_period = planet_cell(row_idx, 'Orbital Period [days]', planets_rows)\n",
    "            planet_radius = planet_cell(row_idx, 'Planet Radius [Earth Radius]', planets_rows)\n",
    "            planet_mass = planet_cell(row_idx, 'Planet Mass [Earth Mass]', planets_rows)\n",
    "            semi_major_radius = planet_cell(row_idx, 'Orbit Semi-Major Axis [au]', planets_rows)\n",
    "            eccentricity = planet_cell(row_idx, 'Eccentricity', planets_rows)\n",
    "            equilibrium_temperature = planet_cell(row_idx, 'Equilibrium Temperature [K]', planets_rows)\n",
    "            insolation_flux = planet_cell(row_idx, 'Insolation Flux [Earth Flux]', planets_rows)\n",
    "            planet = Planet(planet_name, host_name, discovery_method, discovery_year, controversial_flag, orbital_period, planet_radius, planet_mass, semi_major_radius, eccentricity, equilibrium_temperature, insolation_flux)\n",
    "            planets.append(planet)\n",
    "        except IndexError:\n",
    "            continue\n",
    "        except ValueError:\n",
    "            continue\n",
    "        except KeyError:\n",
    "            continue\n",
    "    return planets\"\"\""
   ]
  },
  {
   "cell_type": "raw",
   "id": "d54f997c",
   "metadata": {},
   "source": [
    "# END true_functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a97473b",
   "metadata": {},
   "source": [
    "## True Data Structures\n",
    "\n",
    "Here, the **correct** versions of all data structures that are defined in the notebook are stored. These data structures are compared against the data structures in the student notebook to check for their correctness."
   ]
  },
  {
   "cell_type": "raw",
   "id": "315ad138",
   "metadata": {},
   "source": [
    "# BEGIN true_data_structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "418c04b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_data_structures = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c5849904",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_data_structures['Star'] = \"\"\"\n",
    "from collections import namedtuple\n",
    "star_attributes = ['spectral_type', 'stellar_effective_temperature', 'stellar_radius', 'stellar_mass', 'stellar_luminosity', 'stellar_surface_gravity', 'stellar_age']\n",
    "Star = namedtuple('Star', star_attributes)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d8cee215",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_data_structures['stars_dict'] = \"\"\"\n",
    "import os, csv\n",
    "\n",
    "def process_csv(filename):\n",
    "    csv_file = open(filename, encoding='utf-8')\n",
    "    csv_reader = csv.reader(csv_file)\n",
    "    csv_data = list(csv_reader)\n",
    "    csv_file.close()\n",
    "    return csv_data\n",
    "\n",
    "files_in_data = os.listdir(\"data\") \n",
    "files_in_data = [fname for fname in files_in_data if not fname.startswith(\".\")]\n",
    "files_in_data.sort(key = lambda path: path.split(os.path.sep), reverse = True) \n",
    "\n",
    "stars_paths = []\n",
    "for file in files_in_data:\n",
    "    if file.startswith('stars'):\n",
    "        stars_paths.append(os.path.join(\"data\", file))\n",
    "        \n",
    "stars_dict = {}\n",
    "for csv_file in stars_paths:\n",
    "    curr_stars_dict = get_stars(csv_file)\n",
    "    stars_dict.update(curr_stars_dict)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "07908217",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_data_structures['Planet'] = \"\"\"\n",
    "from collections import namedtuple\n",
    "planets_attributes = ['planet_name', 'host_name', 'discovery_method', 'discovery_year', 'controversial_flag', 'orbital_period', 'planet_radius', 'planet_mass', 'semi_major_radius', 'eccentricity', 'equilibrium_temperature', 'insolation_flux']\n",
    "Planet = namedtuple('Planet', planets_attributes)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "83be86c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_data_structures['planets_list'] = \"\"\"\n",
    "import os\n",
    "import csv\n",
    "import json\n",
    "\n",
    "def process_csv(filename):\n",
    "    csv_file = open(filename, encoding='utf-8')\n",
    "    csv_reader = csv.reader(csv_file)\n",
    "    csv_data = list(csv_reader)\n",
    "    csv_file.close()\n",
    "    return csv_data\n",
    "\n",
    "def read_json(path):\n",
    "    with open(path, encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "planets_list = []\n",
    "for i in range(1, 6):\n",
    "    planet_path = os.path.join('data', 'planets_%d.csv' % i)\n",
    "    mapping_path = os.path.join('data', 'mapping_%d.json' % i)\n",
    "    planets_list.extend(get_planets(planet_path, mapping_path))\n",
    "len(planets_list)\"\"\""
   ]
  },
  {
   "cell_type": "raw",
   "id": "341cf73a",
   "metadata": {},
   "source": [
    "# END true_data_structures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de10fb3",
   "metadata": {},
   "source": [
    "## Original\n",
    "\n",
    "The original test simply runs the student's notebook as it is (after removing cells with syntax errors, and performing other clean-up). This helps us detect if the student failed any public tests."
   ]
  },
  {
   "cell_type": "raw",
   "id": "fe9e4c61",
   "metadata": {},
   "source": [
    "# BEGIN original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "57c867a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "nb = new_clean_nb(read_nb(os.path.join(DIRECTORY, FILE)))\n",
    "\n",
    "results['original'] = parse_nb(run_nb(nb, os.path.join(DIRECTORY, \"hidden\", \"original\", FILE)))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ecb49232",
   "metadata": {},
   "source": [
    "# END original"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9eec99a",
   "metadata": {},
   "source": [
    "## Hardcode\n",
    "\n",
    "The hardcode tests run the student's notebook on different datasets. However, `public_tests.py` remains unchanged. So, if the answers are hardcoded in the student's notebook, we expect their code to still pass the public tests on all the different datasets. If their code fails any one of the different hardcode datasets, we take that to mean that the answer is not hardcoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dcdcd5a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 done!\n"
     ]
    }
   ],
   "source": [
    "for subdirectory in os.listdir(os.path.join(DIRECTORY, \"hidden\", \"hardcode\")):\n",
    "    path = os.path.join(DIRECTORY, \"hidden\", \"hardcode\", subdirectory)\n",
    "    good_dataset = False\n",
    "    while not good_dataset:\n",
    "        if os.path.exists(os.path.join(path, FILE)):\n",
    "            nb = new_clean_nb(read_nb(os.path.join(DIRECTORY, FILE)))\n",
    "        hardcode_results = parse_nb(run_nb(nb, os.path.join(path, FILE)))\n",
    "        good_dataset = True\n",
    "        for qnum in hardcode_results:\n",
    "            if qnum.startswith('q') and hardcode_results[qnum] == 'All test cases passed!':\n",
    "                print(qnum + ' failed!')\n",
    "                good_dataset = False\n",
    "                break\n",
    "        if not good_dataset:\n",
    "            random_data(path, num_files=6)\n",
    "    print(subdirectory + ' done!')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0dd5d60f",
   "metadata": {},
   "source": [
    "# BEGIN hardcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "142f91d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "for hardcode in os.listdir(os.path.join(DIRECTORY, \"hidden\", \"hardcode\")):\n",
    "    nb = clean_nb(read_nb(os.path.join(DIRECTORY, FILE)))\n",
    "    results['hardcode: ' + hardcode] = parse_nb(run_nb(nb, os.path.join(DIRECTORY, \"hidden\", \"hardcode\", hardcode, FILE)))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9b918781",
   "metadata": {},
   "source": [
    "# END hardcode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365419fe",
   "metadata": {},
   "source": [
    "## Rubric Tests\n",
    "\n",
    "The tests for the rubric points will be defined below. Only the code inside the tags will be executed by `hidden_tests.py`, so the code outside the tags are used for generating the hidden datasets in the first place."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a8738d",
   "metadata": {},
   "source": [
    "### Instructions for creating rubric tests:\n",
    "\n",
    "Functions inside `hidden_tests.py` can be used to modify the student notebook, before executing and parsing the outputs. It is recommended that before trying to create rubric tests, a user goes through all the functions inside `hidden_tests.py` first. Here is a list of commonly used functions that will be most useful:\n",
    "\n",
    "* **`read_nb`**: `read_nb(file)` **reads** a `file` in the `.ipynb` file format and returns a `nb`.\n",
    "* **`run_nb`**: `run_nb(nb, file)` **executes** `nb` at the location `file` and **writes** the contents back into `file`.\n",
    "* **`parse_nb`**: `parse_nb(nb)` read the contents of a student `nb` and **extracts** all graded questions and answers.\n",
    "* **`truncate_nb`**: `truncate_nb(nb, start, end)` takes in a `nb`, and returns a **sliced** notebook between the cells indexed `start` and `end`.\n",
    "* **`find_all_cell_indices`**: `find_all_cell_indices(nb, cell_type, marker)` returns **all** the indices in `nb` of cell type `cell_type` that **contains** the `marker` in its source.\n",
    "* **`inject_code`**: `inject_code(nb, idx, code)` creates a **new** code cell in `nb` **after** the index `idx` with `code` in it.\n",
    "* **`count_defns`**: `count_defns(nb, func_name)` **counts** the number of times `func_name` is defined in the `nb`.\n",
    "* **`replace_defn`**: `replace_defn(nb, func_name, new_defn)` **replaces** the definition of `func_name` in `nb` with `new_defn`.\n",
    "* **`replace_call`**: `replace_call(text, func_name, new_name)` **replaces** all **calls** and definition **names** to `func_name` with `new_name` in `text`.\n",
    "* **`find_code`**: `find_code(nb, target)` returns the **number** of times that the **text** `target` appears in a code cell in `nb`.\n",
    "* **`replace_code`**: `replace_code(nb, target, new_code, start, end)` **replaces** all instances of the **text** `target` in a code cell between the indices `start` and `end` with the **text** `new_code`.\n",
    "* **`add_try_except`**: `add_try_except(text)` adds a (bare) **try/except block** around any given block of code.\n",
    "* **`detect_restart_and_run_all`**: `detect_restart_and_run_all(nb)` flags if any **non-empty code cell** in `nb` is **not executed**.\n",
    "* **`detect_imports`**: `detect_imports(nb)` returns a list of **all** the **import** statements in the `nb`.\n",
    "* **`detect_ast_objects`**: `detect_ast_objects(nb, objects)` returns a dict of **all** cells in the `nb` with the **ast objects** `objects` in them.\n",
    "* **`get_first_plot`**: `get_first_plot(nb, image_file)` returns the first **image** found in the output of a code cell in `nb`, and also stores it in `image_file` for reference.\n",
    "* **`get_label_plot`**: `get_label_plot(plot, kind)` **crops** the `plot` and returns returns a plot containing just the **label** at the location indicated by `kind` - `\"left\"`, `\"right\"`, `\"top\"`, or `\"bottom\"`.\n",
    "* **`get_without_label_plot`**: `get_without_label_plot(plot, kind)` **crops** the `plot` and returns returns a plot containing everything **except** the **label** at the location indicated by `kind` - `\"left\"`, `\"right\"`, `\"top\"`, or `\"bottom\"`.\n",
    "* **`get_ticks_plot`**: `get_ticks_plot(plot, kind)` **crops** the `plot` and returns returns a plot containing just the **ticks** at the location indicated by `kind` - `\"left\"`, or `\"bottom\"`.\n",
    "* **`get_without_ticks_plot`**: `get_without_ticks_plot(plot, kind)` **crops** the `plot` and returns returns a plot containing everything **except** the **ticks** at the location indicated by `kind` - `\"left\"`, or `\"bottom\"`.\n",
    "* **`get_bounding_box_plot`**: `get_bounding_box_plot(plot)` **crops** the `plot` and returns returns a plot containing just the **bounding box** of the plot.\n",
    "* **`check_text_in_plot`**: `check_text_in_plot(plot, expected_text)` checks if the `expected_text` is in the `plot`, and returns both the **missing** and the **extra** text in the given `plot`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8822ea12",
   "metadata": {},
   "source": [
    "### q1: answer is not sorted explicitly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "425e4fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"update readme\"\"\"\n",
    "\n",
    "rubric_item = \"q1: answer is not sorted explicitly\"\n",
    "readme_text = \"\"\"This test checks if your solution\n",
    "correctly implements sorting. It ensures that the\n",
    "answer remains consistent even if the comparison\n",
    "behavior for strings is modified in a certain way.\n",
    "By adapting the sorting process of given elements,\n",
    "the test confirms that you explicitly\n",
    "sorted the list, rather than relying on a specific\n",
    "default behavior.\"\"\" \n",
    "\n",
    "write_readme(readme_text, os.path.join(directories[rubric_item], \"README.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ef307fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_data(directories[rubric_item], 50)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6d66339e",
   "metadata": {},
   "source": [
    "# BEGIN q1: answer is not sorted explicitly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f2e4455e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "rubric_item = \"q1: answer is not sorted explicitly\"\n",
    "nb = new_clean_nb(read_nb(os.path.join(DIRECTORY, FILE)))\n",
    "nb = truncate_nb(nb, end=find_all_cell_indices(nb, \"code\", \"grader.check('q1')\")[-1])\n",
    "\n",
    "sort_redefine = '''\n",
    "import os\n",
    "\n",
    "class newStr(str):\n",
    "    def __lt__(self, other):\n",
    "        if isinstance(other, newStr):\n",
    "            return self > str(other)\n",
    "        return str(self) < other\n",
    "    \n",
    "    def __le__(self, other):\n",
    "        if isinstance(other, newStr):\n",
    "            return self >= str(other)\n",
    "        return str(self) <= other\n",
    "        \n",
    "    def __eq__(self, other):\n",
    "        return str(self) == other\n",
    "\n",
    "    def __ne__(self, other):\n",
    "        return str(self) != other\n",
    "\n",
    "    def __gt__(self, other):\n",
    "        if isinstance(other, newStr):\n",
    "            return self < str(other)\n",
    "        return str(self) > other\n",
    "\n",
    "    def __ge__(self, other):\n",
    "        if isinstance(other, newStr):\n",
    "            return self <= str(other)\n",
    "        return str(self) >= other\n",
    "        \n",
    "    def split(self, sep=None, maxsplit=-1):\n",
    "        orig_split = str(self).split(sep, maxsplit)\n",
    "        return [newStr(item) for item in orig_split]\n",
    "\n",
    "def new_join(*paths):\n",
    "    return newStr(original_join(*paths))\n",
    "    \n",
    "def new_listdir(path):\n",
    "    return [newStr(p) for p in original_listdir(path)]\n",
    "    \n",
    "def new_basename(path):\n",
    "    return newStr(original_basename(path))\n",
    "    \n",
    "def new_dirname(path):\n",
    "    return newStr(original_dirname(path))\n",
    "\n",
    "original_join = os.path.join\n",
    "os.path.join = new_join\n",
    "\n",
    "original_listdir = os.listdir\n",
    "os.listdir = new_listdir\n",
    "\n",
    "original_basename = os.path.basename\n",
    "os.path.basename = new_basename\n",
    "\n",
    "original_dirname = os.path.dirname\n",
    "os.path.dirname = new_dirname\n",
    "'''\n",
    "\n",
    "nb = inject_code(nb, 0, sort_redefine)\n",
    "\n",
    "sort_restore = '''\n",
    "os.path.join = original_join\n",
    "os.listdir = original_listdir\n",
    "os.path.basename = original_basename\n",
    "os.path.dirname = original_dirname\n",
    "'''\n",
    "\n",
    "nb = inject_code(nb, len(nb['cells']), sort_restore)\n",
    "\n",
    "results[rubric_item] = parse_nb(run_nb(nb, os.path.join(directories[rubric_item], FILE)))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d4221a98",
   "metadata": {},
   "source": [
    "# END q1: answer is not sorted explicitly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e546cea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"update public_tests\"\"\"\n",
    "\n",
    "gen_public_tests.gen_public_tests(os.path.join(directories[rubric_item], FILE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9e8eca",
   "metadata": {},
   "source": [
    "### q1: answer does not remove all files and directories that start with `.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "30511691",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"update readme\"\"\"\n",
    "\n",
    "rubric_item = \"q1: answer does not remove all files and directories that start with `.`\"\n",
    "readme_text = \"\"\"This test verifies your ability to correctly list\n",
    "the names of files in the directory, excluding\n",
    "those that system typically generates and start\n",
    "with a \".\". The dataset is modified for this test.\n",
    "Some files beginning with a \".\" have been added to\n",
    "verify if your code can correctly ignore\n",
    "system-specific files while listing the actual\n",
    "dataset files.\"\"\" \n",
    "\n",
    "write_readme(readme_text, os.path.join(directories[rubric_item], \"README.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a28159b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_data(dir_path):\n",
    "    # generate 5 random files beginning with \".\"  \n",
    "    for i in range(5):\n",
    "        filename = \".\" + str(i) + \".txt\"\n",
    "        filepath = os.path.join(dir_path, \"data\", filename)\n",
    "            \n",
    "        with open(filepath, 'w') as f:\n",
    "            f.write('This is a secret file.')\n",
    "\n",
    "random_data(directories[rubric_item], 50)\n",
    "modify_data(directories[rubric_item])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cca03ea1",
   "metadata": {},
   "source": [
    "# BEGIN q1: answer does not remove all files and directories that start with `.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c606ac02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "rubric_item = \"q1: answer does not remove all files and directories that start with `.`\"\n",
    "nb = new_clean_nb(read_nb(os.path.join(DIRECTORY, FILE)))\n",
    "nb = truncate_nb(nb, end=find_all_cell_indices(nb, \"code\", \"grader.check('q1')\")[-1])\n",
    "\n",
    "results[rubric_item] = parse_nb(run_nb(nb, os.path.join(directories[rubric_item], FILE)))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8a1af318",
   "metadata": {},
   "source": [
    "# END q1: answer does not remove all files and directories that start with `.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "62ee1a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"update public_tests\"\"\"\n",
    "\n",
    "gen_public_tests.gen_public_tests(os.path.join(directories[rubric_item], FILE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd90075c",
   "metadata": {},
   "source": [
    "### q2: recomputed variable defined in Question 1, or the answer is not sorted explicitly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2068c074",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"update readme\"\"\"\n",
    "\n",
    "rubric_item = \"q2: recomputed variable defined in Question 1, or the answer is not sorted explicitly\"\n",
    "readme_text = \"\"\"This test verifies if your\n",
    "solution uses the pre-computed and preprocessed\n",
    "variable `files_in_data` from the previous\n",
    "question and doesn't recompute it in the process.\n",
    "It also checks if your answer is correctly sorted.\n",
    "To evaluate this, a piece of code is injected that\n",
    "modifies the `files_in_data` variable.\"\"\" \n",
    "\n",
    "write_readme(readme_text, os.path.join(directories[rubric_item], \"README.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "caaa32f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_data(directories[rubric_item], 50)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9ddf6abd",
   "metadata": {},
   "source": [
    "# BEGIN q2: recomputed variable defined in Question 1, or the answer is not sorted explicitly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "20d077f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "rubric_item = \"q2: recomputed variable defined in Question 1, or the answer is not sorted explicitly\"\n",
    "nb = new_clean_nb(read_nb(os.path.join(DIRECTORY, FILE)))\n",
    "nb = truncate_nb(nb, end=find_all_cell_indices(nb, \"code\", \"grader.check('q2')\")[-1])\n",
    "\n",
    "code = \"\"\"files_in_data = ['planets_1.csv', 'planets_2.csv', 'planets_3.csv', 'stars_1.csv', 'stars_2.csv', 'mapping_1.json', 'mapping_2.json', 'mapping_3.json','random_file.csv', 'random_file.json']\"\"\"\n",
    "nb = inject_code(nb, find_all_cell_indices(nb, \"markdown\", \"**Question 2:**\")[-1], code)\n",
    "\n",
    "sort_redefine = '''\n",
    "import os\n",
    "\n",
    "class newStr(str):\n",
    "    def __lt__(self, other):\n",
    "        if isinstance(other, newStr):\n",
    "            return self > str(other)\n",
    "        return str(self) < other\n",
    "    \n",
    "    def __le__(self, other):\n",
    "        if isinstance(other, newStr):\n",
    "            return self >= str(other)\n",
    "        return str(self) <= other\n",
    "        \n",
    "    def __eq__(self, other):\n",
    "        return str(self) == other\n",
    "\n",
    "    def __ne__(self, other):\n",
    "        return str(self) != other\n",
    "\n",
    "    def __gt__(self, other):\n",
    "        if isinstance(other, newStr):\n",
    "            return self < str(other)\n",
    "        return str(self) > other\n",
    "\n",
    "    def __ge__(self, other):\n",
    "        if isinstance(other, newStr):\n",
    "            return self <= str(other)\n",
    "        return str(self) >= other\n",
    "        \n",
    "    def split(self, sep=None, maxsplit=-1):\n",
    "        orig_split = str(self).split(sep, maxsplit)\n",
    "        return [newStr(item) for item in orig_split]\n",
    "\n",
    "def new_join(*paths):\n",
    "    return newStr(original_join(*paths))\n",
    "    \n",
    "def new_listdir(path):\n",
    "    return [newStr(p) for p in original_listdir(path)]\n",
    "    \n",
    "def new_basename(path):\n",
    "    return newStr(original_basename(path))\n",
    "    \n",
    "def new_dirname(path):\n",
    "    return newStr(original_dirname(path))\n",
    "\n",
    "original_join = os.path.join\n",
    "os.path.join = new_join\n",
    "\n",
    "original_listdir = os.listdir\n",
    "os.listdir = new_listdir\n",
    "\n",
    "original_basename = os.path.basename\n",
    "os.path.basename = new_basename\n",
    "\n",
    "original_dirname = os.path.dirname\n",
    "os.path.dirname = new_dirname\n",
    "'''\n",
    "\n",
    "nb = inject_code(nb, 0, sort_redefine)\n",
    "\n",
    "sort_restore = '''\n",
    "os.path.join = original_join\n",
    "os.listdir = original_listdir\n",
    "os.path.basename = original_basename\n",
    "os.path.dirname = original_dirname\n",
    "'''\n",
    "\n",
    "nb = inject_code(nb, len(nb['cells']), sort_restore)\n",
    "\n",
    "results[rubric_item] = parse_nb(run_nb(nb, os.path.join(directories[rubric_item], FILE)))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "129fd73e",
   "metadata": {},
   "source": [
    "# END q2: recomputed variable defined in Question 1, or the answer is not sorted explicitly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e4c69892",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"update public_tests\"\"\"\n",
    "\n",
    "gen_public_tests.gen_public_tests(os.path.join(directories[rubric_item], FILE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8798d60e",
   "metadata": {},
   "source": [
    "### q2: answer does not remove all files and directories that start with `.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9810a806",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"update readme\"\"\"\n",
    "\n",
    "rubric_item = \"q2: answer does not remove all files and directories that start with `.`\"\n",
    "readme_text = \"\"\"This test verifies your ability to correctly list\n",
    "the names of files in the directory, excluding\n",
    "those that system typically generates and start\n",
    "with a \".\". The dataset is modified for this test.\n",
    "Some files beginning with a \".\" have been added to\n",
    "verify if your code can correctly ignore\n",
    "system-specific files while listing the actual\n",
    "dataset files.\"\"\" \n",
    "\n",
    "write_readme(readme_text, os.path.join(directories[rubric_item], \"README.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d58aab2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_data(dir_path):\n",
    "    # generate 5 random files beginning with \".\"  \n",
    "    for i in range(5):\n",
    "        filename = \".\" + str(i) + \".txt\"\n",
    "        filepath = os.path.join(dir_path, \"data\", filename)\n",
    "            \n",
    "        with open(filepath, 'w') as f:\n",
    "            f.write('This is a secret file.')\n",
    "\n",
    "random_data(directories[rubric_item], 50)\n",
    "modify_data(directories[rubric_item])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "90e2c1b0",
   "metadata": {},
   "source": [
    "# BEGIN q2: answer does not remove all files and directories that start with `.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3471f506",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "rubric_item = \"q2: answer does not remove all files and directories that start with `.`\"\n",
    "nb = new_clean_nb(read_nb(os.path.join(DIRECTORY, FILE)))\n",
    "nb = truncate_nb(nb, end=find_all_cell_indices(nb, \"code\", \"grader.check('q2')\")[-1])\n",
    "\n",
    "results[rubric_item] = parse_nb(run_nb(nb, os.path.join(directories[rubric_item], FILE)))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "09c22dbb",
   "metadata": {},
   "source": [
    "# END q2: answer does not remove all files and directories that start with `.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "436ab21e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"update public_tests\"\"\"\n",
    "\n",
    "gen_public_tests.gen_public_tests(os.path.join(directories[rubric_item], FILE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75e1d87",
   "metadata": {},
   "source": [
    "### q2: paths are hardcoded using slashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6f066564",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"update readme\"\"\"\n",
    "\n",
    "rubric_item = \"q2: paths are hardcoded using slashes\"\n",
    "readme_text = \"\"\"The test is checking for the\n",
    "robustness of your code across different operating\n",
    "systems. If paths have been hardcoded using \"/\" or\n",
    "\"\\\\\\\\\", the code may fail on some systems. The code\n",
    "injection is carrying out alterations to evaluate\n",
    "whether your code can function correctly in\n",
    "different operating system environments.\n",
    "Therefore, ensure that you're using `os.path.join`\n",
    "instead of hardcoding slashes.\"\"\" \n",
    "\n",
    "write_readme(readme_text, os.path.join(directories[rubric_item], \"README.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0547729c",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_data(directories[rubric_item], 50)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9b8f5051",
   "metadata": {},
   "source": [
    "# BEGIN q2: paths are hardcoded using slashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1e232c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "rubric_item = \"q2: paths are hardcoded using slashes\"\n",
    "nb = new_clean_nb(read_nb(os.path.join(DIRECTORY, FILE)))\n",
    "nb = truncate_nb(nb, end=find_all_cell_indices(nb, \"code\", \"grader.check('q2')\")[-1])\n",
    "\n",
    "path_redefine = '''\n",
    "import os\n",
    "\n",
    "def new_join(*paths):\n",
    "    return '&'.join(paths)\n",
    "    \n",
    "def new_basename(path):\n",
    "    return path.split('&')[-1]\n",
    "    \n",
    "def new_dirname(path):\n",
    "    return '&'.join(path.split('&')[:-1])\n",
    "    \n",
    "def new_split(path):\n",
    "    return tuple(['&'.join(path.split('&')[:-1]), path.split('&')[-1]])'''\n",
    "\n",
    "nb = inject_code(nb, find_all_cell_indices(nb, \"markdown\", \"**Question 1:**\")[-1], path_redefine)\n",
    "nb = replace_code(nb, 'os.path.join', 'new_join')\n",
    "nb = replace_code(nb, 'os.path.basename', 'new_basename')\n",
    "nb = replace_code(nb, 'os.path.dirname', 'new_dirname')\n",
    "nb = replace_code(nb, 'os.path.split', 'new_split')\n",
    "nb = replace_code(nb, 'os.path.sep', \"'&'\")\n",
    "\n",
    "results[rubric_item] = parse_nb(run_nb(nb, os.path.join(directories[rubric_item], FILE)))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "07c7c5d9",
   "metadata": {},
   "source": [
    "# END q2: paths are hardcoded using slashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bd8dd835",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"update public_tests\"\"\"\n",
    "\n",
    "gen_public_tests.gen_public_tests(os.path.join(directories[rubric_item], FILE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478d4682",
   "metadata": {},
   "source": [
    "### q3: recomputed variable defined in Question 1 or Question 2, or the answer is not sorted explicitly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "70b48c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"update readme\"\"\"\n",
    "\n",
    "rubric_item = \"q3: recomputed variable defined in Question 1 or Question 2, or the answer is not sorted explicitly\"\n",
    "readme_text = \"\"\"This test verifies if your\n",
    "solution uses the pre-computed and preprocessed\n",
    "variable `files_in_data` from the previous\n",
    "question and doesn't recompute it in the process.\n",
    "It also checks if your answer is correctly sorted.\n",
    "To evaluate this, a piece of code is injected that\n",
    "modifies the `files_in_data` variable.\"\"\" \n",
    "\n",
    "write_readme(readme_text, os.path.join(directories[rubric_item], \"README.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "66427466",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_data(directories[rubric_item], 50)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "070cb340",
   "metadata": {},
   "source": [
    "# BEGIN q3: recomputed variable defined in Question 1 or Question 2, or the answer is not sorted explicitly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "13176836",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "rubric_item = \"q3: recomputed variable defined in Question 1 or Question 2, or the answer is not sorted explicitly\"\n",
    "nb = new_clean_nb(read_nb(os.path.join(DIRECTORY, FILE)))\n",
    "nb = truncate_nb(nb, end=find_all_cell_indices(nb, \"code\", \"grader.check('q3')\")[-1])\n",
    "\n",
    "code = \"\"\"files_in_data = ['planets_1.csv', 'planets_2.csv', 'planets_3.csv', 'stars_1.csv', 'stars_2.csv', 'mapping_1.json', 'mapping_2.json', 'mapping_3.json','random_file.csv', 'random_file.json']\"\"\"\n",
    "nb = inject_code(nb, find_all_cell_indices(nb, \"markdown\", \"**Question 2:**\")[-1], code)\n",
    "\n",
    "sort_redefine = '''\n",
    "import os\n",
    "\n",
    "class newStr(str):\n",
    "    def __lt__(self, other):\n",
    "        if isinstance(other, newStr):\n",
    "            return self > str(other)\n",
    "        return str(self) < other\n",
    "    \n",
    "    def __le__(self, other):\n",
    "        if isinstance(other, newStr):\n",
    "            return self >= str(other)\n",
    "        return str(self) <= other\n",
    "        \n",
    "    def __eq__(self, other):\n",
    "        return str(self) == other\n",
    "\n",
    "    def __ne__(self, other):\n",
    "        return str(self) != other\n",
    "\n",
    "    def __gt__(self, other):\n",
    "        if isinstance(other, newStr):\n",
    "            return self < str(other)\n",
    "        return str(self) > other\n",
    "\n",
    "    def __ge__(self, other):\n",
    "        if isinstance(other, newStr):\n",
    "            return self <= str(other)\n",
    "        return str(self) >= other\n",
    "        \n",
    "    def split(self, sep=None, maxsplit=-1):\n",
    "        orig_split = str(self).split(sep, maxsplit)\n",
    "        return [newStr(item) for item in orig_split]\n",
    "\n",
    "def new_join(*paths):\n",
    "    return newStr(original_join(*paths))\n",
    "    \n",
    "def new_listdir(path):\n",
    "    return [newStr(p) for p in original_listdir(path)]\n",
    "    \n",
    "def new_basename(path):\n",
    "    return newStr(original_basename(path))\n",
    "    \n",
    "def new_dirname(path):\n",
    "    return newStr(original_dirname(path))\n",
    "\n",
    "original_join = os.path.join\n",
    "os.path.join = new_join\n",
    "\n",
    "original_listdir = os.listdir\n",
    "os.listdir = new_listdir\n",
    "\n",
    "original_basename = os.path.basename\n",
    "os.path.basename = new_basename\n",
    "\n",
    "original_dirname = os.path.dirname\n",
    "os.path.dirname = new_dirname\n",
    "'''\n",
    "\n",
    "nb = inject_code(nb, 0, sort_redefine)\n",
    "\n",
    "sort_restore = '''\n",
    "os.path.join = original_join\n",
    "os.listdir = original_listdir\n",
    "os.path.basename = original_basename\n",
    "os.path.dirname = original_dirname\n",
    "'''\n",
    "\n",
    "nb = inject_code(nb, len(nb['cells']), sort_restore)\n",
    "\n",
    "results[rubric_item] = parse_nb(run_nb(nb, os.path.join(directories[rubric_item], FILE)))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "63496fd3",
   "metadata": {},
   "source": [
    "# END q3: recomputed variable defined in Question 1 or Question 2, or the answer is not sorted explicitly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a160ee28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"update public_tests\"\"\"\n",
    "\n",
    "gen_public_tests.gen_public_tests(os.path.join(directories[rubric_item], FILE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e55dbe8",
   "metadata": {},
   "source": [
    "### q3: answer does not remove all files and directories that start with `.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "09098f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"update readme\"\"\"\n",
    "\n",
    "rubric_item = \"q3: answer does not remove all files and directories that start with `.`\"\n",
    "readme_text = \"\"\"This test verifies your ability to correctly list\n",
    "the names of files in the directory, excluding\n",
    "those that system typically generates and start\n",
    "with a \".\". The dataset is modified for this test.\n",
    "Some files beginning with a \".\" have been added to\n",
    "verify if your code can correctly ignore\n",
    "system-specific files while listing the actual\n",
    "dataset files.\"\"\" \n",
    "\n",
    "write_readme(readme_text, os.path.join(directories[rubric_item], \"README.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "26b4fbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_data(dir_path):\n",
    "    # generate 5 random files beginning with \".\"  \n",
    "    for i in range(5):\n",
    "        filename = \".\" + str(i) + \".csv\"\n",
    "        filepath = os.path.join(dir_path, \"data\", filename)\n",
    "            \n",
    "        with open(filepath, 'w') as f:\n",
    "            f.write('This is a secret file.')\n",
    "\n",
    "random_data(directories[rubric_item], 50)\n",
    "modify_data(directories[rubric_item])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e9a0b447",
   "metadata": {},
   "source": [
    "# BEGIN q3: answer does not remove all files and directories that start with `.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "dcf048aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "rubric_item = \"q3: answer does not remove all files and directories that start with `.`\"\n",
    "nb = new_clean_nb(read_nb(os.path.join(DIRECTORY, FILE)))\n",
    "nb = truncate_nb(nb, end=find_all_cell_indices(nb, \"code\", \"grader.check('q3')\")[-1])\n",
    "\n",
    "results[rubric_item] = parse_nb(run_nb(nb, os.path.join(directories[rubric_item], FILE)))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b0bd0d7c",
   "metadata": {},
   "source": [
    "# END q3: answer does not remove all files and directories that start with `.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4f4eb2f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"update public_tests\"\"\"\n",
    "\n",
    "gen_public_tests.gen_public_tests(os.path.join(directories[rubric_item], FILE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dcce6ac",
   "metadata": {},
   "source": [
    "### q3: answer does not check only for files that end with `.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "275571ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"update readme\"\"\"\n",
    "\n",
    "rubric_item = \"q3: answer does not check only for files that end with `.csv`\"\n",
    "readme_text = \"\"\"In this test, we examined whether\n",
    "your code properly identifies only files that end\n",
    "with the \".csv\" extension as CSV files. To do so,\n",
    "we added additional files to the dataset with\n",
    "extension endings in \"csv\". Make sure you are\n",
    "checking not just for \"csv\" in the string, but\n",
    "specifically for \".csv\" at the end of the file's\n",
    "name.\"\"\" \n",
    "\n",
    "write_readme(readme_text, os.path.join(directories[rubric_item], \"README.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ac0b5ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faker\n",
    "def modify_data(dir_path):\n",
    "    fake = faker.Faker()\n",
    "\n",
    "    # Add some non-csv files that ends with \"csv\"\n",
    "    for i in range(6, 10):\n",
    "        # Write stars data\n",
    "        file_path = os.path.join(dir_path, \"data\", f\"stars_{i}.csvtxt\")\n",
    "        with open(file_path, \"w\", newline='', encoding='utf-8') as f:\n",
    "            f.write(fake.paragraph())\n",
    "\n",
    "        # Write planets data\n",
    "        file_path = os.path.join(dir_path, \"data\", f\"planets_{i}.txtcsv\")\n",
    "        with open(file_path, \"w\", newline='', encoding='utf-8') as f:\n",
    "            f.write(fake.paragraph())\n",
    "\n",
    "        # Write mapping data\n",
    "        file_path = os.path.join(dir_path, \"data\", f\"mapping_{i}.csvcsv\")\n",
    "        with open(file_path, \"w\", newline='', encoding='utf-8') as f:\n",
    "            f.write(fake.paragraph())\n",
    "            \n",
    "random_data(directories[rubric_item], 50)\n",
    "modify_data(directories[rubric_item])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3023e7a6",
   "metadata": {},
   "source": [
    "# BEGIN q3: answer does not check only for files that end with `.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "854d2385",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "rubric_item = \"q3: answer does not check only for files that end with `.csv`\"\n",
    "nb = new_clean_nb(read_nb(os.path.join(DIRECTORY, FILE)))\n",
    "nb = truncate_nb(nb, end=find_all_cell_indices(nb, \"code\", \"grader.check('q3')\")[-1])\n",
    "\n",
    "results[rubric_item] = parse_nb(run_nb(nb, os.path.join(directories[rubric_item], FILE)))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3899aefa",
   "metadata": {},
   "source": [
    "# END q3: answer does not check only for files that end with `.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b6407bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"update public_tests\"\"\"\n",
    "\n",
    "gen_public_tests.gen_public_tests(os.path.join(directories[rubric_item], FILE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eda4822",
   "metadata": {},
   "source": [
    "### q3: paths are hardcoded using slashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fc80d462",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"update readme\"\"\"\n",
    "\n",
    "rubric_item = \"q3: paths are hardcoded using slashes\"\n",
    "readme_text = \"\"\"The test is checking for the\n",
    "robustness of your code across different operating\n",
    "systems. If paths have been hardcoded using \"/\" or\n",
    "\"\\\\\\\\\", the code may fail on some systems. The code\n",
    "injection is carrying out alterations to evaluate\n",
    "whether your code can function correctly in\n",
    "different operating system environments.\n",
    "Therefore, ensure that you're using `os.path.join`\n",
    "instead of hardcoding slashes.\"\"\" \n",
    "\n",
    "write_readme(readme_text, os.path.join(directories[rubric_item], \"README.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "43fc03dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_data(directories[rubric_item], 50)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "26c6bad9",
   "metadata": {},
   "source": [
    "# BEGIN q3: paths are hardcoded using slashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a96c3ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "rubric_item = \"q3: paths are hardcoded using slashes\"\n",
    "nb = new_clean_nb(read_nb(os.path.join(DIRECTORY, FILE)))\n",
    "nb = truncate_nb(nb, end=find_all_cell_indices(nb, \"code\", \"grader.check('q3')\")[-1])\n",
    "\n",
    "path_redefine = '''\n",
    "import os\n",
    "\n",
    "def new_join(*paths):\n",
    "    return '&'.join(paths)\n",
    "    \n",
    "def new_basename(path):\n",
    "    return path.split('&')[-1]\n",
    "    \n",
    "def new_dirname(path):\n",
    "    return '&'.join(path.split('&')[:-1])\n",
    "    \n",
    "def new_split(path):\n",
    "    return tuple(['&'.join(path.split('&')[:-1]), path.split('&')[-1]])'''\n",
    "\n",
    "nb = inject_code(nb, find_all_cell_indices(nb, \"markdown\", \"**Question 1:**\")[-1], path_redefine)\n",
    "nb = replace_code(nb, 'os.path.join', 'new_join')\n",
    "nb = replace_code(nb, 'os.path.basename', 'new_basename')\n",
    "nb = replace_code(nb, 'os.path.dirname', 'new_dirname')\n",
    "nb = replace_code(nb, 'os.path.split', 'new_split')\n",
    "nb = replace_code(nb, 'os.path.sep', \"'&'\")\n",
    "\n",
    "results[rubric_item] = parse_nb(run_nb(nb, os.path.join(directories[rubric_item], FILE)))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d4213af8",
   "metadata": {},
   "source": [
    "# END q3: paths are hardcoded using slashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b766e9f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"update public_tests\"\"\"\n",
    "\n",
    "gen_public_tests.gen_public_tests(os.path.join(directories[rubric_item], FILE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a765bb6e",
   "metadata": {},
   "source": [
    "### q4: recomputed variable defined in Question 1 or Question 2, or the answer is not sorted explicitly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "822ea1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"update readme\"\"\"\n",
    "\n",
    "rubric_item = \"q4: recomputed variable defined in Question 1 or Question 2, or the answer is not sorted explicitly\"\n",
    "readme_text = \"\"\"This test verifies if your\n",
    "solution uses the pre-computed and preprocessed\n",
    "variable `files_in_data` from the previous\n",
    "question and doesn't recompute it in the process.\n",
    "It also checks if your answer is correctly sorted.\n",
    "To evaluate this, a piece of code is injected that\n",
    "modifies the `files_in_data` variable.\"\"\" \n",
    "\n",
    "write_readme(readme_text, os.path.join(directories[rubric_item], \"README.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cce4ddf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_data(directories[rubric_item], 50)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5f209970",
   "metadata": {},
   "source": [
    "# BEGIN q4: recomputed variable defined in Question 1 or Question 2, or the answer is not sorted explicitly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3e3cb2a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "rubric_item = \"q4: recomputed variable defined in Question 1 or Question 2, or the answer is not sorted explicitly\"\n",
    "nb = new_clean_nb(read_nb(os.path.join(DIRECTORY, FILE)))\n",
    "nb = truncate_nb(nb, end=find_all_cell_indices(nb, \"code\", \"grader.check('q4')\")[-1])\n",
    "\n",
    "code = \"\"\"files_in_data = ['planets_1.csv', 'planets_2.csv', 'planets_3.csv', 'stars_1.csv', 'stars_2.csv', 'mapping_1.json', 'mapping_2.json', 'mapping_3.json','random_file.csv', 'random_file.json']\"\"\"\n",
    "nb = inject_code(nb, find_all_cell_indices(nb, \"markdown\", \"**Question 2:**\")[-1], code)\n",
    "\n",
    "sort_redefine = '''\n",
    "import os\n",
    "\n",
    "class newStr(str):\n",
    "    def __lt__(self, other):\n",
    "        if isinstance(other, newStr):\n",
    "            return self > str(other)\n",
    "        return str(self) < other\n",
    "    \n",
    "    def __le__(self, other):\n",
    "        if isinstance(other, newStr):\n",
    "            return self >= str(other)\n",
    "        return str(self) <= other\n",
    "        \n",
    "    def __eq__(self, other):\n",
    "        return str(self) == other\n",
    "\n",
    "    def __ne__(self, other):\n",
    "        return str(self) != other\n",
    "\n",
    "    def __gt__(self, other):\n",
    "        if isinstance(other, newStr):\n",
    "            return self < str(other)\n",
    "        return str(self) > other\n",
    "\n",
    "    def __ge__(self, other):\n",
    "        if isinstance(other, newStr):\n",
    "            return self <= str(other)\n",
    "        return str(self) >= other\n",
    "        \n",
    "    def split(self, sep=None, maxsplit=-1):\n",
    "        orig_split = str(self).split(sep, maxsplit)\n",
    "        return [newStr(item) for item in orig_split]\n",
    "\n",
    "def new_join(*paths):\n",
    "    return newStr(os.path.join(*paths))\n",
    "    \n",
    "def new_listdir(path):\n",
    "    return [newStr(p) for p in os.listdir(path)]\n",
    "    \n",
    "def new_basename(path):\n",
    "    return newStr(os.path.basename(path))\n",
    "    \n",
    "def new_dirname(path):\n",
    "    return newStr(os.path.dirname(path))\n",
    "    \n",
    "def new_split(path):\n",
    "    return tuple([new_dirname(path), new_basename(path)])'''\n",
    "\n",
    "nb = replace_code(nb, 'os.path.join', 'new_join')\n",
    "nb = replace_code(nb, 'os.path.basename', 'new_basename')\n",
    "nb = replace_code(nb, 'os.path.dirname', 'new_dirname')\n",
    "nb = replace_code(nb, 'os.path.split', 'new_split')\n",
    "nb = replace_code(nb, 'os.path.sep', \"'&'\")\n",
    "nb = inject_code(nb, 0, sort_redefine)\n",
    "\n",
    "results[rubric_item] = parse_nb(run_nb(nb, os.path.join(directories[rubric_item], FILE)))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "46e89f5c",
   "metadata": {},
   "source": [
    "# END q4: recomputed variable defined in Question 1 or Question 2, or the answer is not sorted explicitly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "688d0182",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"update public_tests\"\"\"\n",
    "\n",
    "gen_public_tests.gen_public_tests(os.path.join(directories[rubric_item], FILE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3d6c26",
   "metadata": {},
   "source": [
    "### q4: answer does not remove all files and directories that start with `.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1acf7cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"update readme\"\"\"\n",
    "\n",
    "rubric_item = \"q4: answer does not remove all files and directories that start with `.`\"\n",
    "readme_text = \"\"\"This test verifies your ability to correctly list\n",
    "the names of files in the directory, excluding\n",
    "those that system typically generates and start\n",
    "with a \".\". The dataset is modified for this test.\n",
    "Some files beginning with a \".\" have been added to\n",
    "verify if your code can correctly ignore\n",
    "system-specific files while listing the actual\n",
    "dataset files.\"\"\" \n",
    "\n",
    "write_readme(readme_text, os.path.join(directories[rubric_item], \"README.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "798c9a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_data(dir_path):\n",
    "    # generate 5 random files beginning with \".\"  \n",
    "    for i in range(5):\n",
    "        filename = \".stars_\" + str(i) + \".csv\"\n",
    "        filepath = os.path.join(dir_path, \"data\", filename)\n",
    "            \n",
    "        with open(filepath, 'w') as f:\n",
    "            f.write('This is a secret file.')\n",
    "\n",
    "random_data(directories[rubric_item], 50)\n",
    "modify_data(directories[rubric_item])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "550e30ef",
   "metadata": {},
   "source": [
    "# BEGIN q4: answer does not remove all files and directories that start with `.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2143ce41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "rubric_item = \"q4: answer does not remove all files and directories that start with `.`\"\n",
    "nb = new_clean_nb(read_nb(os.path.join(DIRECTORY, FILE)))\n",
    "nb = truncate_nb(nb, end=find_all_cell_indices(nb, \"code\", \"grader.check('q4')\")[-1])\n",
    "\n",
    "results[rubric_item] = parse_nb(run_nb(nb, os.path.join(directories[rubric_item], FILE)))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "78f4d09b",
   "metadata": {},
   "source": [
    "# END q4: answer does not remove all files and directories that start with `.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f5507bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"update public_tests\"\"\"\n",
    "\n",
    "gen_public_tests.gen_public_tests(os.path.join(directories[rubric_item], FILE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f743a26c",
   "metadata": {},
   "source": [
    "### q4: answer does not check for only files that start with `stars`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "29834d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"update readme\"\"\"\n",
    "\n",
    "rubric_item = \"q4: answer does not check for only files that start with `stars`\"\n",
    "readme_text = \"\"\"This test examines whether your code correctly\n",
    "identifies and filters files starting with 'stars'\n",
    "in the 'data' directory. The dataset has been\n",
    "modified to include additional files which start\n",
    "with substrings of 'stars'. This modification aims\n",
    "to check whether your code is carefully\n",
    "distinguishing files whose names start\n",
    "specifically with 'stars', not merely a substring\n",
    "of it.\"\"\" \n",
    "\n",
    "write_readme(readme_text, os.path.join(directories[rubric_item], \"README.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0fa6acae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def modify_data(directory):\n",
    "    # add some files start with substrings of \"stars\"\n",
    "    file_names_with_substring = ['starlight.csv', 'starry night.csv', 'star_1.csv', 'all_stars.csv']\n",
    "    for filename in file_names_with_substring:\n",
    "        df = pd.DataFrame(np.random.randint(0, 100, size=(100, 4)), columns=list('ABCD'))\n",
    "        df.to_csv(os.path.join(directory, \"data\", filename), index=False, encoding='utf-8')\n",
    "\n",
    "random_data(directories[rubric_item], 50)\n",
    "modify_data(directories[rubric_item])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9b8a8836",
   "metadata": {},
   "source": [
    "# BEGIN q4: answer does not check for only files that start with `stars`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "782e7c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "rubric_item = \"q4: answer does not check for only files that start with `stars`\"\n",
    "nb = new_clean_nb(read_nb(os.path.join(DIRECTORY, FILE)))\n",
    "nb = truncate_nb(nb, end=find_all_cell_indices(nb, \"code\", \"grader.check('q4')\")[-1])\n",
    "\n",
    "results[rubric_item] = parse_nb(run_nb(nb, os.path.join(directories[rubric_item], FILE)))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a469db43",
   "metadata": {},
   "source": [
    "# END q4: answer does not check for only files that start with `stars`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bfb09e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"update public_tests\"\"\"\n",
    "\n",
    "gen_public_tests.gen_public_tests(os.path.join(directories[rubric_item], FILE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2900a7",
   "metadata": {},
   "source": [
    "### q4: paths are hardcoded using slashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b0635f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"update readme\"\"\"\n",
    "\n",
    "rubric_item = \"q4: paths are hardcoded using slashes\"\n",
    "readme_text = \"\"\"The test is checking for the\n",
    "robustness of your code across different operating\n",
    "systems. If paths have been hardcoded using \"/\" or\n",
    "\"\\\\\\\\\", the code may fail on some systems. The code\n",
    "injection is carrying out alterations to evaluate\n",
    "whether your code can function correctly in\n",
    "different operating system environments.\n",
    "Therefore, ensure that you're using `os.path.join`\n",
    "instead of hardcoding slashes.\"\"\" \n",
    "\n",
    "write_readme(readme_text, os.path.join(directories[rubric_item], \"README.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4ce16388",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_data(directories[rubric_item], 50)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9aded1b6",
   "metadata": {},
   "source": [
    "# BEGIN q4: paths are hardcoded using slashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e2f860de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "rubric_item = \"q4: paths are hardcoded using slashes\"\n",
    "nb = new_clean_nb(read_nb(os.path.join(DIRECTORY, FILE)))\n",
    "nb = truncate_nb(nb, end=find_all_cell_indices(nb, \"code\", \"grader.check('q4')\")[-1])\n",
    "\n",
    "path_redefine = '''\n",
    "import os\n",
    "\n",
    "def new_join(*paths):\n",
    "    return '&'.join(paths)\n",
    "    \n",
    "def new_basename(path):\n",
    "    return path.split('&')[-1]\n",
    "    \n",
    "def new_dirname(path):\n",
    "    return '&'.join(path.split('&')[:-1])\n",
    "    \n",
    "def new_split(path):\n",
    "    return tuple(['&'.join(path.split('&')[:-1]), path.split('&')[-1]])'''\n",
    "\n",
    "nb = inject_code(nb, find_all_cell_indices(nb, \"markdown\", \"**Question 1:**\")[-1], path_redefine)\n",
    "nb = replace_code(nb, 'os.path.join', 'new_join')\n",
    "nb = replace_code(nb, 'os.path.basename', 'new_basename')\n",
    "nb = replace_code(nb, 'os.path.dirname', 'new_dirname')\n",
    "nb = replace_code(nb, 'os.path.split', 'new_split')\n",
    "nb = replace_code(nb, 'os.path.sep', \"'&'\")\n",
    "\n",
    "results[rubric_item] = parse_nb(run_nb(nb, os.path.join(directories[rubric_item], FILE)))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "449f314d",
   "metadata": {},
   "source": [
    "# END q4: paths are hardcoded using slashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8a01c3c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"update public_tests\"\"\"\n",
    "\n",
    "gen_public_tests.gen_public_tests(os.path.join(directories[rubric_item], FILE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1fb1bd",
   "metadata": {},
   "source": [
    "### Star: data structure is defined more than once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "76aaa1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"update readme\"\"\"\n",
    "\n",
    "rubric_item = \"Star: data structure is defined more than once\"\n",
    "readme_text = \"\"\"This test is checking if you have defined your\n",
    "namedtuple class multiple times. Try to ensure you\n",
    "define your classes where you are asked to,\n",
    "and not inside functions, which could result in\n",
    "the class being redefined every time the function\n",
    "is called. This could lead to unnecessary\n",
    "performance issues and possible conflicts if\n",
    "definitions don't align.\"\"\" \n",
    "\n",
    "write_readme(readme_text, os.path.join(directories[rubric_item], \"README.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a6be16cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_data(directories[rubric_item], 50)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e5fc7f70",
   "metadata": {},
   "source": [
    "# BEGIN Star: data structure is defined more than once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b6ce3ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "rubric_item = \"Star: data structure is defined more than once\"\n",
    "nb = new_clean_nb(read_nb(os.path.join(DIRECTORY, FILE)))\n",
    "\n",
    "hidn_namedtuple_count = '''\n",
    "from collections import namedtuple\n",
    "\n",
    "old_namedtuple = namedtuple\n",
    "hidn_namedtuple_count = {}\n",
    "def namedtuple(name, attributes):\n",
    "    global hidn_namedtuple_count\n",
    "    if name not in hidn_namedtuple_count:\n",
    "        hidn_namedtuple_count[name] = 0\n",
    "    hidn_namedtuple_count[name] += 1\n",
    "    return old_namedtuple(name, attributes)'''\n",
    "\n",
    "nb = inject_code(nb, find_all_cell_indices(nb, \"markdown\", \"**Question 1:**\")[-1], hidn_namedtuple_count)\n",
    "\n",
    "code = \"\"\"\n",
    "if hidn_namedtuple_count['Star'] == 1:\n",
    "    test_output = \"Star results: All test cases passed!\"\n",
    "\"\"\"\n",
    "nb = inject_code(nb, len(nb['cells']), get_test_text('Star', code))\n",
    "\n",
    "results[rubric_item] = parse_nb(run_nb(nb, os.path.join(directories[rubric_item], FILE)))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b199acce",
   "metadata": {},
   "source": [
    "# END Star: data structure is defined more than once"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94875533",
   "metadata": {},
   "source": [
    "### Star: data structure is defined incorrectly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a4cb70f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"update readme\"\"\"\n",
    "\n",
    "rubric_item = \"Star: data structure is defined incorrectly\"\n",
    "readme_text = \"\"\"This test is attempting to\n",
    "ensure that you have defined your Star namedtuple\n",
    "correctly. It tries to create a new Star object\n",
    "using your definition. The successful creation of\n",
    "this object would confirm that the star object\n",
    "meets the necessary structure that will be used in\n",
    "the later parts of the project.\"\"\" \n",
    "\n",
    "write_readme(readme_text, os.path.join(directories[rubric_item], \"README.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8d1a18a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_data(directories[rubric_item], 50)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a5f26a23",
   "metadata": {},
   "source": [
    "# BEGIN Star: data structure is defined incorrectly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5de77e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "rubric_item = \"Star: data structure is defined incorrectly\"\n",
    "nb = new_clean_nb(read_nb(os.path.join(DIRECTORY, FILE)))\n",
    "nb = truncate_nb(nb, end=find_all_cell_indices(nb, \"code\", \"grader.check('Star')\")[-1])\n",
    "\n",
    "code = \"\"\"\n",
    "sun = None\n",
    "try:\n",
    "    sun = Star('G2 V', 5780.0, 1.0, 1.0, 0.0, 4.44, 4.6)\n",
    "except:\n",
    "    pass\"\"\"\n",
    "nb = inject_code(nb, find_all_cell_indices(nb, \"code\", \"grader.check('Star')\")[-1], code)\n",
    "\n",
    "results[rubric_item] = parse_nb(run_nb(nb, os.path.join(directories[rubric_item], FILE)))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3b7573c2",
   "metadata": {},
   "source": [
    "# END Star: data structure is defined incorrectly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e6d1b8e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"update public_tests\"\"\"\n",
    "\n",
    "gen_public_tests.gen_public_tests(os.path.join(directories[rubric_item], FILE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f6a348",
   "metadata": {},
   "source": [
    "### star_cell: function does not typecast values based on columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5f5d0e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"update readme\"\"\"\n",
    "\n",
    "rubric_item = \"star_cell: function does not typecast values based on columns\"\n",
    "readme_text = \"\"\"This test checks whether your function correctly\n",
    "preprocesses and typecasts values according to\n",
    "their corresponding column types. For example,\n",
    "numeric columns should return float values, and\n",
    "textual columns should return string values. This\n",
    "is checked by running your function on various\n",
    "columns and analyzing the data types of the\n",
    "returned values. The intention is to ensure your\n",
    "function effectively automates this process, thus\n",
    "reducing the need for additional manual\n",
    "typecasting.\"\"\" \n",
    "\n",
    "write_readme(readme_text, os.path.join(directories[rubric_item], \"README.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8737bbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_data(directories[rubric_item], 50)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3ad5cef8",
   "metadata": {},
   "source": [
    "# BEGIN star_cell: function does not typecast values based on columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9780709e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "rubric_item = \"star_cell: function does not typecast values based on columns\"\n",
    "nb = new_clean_nb(read_nb(os.path.join(DIRECTORY, FILE)))\n",
    "nb = truncate_nb(nb, end=find_all_cell_indices(nb, \"code\", \"grader.check('star_cell')\")[-1])\n",
    "\n",
    "var_inputs_code = \"\"\"\n",
    "var_inputs = []\n",
    "import os\n",
    "import csv\n",
    "def process_csv(filename):\n",
    "    csv_file = open(filename, encoding=\"utf-8\")\n",
    "    csv_reader = csv.reader(csv_file)\n",
    "    csv_data = list(csv_reader)\n",
    "    csv_file.close()\n",
    "    return csv_data\n",
    "\n",
    "_stars_rows = []\n",
    "for i in range(1, 3):\n",
    "    _stars_csv = process_csv(os.path.join(\"data\", \"stars_%d.csv\" % (i)))\n",
    "    _stars_rows.append(_stars_csv[1:])\n",
    "    _cols = _stars_csv[0]\n",
    "    \n",
    "for _col in _cols:\n",
    "    for _rows in _stars_rows:\n",
    "        var_inputs.append((0, _col, _rows))\n",
    "\"\"\"\n",
    "nb = inject_function_logic_check(nb, 'star_cell', var_inputs_code, 'TEXT_FORMAT')\n",
    "src = 'check = public_tests.compare(expected_val, actual_val, test_format)'\n",
    "trgt = 'check = public_tests.compare(type(expected_val), type(actual_val), test_format)'\n",
    "nb['cells'][-2]['source'] = nb['cells'][-2]['source'].replace(src, trgt)\n",
    "\n",
    "results[rubric_item] = parse_nb(run_nb(nb, os.path.join(directories[rubric_item], FILE)))\n",
    "test_output = results[rubric_item][rubric_item.split(\":\")[0]]\n",
    "if test_output != 'All test cases passed!':\n",
    "    comments[rubric_item] += '\\nFAILED TEST CASE: ' + test_output"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ef7a151e",
   "metadata": {},
   "source": [
    "# END star_cell: function does not typecast values based on columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aad7afc",
   "metadata": {},
   "source": [
    "### star_cell: column indices are hardcoded instead of using column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2fe560dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"update readme\"\"\"\n",
    "\n",
    "rubric_item = \"star_cell: column indices are hardcoded instead of using column names\"\n",
    "readme_text = \"\"\"This test checks if your function correctly uses\n",
    "column names to find the index, instead of relying\n",
    "on hardcoded indices. To do this, the columns in\n",
    "the datasets are shuffled around in various ways.\n",
    "If your function relies on hardcoded indices, this\n",
    "test can highlight that issue since the correct\n",
    "data will not be extracted due to the permutation\n",
    "of columns.\"\"\" \n",
    "\n",
    "write_readme(readme_text, os.path.join(directories[rubric_item], \"README.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "18a97065",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_data(directory):\n",
    "    col_order = None\n",
    "    for i in range(1, 6):\n",
    "        stars_df = pd.read_csv(os.path.join(directory, \"data\", 'stars_%d.csv' % (i)), encoding='utf-8')\n",
    "        if col_order == None:\n",
    "            col_order = list(np.random.permutation(stars_df.columns)) # come up with random permutation\n",
    "\n",
    "        # Randomly permute the order of the columns in the dataframe and save the dataframe\n",
    "        stars_df = stars_df[col_order]\n",
    "\n",
    "        stars_df.to_csv(os.path.join(directory, \"data\", 'stars_%d.csv' % (i)), index=False, encoding='utf-8')\n",
    "    \n",
    "random_data(directories[rubric_item], 50)\n",
    "modify_data(directories[rubric_item])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "21cfc64f",
   "metadata": {},
   "source": [
    "# BEGIN star_cell: column indices are hardcoded instead of using column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "78aff42f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "rubric_item = \"star_cell: column indices are hardcoded instead of using column names\"\n",
    "nb = new_clean_nb(read_nb(os.path.join(DIRECTORY, FILE)))\n",
    "nb = truncate_nb(nb, end=find_all_cell_indices(nb, \"code\", \"grader.check('star_cell')\")[-1])\n",
    "\n",
    "var_inputs_code = \"\"\"\n",
    "var_inputs = []\n",
    "import os\n",
    "import csv\n",
    "def process_csv(filename):\n",
    "    csv_file = open(filename, encoding=\"utf-8\")\n",
    "    csv_reader = csv.reader(csv_file)\n",
    "    csv_data = list(csv_reader)\n",
    "    csv_file.close()\n",
    "    return csv_data\n",
    "\n",
    "_stars_rows = []\n",
    "for i in range(1, 3):\n",
    "    _stars_csv = process_csv(os.path.join(\"data\", \"stars_%d.csv\" % (i)))\n",
    "    _stars_rows.append(_stars_csv[1:])\n",
    "    _cols = _stars_csv[0]\n",
    "    \n",
    "for _col in _cols:\n",
    "    for _rows in _stars_rows:\n",
    "        var_inputs.append((0, _col, _rows))\n",
    "\"\"\"\n",
    "nb = inject_function_logic_check(nb, 'star_cell', var_inputs_code, 'TEXT_FORMAT')\n",
    "\n",
    "results[rubric_item] = parse_nb(run_nb(nb, os.path.join(directories[rubric_item], FILE)))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "244757e5",
   "metadata": {},
   "source": [
    "# END star_cell: column indices are hardcoded instead of using column names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa68ad4",
   "metadata": {},
   "source": [
    "### star_cell: function logic is incorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "95a5a122",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"update readme\"\"\"\n",
    "\n",
    "rubric_item = \"star_cell: function logic is incorrect\"\n",
    "readme_text = \"\"\"The test is evaluating the\n",
    "'star_cell' function implementation which you have\n",
    "written. It specifically checks whether the\n",
    "function correctly extracts values from the list\n",
    "of lists 'stars_rows' given the row index and\n",
    "column name. The test will verify if the function\n",
    "accurately handles missing values and typecasts\n",
    "different values based on the column name. The\n",
    "test will run the function on a variety of\n",
    "possible inputs.\"\"\" \n",
    "\n",
    "write_readme(readme_text, os.path.join(directories[rubric_item], \"README.txt\"))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5b8a5c3a",
   "metadata": {},
   "source": [
    "# BEGIN star_cell: function logic is incorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "63009a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "rubric_item = \"star_cell: function logic is incorrect\"\n",
    "nb = new_clean_nb(read_nb(os.path.join(DIRECTORY, FILE)))\n",
    "nb = truncate_nb(nb, end=find_all_cell_indices(nb, \"code\", \"grader.check('star_cell')\")[-1])\n",
    "\n",
    "var_inputs_code = \"\"\"\n",
    "var_inputs = []\n",
    "import os\n",
    "import csv\n",
    "def process_csv(filename):\n",
    "    csv_file = open(filename, encoding=\"utf-8\")\n",
    "    csv_reader = csv.reader(csv_file)\n",
    "    csv_data = list(csv_reader)\n",
    "    csv_file.close()\n",
    "    return csv_data\n",
    "\n",
    "_stars_rows = []\n",
    "for i in range(1, 3):\n",
    "    _stars_csv = process_csv(os.path.join(\"data\", \"stars_%d.csv\" % (i)))\n",
    "    _stars_rows.append(_stars_csv[1:])\n",
    "    _cols = _stars_csv[0]\n",
    "    \n",
    "for _rows in _stars_rows:\n",
    "    for _col in _cols:\n",
    "        for _idx in range(len(_rows)):\n",
    "            var_inputs.append((_idx, _col, _rows))\n",
    "\"\"\"\n",
    "nb = inject_function_logic_check(nb, 'star_cell', var_inputs_code, 'TEXT_FORMAT')\n",
    "\n",
    "results[rubric_item] = parse_nb(run_nb(nb, os.path.join(directories[rubric_item], FILE)))\n",
    "test_output = results[rubric_item][rubric_item.split(\":\")[0]]\n",
    "if test_output != 'All test cases passed!':\n",
    "    comments[rubric_item] += '\\nFAILED TEST CASE: ' + test_output"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3ba60a44",
   "metadata": {},
   "source": [
    "# END star_cell: function logic is incorrect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0c00ae",
   "metadata": {},
   "source": [
    "### star_cell: function is defined more than once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4cf46104",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"update readme\"\"\"\n",
    "\n",
    "rubric_item = \"star_cell: function is defined more than once\"\n",
    "readme_text = \"\"\"This test is designed to ensure that your function\n",
    "'star_cell' is defined only once in your notebook.\n",
    "Having multiple definitions can lead to unexpected\n",
    "results if notebook cells are executed out of\n",
    "order. The test reads through your code and counts\n",
    "definitions of the function 'star_cell'. It may\n",
    "fail if more than one definition is found. Please\n",
    "ensure your function is defined only once.\"\"\" \n",
    "\n",
    "write_readme(readme_text, os.path.join(directories[rubric_item], \"README.txt\"))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e28db913",
   "metadata": {},
   "source": [
    "# BEGIN star_cell: function is defined more than once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0a2e0ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "rubric_item = \"star_cell: function is defined more than once\"\n",
    "nb = new_clean_nb(read_nb(os.path.join(DIRECTORY, FILE)))\n",
    "\n",
    "results[rubric_item] = {}\n",
    "if count_defns(nb, 'star_cell') != 1:\n",
    "    results[rubric_item][rubric_item.split(\":\")[0]] = \"function is defined more than once\"\n",
    "else:\n",
    "    results[rubric_item][rubric_item.split(\":\")[0]] = \"All test cases passed!\""
   ]
  },
  {
   "cell_type": "raw",
   "id": "247a7fc0",
   "metadata": {},
   "source": [
    "# END star_cell: function is defined more than once"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa76b415",
   "metadata": {},
   "source": [
    "### q5: `star_cell` function is not used to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d4afc29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"update readme\"\"\"\n",
    "\n",
    "rubric_item = \"q5: `star_cell` function is not used to answer\"\n",
    "readme_text = \"\"\"This test is checking if you are using the\n",
    "`star_cell` function to answer the question. A\n",
    "modification has been made to the `star_cell`\n",
    "function so that it reads from a different\n",
    "dataset. If your answer does not change\n",
    "accordingly, it suggests that you did not use the\n",
    "`star_cell` function. Remember to utilize the\n",
    "provided functions instead of reading the data\n",
    "directly from the csv again.\"\"\" \n",
    "\n",
    "write_readme(readme_text, os.path.join(directories[rubric_item], \"README.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "662cebfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_data(directories[rubric_item], 50)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d13af38a",
   "metadata": {},
   "source": [
    "# BEGIN q5: `star_cell` function is not used to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b1ad0c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "rubric_item = \"q5: `star_cell` function is not used to answer\"\n",
    "nb = new_clean_nb(read_nb(os.path.join(DIRECTORY, FILE)))\n",
    "nb = truncate_nb(nb, end=find_all_cell_indices(nb, \"code\", \"grader.check('q5')\")[-1])\n",
    "\n",
    "false_star_cell = \"\"\"\n",
    "import os\n",
    "import csv\n",
    "import copy\n",
    "import random\n",
    "\n",
    "def process_csv(filename):\n",
    "    csv_file = open(filename, encoding='utf-8')\n",
    "    csv_reader = csv.reader(csv_file)\n",
    "    csv_data = list(csv_reader)\n",
    "    csv_file.close()\n",
    "    return csv_data\n",
    "    \n",
    "stars_1_csv = process_csv(os.path.join('data', 'stars_1.csv'))\n",
    "stars_header = stars_1_csv[0]\n",
    "stars_1_rows = stars_1_csv[1:]\n",
    "\n",
    "def star_cell(row_idx, col_name, stars_rows, header=stars_header):\n",
    "    stars_rows = copy.deepcopy(stars_rows)\n",
    "    random.seed(0)\n",
    "    rows_in_cols = {}\n",
    "    for i in range(len(stars_rows[0])):\n",
    "        rows_in_cols[i] = []\n",
    "        for j in range(len(stars_rows)):\n",
    "            rows_in_cols[i].append(stars_rows[j][i])\n",
    "        random.shuffle(rows_in_cols[i])\n",
    "        \n",
    "    for j in range(len(stars_rows)):\n",
    "        for i in range(len(stars_rows[0])):\n",
    "            stars_rows[j][i] = rows_in_cols[i][j]\n",
    "    \n",
    "    col_idx = header.index(col_name)\n",
    "    val = stars_rows[row_idx][col_idx]\n",
    "    if val == '':\n",
    "        return None\n",
    "    elif col_name in ['Stellar Effective Temperature [K]', 'Stellar Radius [Solar Radius]', 'Stellar Mass [Solar mass]', 'Stellar Luminosity [log(Solar)]', 'Stellar Surface Gravity [log10(cm/s**2)]', 'Stellar Age [Gyr]']:\n",
    "        return float(val)\n",
    "    else:\n",
    "        return val\"\"\"\n",
    "\n",
    "nb = replace_with_false_function(nb, 'star_cell', false_star_cell)\n",
    "\n",
    "results[rubric_item] = parse_nb(run_nb(nb, os.path.join(directories[rubric_item], FILE)))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "81c5dd26",
   "metadata": {},
   "source": [
    "# END q5: `star_cell` function is not used to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f87d86e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"update public_tests\"\"\"\n",
    "\n",
    "gen_public_tests.gen_public_tests(os.path.join(directories[rubric_item], FILE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73cb709c",
   "metadata": {},
   "source": [
    "### q5: answer unnecessarily iterates over the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "80e70193",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"update readme\"\"\"\n",
    "\n",
    "rubric_item = \"q5: answer unnecessarily iterates over the entire dataset\"\n",
    "readme_text = \"\"\"The test is checking whether you are unnecessarily\n",
    "iterating over the entire dataset in order to\n",
    "extract the data for the third Star. Make sure you\n",
    "are only using the row index of the third star to\n",
    "extract its data, without iterating over all the\n",
    "rows. There is code injected that tracks how\n",
    "many times the `star_cell` function is called, so\n",
    "be careful to use the correct method for\n",
    "extracting the data.\"\"\" \n",
    "\n",
    "write_readme(readme_text, os.path.join(directories[rubric_item], \"README.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7b318b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_data(directories[rubric_item], 50)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "67e3e6e6",
   "metadata": {},
   "source": [
    "# BEGIN q5: answer unnecessarily iterates over the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f766d86f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "rubric_item = \"q5: answer unnecessarily iterates over the entire dataset\"\n",
    "nb = new_clean_nb(read_nb(os.path.join(DIRECTORY, FILE)))\n",
    "nb = truncate_nb(nb, end=find_all_cell_indices(nb, \"code\", \"grader.check('q5')\")[-1])\n",
    "\n",
    "false_star_cell = \"\"\"\n",
    "import os\n",
    "import csv\n",
    "\n",
    "def process_csv(filename):\n",
    "    csv_file = open(filename, encoding='utf-8')\n",
    "    csv_reader = csv.reader(csv_file)\n",
    "    csv_data = list(csv_reader)\n",
    "    csv_file.close()\n",
    "    return csv_data\n",
    "    \n",
    "stars_1_csv = process_csv(os.path.join(\"data\", \"stars_1.csv\"))\n",
    "stars_header = stars_1_csv[0]\n",
    "stars_1_rows = stars_1_csv[1:]\n",
    "\n",
    "hidden_count = 0\n",
    "\n",
    "def star_cell(row_idx, col_name, stars_rows, header=stars_header):\n",
    "    global hidden_count\n",
    "    hidden_count += 1\n",
    "    col_idx = header.index(col_name)\n",
    "    val = stars_rows[row_idx][col_idx]\n",
    "    if val == '':\n",
    "        return None\n",
    "    elif col_name in ['Stellar Effective Temperature [K]', 'Stellar Radius [Solar Radius]', 'Stellar Mass [Solar mass]', 'Stellar Luminosity [log(Solar)]', 'Stellar Surface Gravity [log10(cm/s**2)]', 'Stellar Age [Gyr]']:\n",
    "        return float(val)\n",
    "    else:\n",
    "        return val\"\"\"\n",
    "nb = replace_with_false_function(nb, 'star_cell', false_star_cell)\n",
    "\n",
    "nb = inject_code(nb, find_all_cell_indices(nb, \"markdown\", \"**Question 5:**\")[-1], 'hidden_count = 0')\n",
    "\n",
    "code = \"\"\"\n",
    "if hidden_count <= 2 + len(stars_header):\n",
    "    test_output = 'q5 results: All test cases passed!'\"\"\"\n",
    "nb = inject_code(nb, len(nb['cells']), get_test_text('q5', code))\n",
    "\n",
    "results[rubric_item] = parse_nb(run_nb(nb, os.path.join(directories[rubric_item], FILE)))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "45ace735",
   "metadata": {},
   "source": [
    "# END q5: answer unnecessarily iterates over the entire dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510cf019",
   "metadata": {},
   "source": [
    "### q5: paths are hardcoded using slashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "980d564c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"update readme\"\"\"\n",
    "\n",
    "rubric_item = \"q5: paths are hardcoded using slashes\"\n",
    "readme_text = \"\"\"The test is checking for the\n",
    "robustness of your code across different operating\n",
    "systems. If paths have been hardcoded using \"/\" or\n",
    "\"\\\\\\\\\", the code may fail on some systems. The code\n",
    "injection is carrying out alterations to evaluate\n",
    "whether your code can function correctly in\n",
    "different operating system environments.\n",
    "Therefore, ensure that you're using `os.path.join`\n",
    "instead of hardcoding slashes.\"\"\" \n",
    "\n",
    "write_readme(readme_text, os.path.join(directories[rubric_item], \"README.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8568b31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_data(directories[rubric_item], 50)\n",
    "for i in range(1, 6):\n",
    "    file_copy(os.path.join(directories[rubric_item], 'data', 'stars_%d.csv' % (i)), os.path.join(directories[rubric_item], 'data&stars_%d.csv' % (i)))\n",
    "    file_copy(os.path.join(directories[rubric_item], 'data', 'planets_%d.csv' % (i)), os.path.join(directories[rubric_item], 'data&planets_%d.csv' % (i)))\n",
    "    file_copy(os.path.join(directories[rubric_item], 'data', 'mapping_%d.json' % (i)), os.path.join(directories[rubric_item], 'data&mapping_%d.json' % (i)))\n",
    "random_data(directories[rubric_item], 50)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "702a795f",
   "metadata": {},
   "source": [
    "# BEGIN q5: paths are hardcoded using slashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c2656929",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "rubric_item = \"q5: paths are hardcoded using slashes\"\n",
    "nb = new_clean_nb(read_nb(os.path.join(DIRECTORY, FILE)))\n",
    "nb = truncate_nb(nb, end=find_all_cell_indices(nb, \"code\", \"grader.check('q5')\")[-1])\n",
    "\n",
    "path_redefine = '''\n",
    "import os\n",
    "\n",
    "def new_join(*paths):\n",
    "    return '&'.join(paths)\n",
    "    \n",
    "def new_basename(path):\n",
    "    return path.split('&')[-1]\n",
    "    \n",
    "def new_dirname(path):\n",
    "    return '&'.join(path.split('&')[:-1])\n",
    "    \n",
    "def new_split(path):\n",
    "    return tuple(['&'.join(path.split('&')[:-1]), path.split('&')[-1]])'''\n",
    "\n",
    "nb = inject_code(nb, find_all_cell_indices(nb, \"markdown\", \"**Question 1:**\")[-1], path_redefine)\n",
    "nb = replace_code(nb, 'os.path.join', 'new_join')\n",
    "nb = replace_code(nb, 'os.path.basename', 'new_basename')\n",
    "nb = replace_code(nb, 'os.path.dirname', 'new_dirname')\n",
    "nb = replace_code(nb, 'os.path.split', 'new_split')\n",
    "nb = replace_code(nb, 'os.path.sep', \"'&'\")\n",
    "\n",
    "results[rubric_item] = parse_nb(run_nb(nb, os.path.join(directories[rubric_item], FILE)))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b9a661e4",
   "metadata": {},
   "source": [
    "# END q5: paths are hardcoded using slashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "8790dac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"update public_tests\"\"\"\n",
    "\n",
    "gen_public_tests.gen_public_tests(os.path.join(directories[rubric_item], FILE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93305bcb",
   "metadata": {},
   "source": [
    "### get_stars: function logic is incorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "77531a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"update readme\"\"\"\n",
    "\n",
    "rubric_item = \"get_stars: function logic is incorrect\"\n",
    "readme_text = \"\"\"This test is checking if your `get_stars` function\n",
    "is implemented correctly. Your function should\n",
    "take a file path as input, read the data from the\n",
    "CSV file, and return a dictionary mapping the star\n",
    "name to a `Star` object containing all the details\n",
    "of the star. To test your function, it is being\n",
    "called with different inputs and the output is\n",
    "compared to the expected output. Make sure your\n",
    "function returns the correct dictionary for all\n",
    "possible inputs.\"\"\" \n",
    "\n",
    "write_readme(readme_text, os.path.join(directories[rubric_item], \"README.txt\"))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "de000ee6",
   "metadata": {},
   "source": [
    "# BEGIN get_stars: function logic is incorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8a42d1bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "rubric_item = \"get_stars: function logic is incorrect\"\n",
    "nb = new_clean_nb(read_nb(os.path.join(DIRECTORY, FILE)))\n",
    "nb = truncate_nb(nb, end=find_all_cell_indices(nb, \"code\", \"grader.check('get_stars')\")[-1])\n",
    " \n",
    "var_inputs_code = \"\"\"\n",
    "import os\n",
    "var_inputs = []\n",
    "for i in range(1, 6):\n",
    "    var_inputs.append((os.path.join('data', 'stars_%d.csv' % (i)),))\n",
    "\"\"\"\n",
    "nb = inject_function_logic_check(nb, 'get_stars', var_inputs_code, 'TEXT_FORMAT_DICT')\n",
    "\n",
    "results[rubric_item] = parse_nb(run_nb(nb, os.path.join(directories[rubric_item], FILE)))\n",
    "test_output = results[rubric_item][rubric_item.split(\":\")[0]]\n",
    "if test_output != 'All test cases passed!':\n",
    "    comments[rubric_item] += '\\nFAILED TEST CASE: ' + test_output"
   ]
  },
  {
   "cell_type": "raw",
   "id": "52425874",
   "metadata": {},
   "source": [
    "# END get_stars: function logic is incorrect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed890117",
   "metadata": {},
   "source": [
    "### get_stars: hardcoded the name of directory inside the function instead of passing it as a part of the input argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "ed7b5acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"update readme\"\"\"\n",
    "\n",
    "rubric_item = \"get_stars: hardcoded the name of directory inside the function instead of passing it as a part of the input argument\"\n",
    "readme_text = \"\"\"The test is checking if you have hardcoded the\n",
    "name of the directory in the `get_stars` function\n",
    "instead of passing it as a part of the input\n",
    "argument. The test injects code that calls the\n",
    "function on files that are not inside the `data`\n",
    "directory. If your function is not able to read\n",
    "these files correctly, it suggests that the\n",
    "directories may be hardcoded in your function.\n",
    "Make sure to pass the directory as a part of the\n",
    "input argument to make your function more\n",
    "flexible.\"\"\" \n",
    "\n",
    "write_readme(readme_text, os.path.join(directories[rubric_item], \"README.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b18b1b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(directories[rubric_item], 'false_data')):\n",
    "    shutil.rmtree(os.path.join(directories[rubric_item], 'false_data'))\n",
    "os.mkdir(os.path.join(directories[rubric_item], 'false_data'))\n",
    "file_copy(os.path.join(directories[rubric_item], 'data', 'stars_2.csv'), os.path.join(directories[rubric_item], 'false_data', 'stars_1.csv'))\n",
    "file_copy(os.path.join(directories[rubric_item], 'data', 'stars_1.csv'), os.path.join(directories[rubric_item], 'new_stars.csv'))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4c43f2e1",
   "metadata": {},
   "source": [
    "# BEGIN get_stars: hardcoded the name of directory inside the function instead of passing it as a part of the input argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "246ee8ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "rubric_item = \"get_stars: hardcoded the name of directory inside the function instead of passing it as a part of the input argument\"\n",
    "nb = new_clean_nb(read_nb(os.path.join(DIRECTORY, FILE)))\n",
    "nb = truncate_nb(nb, end=find_all_cell_indices(nb, \"code\", \"grader.check('get_stars')\")[-1])\n",
    "\n",
    "var_inputs_code = \"\"\"\n",
    "import os\n",
    "var_inputs = [(os.path.join('false_data', 'stars_1.csv'),), ('new_stars.csv',)]\n",
    "\"\"\"\n",
    "nb = inject_function_logic_check(nb, 'get_stars', var_inputs_code, 'TEXT_FORMAT_DICT')\n",
    "\n",
    "results[rubric_item] = parse_nb(run_nb(nb, os.path.join(directories[rubric_item], FILE)))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9abae627",
   "metadata": {},
   "source": [
    "# END get_stars: hardcoded the name of directory inside the function instead of passing it as a part of the input argument"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eccfdad",
   "metadata": {},
   "source": [
    "### get_stars: function is called more than twice with the same dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "f0b78707",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"update readme\"\"\"\n",
    "\n",
    "rubric_item = \"get_stars: function is called more than twice with the same dataset\"\n",
    "readme_text = \"\"\"You are tasked with writing a function that reads\n",
    "data from a CSV file and returns a dictionary\n",
    "mapping star names to their details. However, you\n",
    "need to make sure that you do not read the same\n",
    "file multiple times, as it is time-consuming.\n",
    "Instead, you should store the data in a variable\n",
    "after reading it once, and access the variable in\n",
    "future calls. Be aware that there may be injected\n",
    "code that tracks how many times each file is\n",
    "provided as input. Make sure your function is not\n",
    "called on any file more than twice.\"\"\" \n",
    "\n",
    "write_readme(readme_text, os.path.join(directories[rubric_item], \"README.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "ca59691b",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_data(directories[rubric_item], 50)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "37364bda",
   "metadata": {},
   "source": [
    "# BEGIN get_stars: function is called more than twice with the same dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "652cda54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "rubric_item = \"get_stars: function is called more than twice with the same dataset\"\n",
    "nb = new_clean_nb(read_nb(os.path.join(DIRECTORY, FILE)))\n",
    "\n",
    "false_get_stars = \"\"\"\n",
    "import os\n",
    "import csv\n",
    "\n",
    "def process_csv(filename):\n",
    "    csv_file = open(filename, encoding='utf-8')\n",
    "    csv_reader = csv.reader(csv_file)\n",
    "    csv_data = list(csv_reader)\n",
    "    csv_file.close()\n",
    "    return csv_data\n",
    "\n",
    "hidden_count = {}\n",
    "\n",
    "def get_stars(star_file):\n",
    "    global hidden_count\n",
    "    if os.path.basename(star_file) not in hidden_count:\n",
    "        hidden_count[os.path.basename(star_file)] = 0\n",
    "    hidden_count[os.path.basename(star_file)] += 1\n",
    "    if 'data' not in star_file:\n",
    "        star_file = os.path.join('data', star_file)\n",
    "    stars_data = process_csv(star_file)\n",
    "    stars_header = stars_data[0]\n",
    "    stars_rows = stars_data[1:]\n",
    "    stars = {}\n",
    "    for row_idx in range(len(stars_rows)):\n",
    "        star_name = star_cell(row_idx, 'Star Name', stars_rows)\n",
    "        spectral_type = star_cell(row_idx, 'Spectral Type', stars_rows)\n",
    "        stellar_effective_temperature = star_cell(row_idx, 'Stellar Effective Temperature [K]', stars_rows)\n",
    "        stellar_radius = star_cell(row_idx, 'Stellar Radius [Solar Radius]', stars_rows)\n",
    "        stellar_mass = star_cell(row_idx, 'Stellar Mass [Solar mass]', stars_rows)\n",
    "        stellar_luminosity = star_cell(row_idx, 'Stellar Luminosity [log(Solar)]', stars_rows)\n",
    "        stellar_surface_gravity = star_cell(row_idx, 'Stellar Surface Gravity [log10(cm/s**2)]', stars_rows)\n",
    "        stellar_age = star_cell(row_idx, 'Stellar Age [Gyr]', stars_rows)\n",
    "        star = Star(spectral_type, stellar_effective_temperature, stellar_radius, stellar_mass, stellar_luminosity, stellar_surface_gravity, stellar_age)\n",
    "        stars[star_name] = star\n",
    "    return stars\"\"\"\n",
    "nb = replace_with_false_function(nb, 'get_stars', false_get_stars)\n",
    "\n",
    "code = \"\"\"\n",
    "if len(hidden_count) > 0 and max(hidden_count.values()) <= 2:\n",
    "    test_output = 'get_stars results: All test cases passed!'\"\"\"\n",
    "nb = inject_code(nb, len(nb['cells']), get_test_text('get_stars', code))\n",
    "\n",
    "results[rubric_item] = parse_nb(run_nb(nb, os.path.join(directories[rubric_item], FILE)))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7948559a",
   "metadata": {},
   "source": [
    "# END get_stars: function is called more than twice with the same dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a769e83e",
   "metadata": {},
   "source": [
    "### get_stars: `star_cell` function is not used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "44badd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"update readme\"\"\"\n",
    "\n",
    "rubric_item = \"get_stars: `star_cell` function is not used\"\n",
    "readme_text = \"\"\"This test is checking if you are using the\n",
    "`star_cell` function to define this function. A\n",
    "modification has been made to the `star_cell`\n",
    "function so that it reads from a different\n",
    "dataset. If the output of this function does not change\n",
    "accordingly, it suggests that you did not use the\n",
    "`star_cell` function. Remember to utilize the\n",
    "provided functions instead of reading the data\n",
    "directly from the csv again.\"\"\" \n",
    "\n",
    "write_readme(readme_text, os.path.join(directories[rubric_item], \"README.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "929ed961",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_data(directories[rubric_item], 50)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a47de76a",
   "metadata": {},
   "source": [
    "# BEGIN get_stars: `star_cell` function is not used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "4d9ebeb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "rubric_item = \"get_stars: `star_cell` function is not used\"\n",
    "nb = new_clean_nb(read_nb(os.path.join(DIRECTORY, FILE)))\n",
    "nb = truncate_nb(nb, end=find_all_cell_indices(nb, \"code\", \"grader.check('get_stars')\")[-1])\n",
    "\n",
    "var_inputs_code = \"\"\"\n",
    "import os\n",
    "var_inputs = [(os.path.join('data', 'stars_1.csv'),)]\n",
    "\"\"\"\n",
    "nb = inject_function_logic_check(nb, 'get_stars', var_inputs_code, 'TEXT_FORMAT_DICT')\n",
    "\n",
    "false_star_cell = \"\"\"\n",
    "import os\n",
    "import csv\n",
    "import copy\n",
    "import random\n",
    "\n",
    "def process_csv(filename):\n",
    "    csv_file = open(filename, encoding='utf-8')\n",
    "    csv_reader = csv.reader(csv_file)\n",
    "    csv_data = list(csv_reader)\n",
    "    csv_file.close()\n",
    "    return csv_data\n",
    "    \n",
    "stars_1_csv = process_csv(os.path.join('data', 'stars_1.csv'))\n",
    "stars_header = stars_1_csv[0]\n",
    "stars_1_rows = stars_1_csv[1:]\n",
    "\n",
    "def star_cell(row_idx, col_name, stars_rows, header=stars_header):\n",
    "    stars_rows = copy.deepcopy(stars_rows)\n",
    "    random.seed(0)\n",
    "    rows_in_cols = {}\n",
    "    for i in range(len(stars_rows[0])):\n",
    "        rows_in_cols[i] = []\n",
    "        for j in range(len(stars_rows)):\n",
    "            rows_in_cols[i].append(stars_rows[j][i])\n",
    "        random.shuffle(rows_in_cols[i])\n",
    "        \n",
    "    for j in range(len(stars_rows)):\n",
    "        for i in range(len(stars_rows[0])):\n",
    "            stars_rows[j][i] = rows_in_cols[i][j]\n",
    "    \n",
    "    col_idx = header.index(col_name)\n",
    "    val = stars_rows[row_idx][col_idx]\n",
    "    if val == '':\n",
    "        return None\n",
    "    elif col_name in ['Stellar Effective Temperature [K]', 'Stellar Radius [Solar Radius]', 'Stellar Mass [Solar mass]', 'Stellar Luminosity [log(Solar)]', 'Stellar Surface Gravity [log10(cm/s**2)]', 'Stellar Age [Gyr]']:\n",
    "        return float(val)\n",
    "    else:\n",
    "        return val\"\"\"\n",
    "nb = replace_with_false_function(nb, 'star_cell', false_star_cell)\n",
    "\n",
    "results[rubric_item] = parse_nb(run_nb(nb, os.path.join(directories[rubric_item], FILE)))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b902b439",
   "metadata": {},
   "source": [
    "# END get_stars: `star_cell` function is not used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb3afcc",
   "metadata": {},
   "source": [
    "### get_stars: function is defined more than once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "f3e62b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"update readme\"\"\"\n",
    "\n",
    "rubric_item = \"get_stars: function is defined more than once\"\n",
    "readme_text = \"\"\"This test is designed to ensure that your function\n",
    "'get_stars' is defined only once in your notebook.\n",
    "Having multiple definitions can lead to unexpected\n",
    "results if notebook cells are executed out of\n",
    "order. The test reads through your code and counts\n",
    "definitions of the function 'get_stars'. It may\n",
    "fail if more than one definition is found. Please\n",
    "ensure your function is defined only once.\"\"\" \n",
    "\n",
    "write_readme(readme_text, os.path.join(directories[rubric_item], \"README.txt\"))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "47154cb7",
   "metadata": {},
   "source": [
    "# BEGIN get_stars: function is defined more than once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "f7aeb1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rubric_item = \"get_stars: function is defined more than once\"\n",
    "nb = new_clean_nb(read_nb(os.path.join(DIRECTORY, FILE)))\n",
    "\n",
    "results[rubric_item] = {}\n",
    "if count_defns(nb, 'get_stars') != 1:\n",
    "    results[rubric_item][rubric_item.split(\":\")[0]] = \"function is defined more than once\"\n",
    "else:\n",
    "    results[rubric_item][rubric_item.split(\":\")[0]] = \"All test cases passed!\""
   ]
  },
  {
   "cell_type": "raw",
   "id": "8af8430c",
   "metadata": {},
   "source": [
    "# END get_stars: function is defined more than once"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff587fd",
   "metadata": {},
   "source": [
    "### q6: `stars_1_dict` data structure is not used to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "5686fe07",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"update readme\"\"\"\n",
    "\n",
    "rubric_item = \"q6: `stars_1_dict` data structure is not used to answer\"\n",
    "readme_text = \"\"\"You need to access the `Star` object for the star\n",
    "named DP Leo in the `stars_1_dict` dictionary. The\n",
    "dictionary already contains all the data about the\n",
    "stars in `stars_1.csv`. Make sure to use the data\n",
    "from the `stars_1_dict` dictionary to answer the\n",
    "question. A modified version of the dictionary is\n",
    "provided right before the answer to this question.\n",
    "If your answer does not use this modified data\n",
    "structure, you may not have used the data\n",
    "correctly.\"\"\" \n",
    "\n",
    "write_readme(readme_text, os.path.join(directories[rubric_item], \"README.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "08194fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_data(directories[rubric_item], 50)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "70ea334a",
   "metadata": {},
   "source": [
    "# BEGIN q6: `stars_1_dict` data structure is not used to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "0bf084af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "rubric_item = \"q6: `stars_1_dict` data structure is not used to answer\"\n",
    "nb = new_clean_nb(read_nb(os.path.join(DIRECTORY, FILE)))\n",
    "nb = truncate_nb(nb, end=find_all_cell_indices(nb, \"code\", \"grader.check('q6')\")[-1])\n",
    "\n",
    "randomized_stars_1_dict = '''\n",
    "import os\n",
    "import random\n",
    "\n",
    "stars_1_dict = get_stars(os.path.join(\"data\", \"stars_1.csv\"))\n",
    "\n",
    "random.seed(0)\n",
    "stars_1_dict_keys = list(stars_1_dict.keys())\n",
    "stars_1_dict_values = list(stars_1_dict.values())\n",
    "random.shuffle(stars_1_dict_keys)\n",
    "random.shuffle(stars_1_dict_keys)\n",
    "\n",
    "stars_1_dict = {}\n",
    "for i in range(len(stars_1_dict_keys)):\n",
    "    stars_1_dict[stars_1_dict_keys[i]] = stars_1_dict_values[i]\n",
    "'''\n",
    "nb = replace_with_false_function(nb, 'get_stars', true_functions[\"get_stars\"])\n",
    "nb = inject_code(nb, find_all_cell_indices(nb, \"markdown\", \"**Question 6:**\")[-1], randomized_stars_1_dict)\n",
    "\n",
    "results[rubric_item] = parse_nb(run_nb(nb, os.path.join(directories[rubric_item], FILE)))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "54e26bb8",
   "metadata": {},
   "source": [
    "# END q6: `stars_1_dict` data structure is not used to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "09d19842",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"update public_tests\"\"\"\n",
    "\n",
    "gen_public_tests.gen_public_tests(os.path.join(directories[rubric_item], FILE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8e0456",
   "metadata": {},
   "source": [
    "### q6: paths are hardcoded using slashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "80d363ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"update readme\"\"\"\n",
    "\n",
    "rubric_item = \"q6: paths are hardcoded using slashes\"\n",
    "readme_text = \"\"\"The test is checking for the\n",
    "robustness of your code across different operating\n",
    "systems. If paths have been hardcoded using \"/\" or\n",
    "\"\\\\\\\\\", the code may fail on some systems. The code\n",
    "injection is carrying out alterations to evaluate\n",
    "whether your code can function correctly in\n",
    "different operating system environments.\n",
    "Therefore, ensure that you're using `os.path.join`\n",
    "instead of hardcoding slashes.\"\"\" \n",
    "\n",
    "write_readme(readme_text, os.path.join(directories[rubric_item], \"README.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "17f0a7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_data(directories[rubric_item], 50)\n",
    "for i in range(1, 6):\n",
    "    file_copy(os.path.join(directories[rubric_item], 'data', 'stars_%d.csv' % (i)), os.path.join(directories[rubric_item], 'data&stars_%d.csv' % (i)))\n",
    "    file_copy(os.path.join(directories[rubric_item], 'data', 'planets_%d.csv' % (i)), os.path.join(directories[rubric_item], 'data&planets_%d.csv' % (i)))\n",
    "    file_copy(os.path.join(directories[rubric_item], 'data', 'mapping_%d.json' % (i)), os.path.join(directories[rubric_item], 'data&mapping_%d.json' % (i)))\n",
    "random_data(directories[rubric_item], 50)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0c7c3c2b",
   "metadata": {},
   "source": [
    "# BEGIN q6: paths are hardcoded using slashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "cc40fdc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "rubric_item = \"q6: paths are hardcoded using slashes\"\n",
    "nb = new_clean_nb(read_nb(os.path.join(DIRECTORY, FILE)))\n",
    "nb = truncate_nb(nb, end=find_all_cell_indices(nb, \"code\", \"grader.check('q6')\")[-1])\n",
    "\n",
    "path_redefine = '''\n",
    "import os\n",
    "\n",
    "def new_join(*paths):\n",
    "    return '&'.join(paths)\n",
    "    \n",
    "def new_basename(path):\n",
    "    return path.split('&')[-1]\n",
    "    \n",
    "def new_dirname(path):\n",
    "    return '&'.join(path.split('&')[:-1])\n",
    "    \n",
    "def new_split(path):\n",
    "    return tuple(['&'.join(path.split('&')[:-1]), path.split('&')[-1]])'''\n",
    "\n",
    "nb = inject_code(nb, find_all_cell_indices(nb, \"markdown\", \"**Question 1:**\")[-1], path_redefine)\n",
    "nb = replace_code(nb, 'os.path.join', 'new_join')\n",
    "nb = replace_code(nb, 'os.path.basename', 'new_basename')\n",
    "nb = replace_code(nb, 'os.path.dirname', 'new_dirname')\n",
    "nb = replace_code(nb, 'os.path.split', 'new_split')\n",
    "nb = replace_code(nb, 'os.path.sep', \"'&'\")\n",
    "\n",
    "results[rubric_item] = parse_nb(run_nb(nb, os.path.join(directories[rubric_item], FILE)))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "99413806",
   "metadata": {},
   "source": [
    "# END q6: paths are hardcoded using slashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "bea676af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"update public_tests\"\"\"\n",
    "\n",
    "gen_public_tests.gen_public_tests(os.path.join(directories[rubric_item], FILE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113e1e97",
   "metadata": {},
   "source": [
    "### q7: incorrect logic is used to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "89392cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"update readme\"\"\"\n",
    "\n",
    "rubric_item = \"q7: incorrect logic is used to answer\"\n",
    "readme_text = \"\"\"The dataset is modified in a way that some stars\n",
    "have missing `stellar_luminosity` data, some have 0 as\n",
    "their `stellar_luminosity` value, and some have very high\n",
    "`stellar_luminosity` values. Your code needs to correctly\n",
    "skip stars with missing `stellar_luminosity` data and\n",
    "calculate the average `stellar_luminosity` of the\n",
    "remaining stars.\"\"\" \n",
    "\n",
    "write_readme(readme_text, os.path.join(directories[rubric_item], \"README.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "7b9f9f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_data(test_dir):\n",
    "    # Load the original dataset\n",
    "    original_path = os.path.join(test_dir, \"data\", 'stars_1.csv')\n",
    "    dataset = pd.read_csv(original_path, encoding='utf-8')\n",
    "    \n",
    "    # Modify the dataset by randomly adding missing stellar_luminosity values\n",
    "    num_stars = len(dataset)\n",
    "    num_missing = int(num_stars / 3)\n",
    "    missing_luminosity_indices = np.random.choice(range(num_stars), size=num_missing, replace=False)\n",
    "    dataset.loc[missing_luminosity_indices, 'Stellar Luminosity [log(Solar)]'] = None\n",
    "    \n",
    "    # Add zeros to some stellar_luminosity values\n",
    "    num_zeros = int(num_stars / 3)\n",
    "    zero_luminosity_indices = np.random.choice(range(num_stars), size=num_zeros, replace=False)\n",
    "    dataset.loc[zero_luminosity_indices, 'Stellar Luminosity [log(Solar)]'] = 0\n",
    "    \n",
    "    # Add high stellar_luminosity values to the remaining rows\n",
    "    dataset['Stellar Luminosity [log(Solar)]'] = np.where(dataset['Stellar Luminosity [log(Solar)]'] != None,\n",
    "                                             dataset['Stellar Luminosity [log(Solar)]'],\n",
    "                                             np.random.uniform(low=1e6, high=1e9))\n",
    "    \n",
    "    # Save the modified dataset\n",
    "    dataset.to_csv(original_path, index=False, encoding='utf-8')\n",
    "\n",
    "random_data(directories[rubric_item], 200)\n",
    "modify_data(directories[rubric_item])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7837c97d",
   "metadata": {},
   "source": [
    "# BEGIN q7: incorrect logic is used to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "1b26a086",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "rubric_item = \"q7: incorrect logic is used to answer\"\n",
    "nb = new_clean_nb(read_nb(os.path.join(DIRECTORY, FILE)))\n",
    "nb = truncate_nb(nb, end=find_all_cell_indices(nb, \"code\", \"grader.check('q7')\")[-1])\n",
    "\n",
    "results[rubric_item] = parse_nb(run_nb(nb, os.path.join(directories[rubric_item], FILE)))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e3ad6420",
   "metadata": {},
   "source": [
    "# END q7: incorrect logic is used to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "a82f341f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"update public_tests\"\"\"\n",
    "\n",
    "gen_public_tests.gen_public_tests(os.path.join(directories[rubric_item], FILE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ae2469",
   "metadata": {},
   "source": [
    "### q7: `stars_1_dict` data structure is not used to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "a25829a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"update readme\"\"\"\n",
    "\n",
    "rubric_item = \"q7: `stars_1_dict` data structure is not used to answer\"\n",
    "readme_text = \"\"\"You need to access the `Star` objects in the \n",
    "`stars_1_dict` dictionary. The dictionary already \n",
    "contains all the data about the stars in \n",
    "`stars_1.csv`. Make sure to use the data\n",
    "from the `stars_1_dict` dictionary to answer the\n",
    "question. A modified version of the dictionary is\n",
    "provided right before the answer to this question.\n",
    "If your answer does not use this modified data\n",
    "structure, you may not have used the data\n",
    "correctly.\"\"\" \n",
    "\n",
    "write_readme(readme_text, os.path.join(directories[rubric_item], \"README.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "13c21efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_data(directories[rubric_item], 50)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a33db790",
   "metadata": {},
   "source": [
    "# BEGIN q7: `stars_1_dict` data structure is not used to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "2bc317ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "rubric_item = \"q7: `stars_1_dict` data structure is not used to answer\"\n",
    "nb = new_clean_nb(read_nb(os.path.join(DIRECTORY, FILE)))\n",
    "nb = truncate_nb(nb, end=find_all_cell_indices(nb, \"code\", \"grader.check('q7')\")[-1])\n",
    "\n",
    "randomized_stars_1_dict = '''\n",
    "import os\n",
    "import random\n",
    "\n",
    "stars_1_dict = get_stars(os.path.join(\"data\", \"stars_1.csv\"))\n",
    "\n",
    "random.seed(0)\n",
    "stars_1_dict_keys = list(stars_1_dict.keys())\n",
    "stars_1_dict_values = list(stars_1_dict.values())\n",
    "random.shuffle(stars_1_dict_keys)\n",
    "random.shuffle(stars_1_dict_values)\n",
    "\n",
    "stars_1_dict = {}\n",
    "for i in range(len(stars_1_dict_keys)):\n",
    "    stars_1_dict[stars_1_dict_keys[i]] = stars_1_dict_values[i]\n",
    "'''\n",
    "nb = replace_with_false_function(nb, 'get_stars', true_functions[\"get_stars\"])\n",
    "nb = inject_code(nb, find_all_cell_indices(nb, \"markdown\", \"**Question 7:**\")[-1], randomized_stars_1_dict)\n",
    "\n",
    "results[rubric_item] = parse_nb(run_nb(nb, os.path.join(directories[rubric_item], FILE)))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "647693b0",
   "metadata": {},
   "source": [
    "# END q7: `stars_1_dict` data structure is not used to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "6033f3ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"update public_tests\"\"\"\n",
    "\n",
    "gen_public_tests.gen_public_tests(os.path.join(directories[rubric_item], FILE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648c2664",
   "metadata": {},
   "source": [
    "### q8: incorrect logic is used to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "833b16e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"update readme\"\"\"\n",
    "\n",
    "rubric_item = \"q8: incorrect logic is used to answer\"\n",
    "readme_text = \"\"\"The dataset is modified in a way that some stars\n",
    "have missing `stellar_age` data, some have 0 as\n",
    "their `stellar_age` value, and some have very high\n",
    "`stellar_age` values. Your code needs to correctly\n",
    "skip stars with missing `stellar_age` data and\n",
    "calculate the average `stellar_age` of the\n",
    "remaining stars.\"\"\" \n",
    "\n",
    "write_readme(readme_text, os.path.join(directories[rubric_item], \"README.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "d2a75b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_data(directory):    \n",
    "    # Path of the original dataset file\n",
    "    original_dataset_path = os.path.join(directory, \"data\", \"stars_2.csv\")\n",
    "    \n",
    "    # Read the original dataset\n",
    "    df = pd.read_csv(original_dataset_path, encoding='utf-8')\n",
    "    \n",
    "    # Modify the dataset by setting nearly a third of stellar_age values as missing\n",
    "    num_rows = len(df)\n",
    "    num_missing = int(num_rows / 3)\n",
    "    missing_indices = np.random.choice(num_rows, num_missing, replace=False)\n",
    "    df.loc[missing_indices, 'Stellar Age [Gyr]'] = np.nan\n",
    "    \n",
    "    # Set another third of stellar_age values as 0\n",
    "    num_zero = int(num_rows / 3)\n",
    "    zero_indices = np.random.choice(num_rows, num_zero, replace=False)\n",
    "    df.loc[zero_indices, 'Stellar Age [Gyr]'] = 0\n",
    "    \n",
    "    # Set the remaining rows with very high stellar_age values\n",
    "    high_indices = ~np.isin(np.arange(num_rows), np.concatenate((missing_indices, zero_indices)))\n",
    "    max_stellar_age = 10**9\n",
    "    df.loc[high_indices, 'Stellar Age [Gyr]'] = np.random.randint(max_stellar_age + 1, 2*max_stellar_age, np.sum(high_indices))\n",
    "    \n",
    "    # Save the modified dataset\n",
    "    df.to_csv(original_dataset_path, index=False, encoding='utf-8')\n",
    "\n",
    "random_data(directories[rubric_item], 200)\n",
    "modify_data(directories[rubric_item])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "23971afc",
   "metadata": {},
   "source": [
    "# BEGIN q8: incorrect logic is used to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "fefa3441",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "rubric_item = \"q8: incorrect logic is used to answer\"\n",
    "nb = new_clean_nb(read_nb(os.path.join(DIRECTORY, FILE)))\n",
    "nb = truncate_nb(nb, end=find_all_cell_indices(nb, \"code\", \"grader.check('q8')\")[-1])\n",
    "\n",
    "results[rubric_item] = parse_nb(run_nb(nb, os.path.join(directories[rubric_item], FILE)))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "87dd3a9d",
   "metadata": {},
   "source": [
    "# END q8: incorrect logic is used to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "67f76315",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"update public_tests\"\"\"\n",
    "\n",
    "gen_public_tests.gen_public_tests(os.path.join(directories[rubric_item], FILE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5641dd",
   "metadata": {},
   "source": [
    "### q8: `get_stars` function is not used to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "c6c0f3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"update readme\"\"\"\n",
    "\n",
    "rubric_item = \"q8: `get_stars` function is not used to answer\"\n",
    "readme_text = \"\"\"This test is checking if you are using the\n",
    "`get_stars` function to answer the question. A\n",
    "modification has been made to the `get_stars`\n",
    "function so that it reads from a different\n",
    "file. If your answer does not change\n",
    "accordingly, it suggests that you did not use the\n",
    "`get_stars` function. Remember to utilize the\n",
    "provided functions instead of reading the data\n",
    "directly from the csv again.\"\"\" \n",
    "\n",
    "write_readme(readme_text, os.path.join(directories[rubric_item], \"README.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "804d5162",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_data(directories[rubric_item], 50)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f77aa031",
   "metadata": {},
   "source": [
    "# BEGIN q8: `get_stars` function is not used to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "34275c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "rubric_item = \"q8: `get_stars` function is not used to answer\"\n",
    "nb = new_clean_nb(read_nb(os.path.join(DIRECTORY, FILE)))\n",
    "nb = truncate_nb(nb, end=find_all_cell_indices(nb, \"code\", \"grader.check('q8')\")[-1])\n",
    "\n",
    "false_get_stars = \"\"\"\n",
    "import random\n",
    "\n",
    "def get_stars(star_file):\n",
    "    if 'data' not in star_file:\n",
    "        star_file = os.path.join('data', star_file)\n",
    "    stars_data = process_csv(star_file)\n",
    "    stars_header = stars_data[0]\n",
    "    stars_rows = stars_data[1:]\n",
    "    random.seed(0)\n",
    "    rows_in_cols = {}\n",
    "    for i in range(len(stars_rows[0])):\n",
    "        rows_in_cols[i] = []\n",
    "        for j in range(len(stars_rows)):\n",
    "            rows_in_cols[i].append(stars_rows[j][i])\n",
    "        random.shuffle(rows_in_cols[i])\n",
    "        \n",
    "    for j in range(len(stars_rows)):\n",
    "        for i in range(len(stars_rows[0])):\n",
    "            stars_rows[j][i] = rows_in_cols[i][j]\n",
    "            \n",
    "    stars = {}\n",
    "    for row_idx in range(len(stars_rows)):\n",
    "        star_name = star_cell(row_idx, 'Star Name', stars_rows)\n",
    "        spectral_type = star_cell(row_idx, 'Spectral Type', stars_rows)\n",
    "        stellar_effective_temperature = star_cell(row_idx, 'Stellar Effective Temperature [K]', stars_rows)\n",
    "        stellar_radius = star_cell(row_idx, 'Stellar Radius [Solar Radius]', stars_rows)\n",
    "        stellar_mass = star_cell(row_idx, 'Stellar Mass [Solar mass]', stars_rows)\n",
    "        stellar_luminosity = star_cell(row_idx, 'Stellar Luminosity [log(Solar)]', stars_rows)\n",
    "        stellar_surface_gravity = star_cell(row_idx, 'Stellar Surface Gravity [log10(cm/s**2)]', stars_rows)\n",
    "        stellar_age = star_cell(row_idx, 'Stellar Age [Gyr]', stars_rows)\n",
    "        star = Star(spectral_type, stellar_effective_temperature, stellar_radius, stellar_mass, stellar_luminosity, stellar_surface_gravity, stellar_age)\n",
    "        stars[star_name] = star\n",
    "    \n",
    "    return stars\"\"\"\n",
    "\n",
    "nb = replace_with_false_function(nb, 'get_stars', false_get_stars)\n",
    "\n",
    "results[rubric_item] = parse_nb(run_nb(nb, os.path.join(directories[rubric_item], FILE)))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "afd2539d",
   "metadata": {},
   "source": [
    "# END q8: `get_stars` function is not used to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "e3e55002",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"update public_tests\"\"\"\n",
    "\n",
    "gen_public_tests.gen_public_tests(os.path.join(directories[rubric_item], FILE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f904a57c",
   "metadata": {},
   "source": [
    "### q8: paths are hardcoded using slashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "7a81fa51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"update readme\"\"\"\n",
    "\n",
    "rubric_item = \"q8: paths are hardcoded using slashes\"\n",
    "readme_text = \"\"\"The test is checking for the\n",
    "robustness of your code across different operating\n",
    "systems. If paths have been hardcoded using \"/\" or\n",
    "\"\\\\\\\\\", the code may fail on some systems. The code\n",
    "injection is carrying out alterations to evaluate\n",
    "whether your code can function correctly in\n",
    "different operating system environments.\n",
    "Therefore, ensure that you're using `os.path.join`\n",
    "instead of hardcoding slashes.\"\"\" \n",
    "\n",
    "write_readme(readme_text, os.path.join(directories[rubric_item], \"README.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "7bc5fe09",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_data(directories[rubric_item], 50)\n",
    "for i in range(1, 6):\n",
    "    file_copy(os.path.join(directories[rubric_item], 'data', 'stars_%d.csv' % (i)), os.path.join(directories[rubric_item], 'data&stars_%d.csv' % (i)))\n",
    "    file_copy(os.path.join(directories[rubric_item], 'data', 'planets_%d.csv' % (i)), os.path.join(directories[rubric_item], 'data&planets_%d.csv' % (i)))\n",
    "    file_copy(os.path.join(directories[rubric_item], 'data', 'mapping_%d.json' % (i)), os.path.join(directories[rubric_item], 'data&mapping_%d.json' % (i)))\n",
    "random_data(directories[rubric_item], 50)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "be0af29d",
   "metadata": {},
   "source": [
    "# BEGIN q8: paths are hardcoded using slashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "e76058e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "rubric_item = \"q8: paths are hardcoded using slashes\"\n",
    "nb = new_clean_nb(read_nb(os.path.join(DIRECTORY, FILE)))\n",
    "nb = truncate_nb(nb, end=find_all_cell_indices(nb, \"code\", \"grader.check('q8')\")[-1])\n",
    "\n",
    "path_redefine = '''\n",
    "import os\n",
    "\n",
    "def new_join(*paths):\n",
    "    return '&'.join(paths)\n",
    "    \n",
    "def new_basename(path):\n",
    "    return path.split('&')[-1]\n",
    "    \n",
    "def new_dirname(path):\n",
    "    return '&'.join(path.split('&')[:-1])\n",
    "    \n",
    "def new_split(path):\n",
    "    return tuple(['&'.join(path.split('&')[:-1]), path.split('&')[-1]])'''\n",
    "\n",
    "nb = inject_code(nb, find_all_cell_indices(nb, \"markdown\", \"**Question 1:**\")[-1], path_redefine)\n",
    "nb = replace_code(nb, 'os.path.join', 'new_join')\n",
    "nb = replace_code(nb, 'os.path.basename', 'new_basename')\n",
    "nb = replace_code(nb, 'os.path.dirname', 'new_dirname')\n",
    "nb = replace_code(nb, 'os.path.split', 'new_split')\n",
    "nb = replace_code(nb, 'os.path.sep', \"'&'\")\n",
    "\n",
    "results[rubric_item] = parse_nb(run_nb(nb, os.path.join(directories[rubric_item], FILE)))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e180bb92",
   "metadata": {},
   "source": [
    "# END q8: paths are hardcoded using slashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "e04f8153",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"update public_tests\"\"\"\n",
    "\n",
    "gen_public_tests.gen_public_tests(os.path.join(directories[rubric_item], FILE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f778203",
   "metadata": {},
   "source": [
    "### stars_dict: data structure is defined incorrectly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "7dfa60cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"update readme\"\"\"\n",
    "\n",
    "rubric_item = \"stars_dict: data structure is defined incorrectly\"\n",
    "readme_text = \"\"\"This test is checking if you have correctly\n",
    "defined the data structure that maps the names of\n",
    "stars to their details. It is important that you\n",
    "define this data structure correctly, as any\n",
    "errors here will affect all future questions as\n",
    "well. The test will compare your data structure\n",
    "against the correct one to see if they match. Make\n",
    "sure you have followed the instructions and\n",
    "defined the data structure correctly.\"\"\" \n",
    "\n",
    "write_readme(readme_text, os.path.join(directories[rubric_item], \"README.txt\"))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0a23e4e0",
   "metadata": {},
   "source": [
    "# BEGIN stars_dict: data structure is defined incorrectly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "e5769e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "rubric_item = \"stars_dict: data structure is defined incorrectly\"\n",
    "nb = new_clean_nb(read_nb(os.path.join(DIRECTORY, FILE)))\n",
    "nb = truncate_nb(nb, end=find_all_cell_indices(nb, \"code\", \"grader.check('stars_dict')\")[-1])\n",
    "\n",
    "nb = inject_data_structure_check(nb, 'stars_dict', \"TEXT_FORMAT_DICT\")\n",
    "\n",
    "results[rubric_item] = parse_nb(run_nb(nb, os.path.join(directories[rubric_item], FILE)))\n",
    "test_output = results[rubric_item][rubric_item.split(\":\")[0]]\n",
    "if test_output != 'All test cases passed!':\n",
    "    comments[rubric_item] += '\\nFAILED TEST CASE: ' + test_output"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9ef73fe4",
   "metadata": {},
   "source": [
    "# END stars_dict: data structure is defined incorrectly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4022924",
   "metadata": {},
   "source": [
    "### stars_dict: `get_stars` function is not used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "314968b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"update readme\"\"\"\n",
    "\n",
    "rubric_item = \"stars_dict: `get_stars` function is not used\"\n",
    "readme_text = \"\"\"This test is checking if you are using the\n",
    "`get_stars` function to define `stars_dict`. A\n",
    "modification has been made to the `get_stars`\n",
    "function so that it reads from a different\n",
    "file. If your answer does not change\n",
    "accordingly, it suggests that you did not use the\n",
    "`get_stars` function. Remember to utilize the\n",
    "provided functions instead of reading the data\n",
    "directly from the csv again.\"\"\" \n",
    "\n",
    "write_readme(readme_text, os.path.join(directories[rubric_item], \"README.txt\"))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b6fbbb51",
   "metadata": {},
   "source": [
    "# BEGIN stars_dict: `get_stars` function is not used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "6ecef687",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "rubric_item = \"stars_dict: `get_stars` function is not used\"\n",
    "nb = new_clean_nb(read_nb(os.path.join(DIRECTORY, FILE)))\n",
    "nb = truncate_nb(nb, end=find_all_cell_indices(nb, \"code\", \"grader.check('stars_dict')\")[-1])\n",
    "\n",
    "nb = inject_data_structure_check(nb, 'stars_dict', \"TEXT_FORMAT_DICT\")\n",
    "\n",
    "false_get_stars = \"\"\"\n",
    "import random\n",
    "\n",
    "def get_stars(star_file):\n",
    "    if 'data' not in star_file:\n",
    "        star_file = os.path.join('data', star_file)\n",
    "    stars_data = process_csv(star_file)\n",
    "    stars_header = stars_data[0]\n",
    "    stars_rows = stars_data[1:]\n",
    "    random.seed(0)\n",
    "    rows_in_cols = {}\n",
    "    for i in range(len(stars_rows[0])):\n",
    "        rows_in_cols[i] = []\n",
    "        for j in range(len(stars_rows)):\n",
    "            rows_in_cols[i].append(stars_rows[j][i])\n",
    "        random.shuffle(rows_in_cols[i])\n",
    "        \n",
    "    for j in range(len(stars_rows)):\n",
    "        for i in range(len(stars_rows[0])):\n",
    "            stars_rows[j][i] = rows_in_cols[i][j]\n",
    "            \n",
    "    stars = {}\n",
    "    for row_idx in range(len(stars_rows)):\n",
    "        star_name = star_cell(row_idx, 'Star Name', stars_rows)\n",
    "        spectral_type = star_cell(row_idx, 'Spectral Type', stars_rows)\n",
    "        stellar_effective_temperature = star_cell(row_idx, 'Stellar Effective Temperature [K]', stars_rows)\n",
    "        stellar_radius = star_cell(row_idx, 'Stellar Radius [Solar Radius]', stars_rows)\n",
    "        stellar_mass = star_cell(row_idx, 'Stellar Mass [Solar mass]', stars_rows)\n",
    "        stellar_luminosity = star_cell(row_idx, 'Stellar Luminosity [log(Solar)]', stars_rows)\n",
    "        stellar_surface_gravity = star_cell(row_idx, 'Stellar Surface Gravity [log10(cm/s**2)]', stars_rows)\n",
    "        stellar_age = star_cell(row_idx, 'Stellar Age [Gyr]', stars_rows)\n",
    "        star = Star(spectral_type, stellar_effective_temperature, stellar_radius, stellar_mass, stellar_luminosity, stellar_surface_gravity, stellar_age)\n",
    "        stars[star_name] = star\n",
    "    \n",
    "    return stars\"\"\"\n",
    "nb = replace_with_false_function(nb, 'get_stars', false_get_stars)\n",
    "\n",
    "results[rubric_item] = parse_nb(run_nb(nb, os.path.join(directories[rubric_item], FILE)))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a89c8520",
   "metadata": {},
   "source": [
    "# END stars_dict: `get_stars` function is not used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e46946",
   "metadata": {},
   "source": [
    "### stars_dict: `stars_paths` is not used to find paths of necessary files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "c625ed3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"update readme\"\"\"\n",
    "\n",
    "rubric_item = \"stars_dict: `stars_paths` is not used to find paths of necessary files\"\n",
    "readme_text = \"\"\"The test is checking if the variable `stars_paths`\n",
    "is correctly used to find the necessary file\n",
    "paths. A code injection is performed that\n",
    "redefines the `stars_paths` variable to contain a\n",
    "different set of files. If the original files are\n",
    "still read despite this injection, it suggests\n",
    "that the `stars_paths` variable was not used to\n",
    "answer the question.\"\"\" \n",
    "\n",
    "write_readme(readme_text, os.path.join(directories[rubric_item], \"README.txt\"))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "66157f14",
   "metadata": {},
   "source": [
    "# BEGIN stars_dict: `stars_paths` is not used to find paths of necessary files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "0619f57f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "rubric_item = \"stars_dict: `stars_paths` is not used to find paths of necessary files\"\n",
    "nb = new_clean_nb(read_nb(os.path.join(DIRECTORY, FILE)))\n",
    "nb = truncate_nb(nb, end=find_all_cell_indices(nb, \"code\", \"grader.check('stars_dict')\")[-1])\n",
    "\n",
    "nb = inject_data_structure_check(nb, 'stars_dict', \"TEXT_FORMAT_DICT\")\n",
    "src = \"for csv_file in stars_paths\"\n",
    "target = \"import os\\nfor csv_file in [os.path.join('data', 'stars_%d.csv' % (i)) for i in range(1, 3)]\"\n",
    "nb['cells'][-2][\"source\"] = nb['cells'][-2][\"source\"].replace(src, target)\n",
    "\n",
    "code = \"\"\"\n",
    "import os\n",
    "stars_paths = [os.path.join('data', 'stars_%d.csv' % (i)) for i in range(1, 3)]\"\"\"\n",
    "nb = inject_code(nb, find_all_cell_indices(nb, \"markdown\", \"### Data Structure 2: `stars_dict`\")[-1], code)\n",
    "\n",
    "results[rubric_item] = parse_nb(run_nb(nb, os.path.join(directories[rubric_item], FILE)))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dd2a219a",
   "metadata": {},
   "source": [
    "# END stars_dict: `stars_paths` is not used to find paths of necessary files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e084daed",
   "metadata": {},
   "source": [
    "### q9: `stars_dict` data structure is not used to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "a2b73f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"update readme\"\"\"\n",
    "\n",
    "rubric_item = \"q9: `stars_dict` data structure is not used to answer\"\n",
    "readme_text = \"\"\"You need to access the `Star` objects in the \n",
    "`stars_dict` dictionary. The dictionary already \n",
    "contains all the data about the stars in \n",
    "the dataset. Make sure to use the data\n",
    "from the `stars_dict` dictionary to answer the\n",
    "question. A modified version of the dictionary is\n",
    "provided right before the answer to this question.\n",
    "If your answer does not use this modified data\n",
    "structure, you may not have used the data\n",
    "correctly.\"\"\" \n",
    "\n",
    "write_readme(readme_text, os.path.join(directories[rubric_item], \"README.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "029558ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_data(directories[rubric_item], 50)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6e6fbede",
   "metadata": {},
   "source": [
    "# BEGIN q9: `stars_dict` data structure is not used to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "f7029d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "rubric_item = \"q9: `stars_dict` data structure is not used to answer\"\n",
    "nb = new_clean_nb(read_nb(os.path.join(DIRECTORY, FILE)))\n",
    "nb = truncate_nb(nb, end=find_all_cell_indices(nb, \"code\", \"grader.check('q9')\")[-1])\n",
    "\n",
    "randomized_stars_dict = true_data_structures[\"stars_dict\"] + '''\n",
    "import random\n",
    "\n",
    "random.seed(0)\n",
    "stars_dict_keys = list(stars_dict.keys())\n",
    "stars_dict_values = list(stars_dict.values())\n",
    "random.shuffle(stars_dict_keys)\n",
    "random.shuffle(stars_dict_values)\n",
    "\n",
    "stars_dict = {}\n",
    "for i in range(len(stars_dict_keys)):\n",
    "    stars_dict[stars_dict_keys[i]] = stars_dict_values[i]\n",
    "'''\n",
    "nb = replace_with_false_data_structure(nb, 'stars_dict', randomized_stars_dict)\n",
    "\n",
    "results[rubric_item] = parse_nb(run_nb(nb, os.path.join(directories[rubric_item], FILE)))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "95b24bd2",
   "metadata": {},
   "source": [
    "# END q9: `stars_dict` data structure is not used to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "a4eab82f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"update public_tests\"\"\"\n",
    "\n",
    "gen_public_tests.gen_public_tests(os.path.join(directories[rubric_item], FILE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3903483e",
   "metadata": {},
   "source": [
    "### q10: incorrect logic is used to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "5f31e4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"update readme\"\"\"\n",
    "\n",
    "rubric_item = \"q10: incorrect logic is used to answer\"\n",
    "readme_text = \"\"\"You need to find the name of the largest star in\n",
    "terms of stellar radius. There might be some\n",
    "logical errors in your code that could prevent you\n",
    "from getting the correct answer. To test this, we\n",
    "will use a different dataset where everything is\n",
    "different. If your code fails to find the largest\n",
    "star in this new dataset, it suggests there are\n",
    "logical errors in your code. Make sure to handle\n",
    "missing data properly and implement the correct\n",
    "logic to find the largest star.\"\"\" \n",
    "\n",
    "write_readme(readme_text, os.path.join(directories[rubric_item], \"README.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "d5b8bda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_data(path):\n",
    "    # Load the stars data\n",
    "    big_file = random.randint(1, 6)\n",
    "    for i in range(1, 6):\n",
    "        filepath = os.path.join(path, \"data\", 'stars_%d.csv' % (i))\n",
    "        df = pd.read_csv(filepath, encoding='utf-8')\n",
    "        \n",
    "        df['Stellar Radius [Solar Radius]'] = np.random.uniform(0.01, 110.0, len(df))\n",
    "        \n",
    "        if i == big_file:\n",
    "            df.loc[random.randint(1, len(df)-1), 'Stellar Radius [Solar Radius]'] = 150.0\n",
    "            \n",
    "        df.to_csv(filepath, index=False, encoding='utf-8')\n",
    "    \n",
    "random_data(directories[rubric_item], 200)\n",
    "modify_data(directories[rubric_item])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "29adffd7",
   "metadata": {},
   "source": [
    "# BEGIN q10: incorrect logic is used to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "2c55fc97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "rubric_item = \"q10: incorrect logic is used to answer\"\n",
    "nb = new_clean_nb(read_nb(os.path.join(DIRECTORY, FILE)))\n",
    "nb = truncate_nb(nb, end=find_all_cell_indices(nb, \"code\", \"grader.check('q10')\")[-1])\n",
    "\n",
    "results[rubric_item] = parse_nb(run_nb(nb, os.path.join(directories[rubric_item], FILE)))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "386dda3b",
   "metadata": {},
   "source": [
    "# END q10: incorrect logic is used to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "0ee49232",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"update public_tests\"\"\"\n",
    "\n",
    "gen_public_tests.gen_public_tests(os.path.join(directories[rubric_item], FILE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be45de14",
   "metadata": {},
   "source": [
    "### q10: `stars_dict` data structure is not used to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "708443c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"update readme\"\"\"\n",
    "\n",
    "rubric_item = \"q10: `stars_dict` data structure is not used to answer\"\n",
    "readme_text = \"\"\"You need to access the `Star` objects in the \n",
    "`stars_dict` dictionary. The dictionary already \n",
    "contains all the data about the stars in \n",
    "the dataset. Make sure to use the data\n",
    "from the `stars_dict` dictionary to answer the\n",
    "question. A modified version of the dictionary is\n",
    "provided right before the answer to this question.\n",
    "If your answer does not use this modified data\n",
    "structure, you may not have used the data\n",
    "correctly\"\"\" \n",
    "\n",
    "write_readme(readme_text, os.path.join(directories[rubric_item], \"README.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "e3996e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_data(directories[rubric_item], 50)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ede27e97",
   "metadata": {},
   "source": [
    "# BEGIN q10: `stars_dict` data structure is not used to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "44047acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "rubric_item = \"q10: `stars_dict` data structure is not used to answer\"\n",
    "nb = new_clean_nb(read_nb(os.path.join(DIRECTORY, FILE)))\n",
    "nb = truncate_nb(nb, end=find_all_cell_indices(nb, \"code\", \"grader.check('q10')\")[-1])\n",
    "\n",
    "randomized_stars_dict = true_data_structures[\"stars_dict\"] + '''\n",
    "import random\n",
    "\n",
    "random.seed(0)\n",
    "stars_dict_keys = list(stars_dict.keys())\n",
    "stars_dict_values = list(stars_dict.values())\n",
    "random.shuffle(stars_dict_keys)\n",
    "random.shuffle(stars_dict_values)\n",
    "\n",
    "stars_dict = {}\n",
    "for i in range(len(stars_dict_keys)):\n",
    "    stars_dict[stars_dict_keys[i]] = stars_dict_values[i]\n",
    "'''\n",
    "nb = replace_with_false_data_structure(nb, 'stars_dict', randomized_stars_dict)\n",
    "\n",
    "results[rubric_item] = parse_nb(run_nb(nb, os.path.join(directories[rubric_item], FILE)))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "228aa8e4",
   "metadata": {},
   "source": [
    "# END q10: `stars_dict` data structure is not used to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "e28fcaa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"update public_tests\"\"\"\n",
    "\n",
    "gen_public_tests.gen_public_tests(os.path.join(directories[rubric_item], FILE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc95f89c",
   "metadata": {},
   "source": [
    "### q11: answer does not check for only stars that start with `Kepler`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "214d1597",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"update readme\"\"\"\n",
    "\n",
    "rubric_item = \"q11: answer does not check for only stars that start with `Kepler`\"\n",
    "readme_text = \"\"\"You need to calculate the average stellar age of\n",
    "stars whose names start with \"Kepler\". Make sure\n",
    "to skip stars with missing stellar age data. Be\n",
    "careful, there are some stars whose names have\n",
    "\"Kepler\" appearing somewhere in the name, but they\n",
    "should not be included in the calculation. The\n",
    "dataset has been modified with changes to the\n",
    "\"Star Name\" column.\"\"\" \n",
    "\n",
    "write_readme(readme_text, os.path.join(directories[rubric_item], \"README.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "92677589",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_data(directory):    \n",
    "    # Path of the original dataset file\n",
    "    for i in range(1, 6):\n",
    "        original_dataset_path = os.path.join(directory, \"data\", \"stars_%d.csv\" % (i))\n",
    "\n",
    "        # Read the original dataset\n",
    "        df = pd.read_csv(original_dataset_path, encoding='utf-8')\n",
    "\n",
    "        # Modify the dataset by setting nearly a third of Star Name values as starting with 'Kepler'\n",
    "        num_rows = len(df)\n",
    "        num_start_keplers = int(num_rows / 3)\n",
    "        start_kepler_indices = np.random.choice(num_rows, num_start_keplers, replace=False)\n",
    "        df.loc[start_kepler_indices, 'Star Name'] = random.choice(['Kepler', 'Kepler ', 'Kepler-']) + df.loc[start_kepler_indices, 'Star Name']\n",
    "\n",
    "        # Modify the dataset by setting nearly a third of Star Name values as having but not starting with 'Kepler'\n",
    "        num_not_start_keplers = int(num_rows / 3)\n",
    "        not_start_keplers_indices = np.random.choice(num_rows, num_not_start_keplers, replace=False)\n",
    "        df.loc[not_start_keplers_indices, 'Star Name'] = random.choice(['SKepler ', 'kepler ', 'Planet Kepler ']) + df.loc[not_start_keplers_indices, 'Star Name']\n",
    "        max_stellar_age = 10**9\n",
    "        df.loc[not_start_keplers_indices, 'Stellar Age [Gyr]'] = np.random.randint(max_stellar_age + 1, 2*max_stellar_age, len(not_start_keplers_indices))\n",
    "\n",
    "        # Save the modified dataset\n",
    "        df.to_csv(original_dataset_path, index=False, encoding='utf-8')\n",
    "    \n",
    "random_data(directories[rubric_item], 200)\n",
    "modify_data(directories[rubric_item])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ae4043eb",
   "metadata": {},
   "source": [
    "# BEGIN q11: answer does not check for only stars that start with `Kepler`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "e20ab7e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "rubric_item = \"q11: answer does not check for only stars that start with `Kepler`\"\n",
    "nb = new_clean_nb(read_nb(os.path.join(DIRECTORY, FILE)))\n",
    "nb = truncate_nb(nb, end=find_all_cell_indices(nb, \"code\", \"grader.check('q11')\")[-1])\n",
    "\n",
    "results[rubric_item] = parse_nb(run_nb(nb, os.path.join(directories[rubric_item], FILE)))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a820ee8f",
   "metadata": {},
   "source": [
    "# END q11: answer does not check for only stars that start with `Kepler`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "1fe8b3d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"update public_tests\"\"\"\n",
    "\n",
    "gen_public_tests.gen_public_tests(os.path.join(directories[rubric_item], FILE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c426f6a5",
   "metadata": {},
   "source": [
    "### q11: incorrect logic is used to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "ee7d5f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"update readme\"\"\"\n",
    "\n",
    "rubric_item = \"q11: incorrect logic is used to answer\"\n",
    "readme_text = \"\"\"You need to find the average Stellar Age\n",
    "of all stars whose names begin with 'Kepler'. \n",
    "There might be some logical errors in your code \n",
    "that could prevent you from getting the correct \n",
    "answer. To test this, we will use a different \n",
    "dataset where everything is different. If your \n",
    "code fails to find the average age of stars in\n",
    "this new dataset, it suggests there are logical \n",
    "errors in your code. Make sure to handle\n",
    "missing data properly and implement the correct\n",
    "logic to find the average age.\"\"\" \n",
    "\n",
    "write_readme(readme_text, os.path.join(directories[rubric_item], \"README.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "e855e410",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_data(path):\n",
    "    for i in range(1, 6):\n",
    "        # Read data from stars.csv file\n",
    "        stars_df = pd.read_csv(os.path.join(path, \"data\", 'stars_%d.csv' % (i)), encoding='utf-8')\n",
    "\n",
    "        # Modify Star Name column to have some names starting with \"Kepler\"\n",
    "        kepler_num = int(len(stars_df) * 0.75)\n",
    "        kepler_indices = stars_df.sample(kepler_num)\n",
    "        stars_df.loc[kepler_indices.index, 'Star Name'] = 'Kepler ' + stars_df['Star Name']\n",
    "\n",
    "        # Randomly set missing Stellar Age values for some stars\n",
    "        num_missing_age = int(len(stars_df) * 0.33)\n",
    "        missing_age_indices = kepler_indices.sample(num_missing_age)\n",
    "        stars_df.loc[missing_age_indices.index, 'Stellar Age [Gyr]'] = None\n",
    "\n",
    "        # Randomly set 0 Stellar Age values for some stars\n",
    "        num_zero_age = int(len(stars_df) * 0.33)\n",
    "        zero_age_indices = kepler_indices.sample(num_zero_age)\n",
    "        stars_df.loc[zero_age_indices.index, 'Stellar Age [Gyr]'] = 0\n",
    "\n",
    "        # Randomly set high Stellar Age values for some stars\n",
    "        num_high_age = int(len(stars_df) * 0.33)\n",
    "        high_age_indices = kepler_indices.sample(num_high_age)\n",
    "        stars_df.loc[high_age_indices.index, 'Stellar Age [Gyr]'] = 1000\n",
    "\n",
    "        # Save modified stars dataset\n",
    "        stars_df.to_csv(os.path.join(path, \"data\", 'stars_%d.csv' % (i)), index=False, encoding='utf-8')\n",
    "    \n",
    "random_data(directories[rubric_item], 200)\n",
    "modify_data(directories[rubric_item])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5560dc6c",
   "metadata": {},
   "source": [
    "# BEGIN q11: incorrect logic is used to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "465fd6f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "rubric_item = \"q11: incorrect logic is used to answer\"\n",
    "nb = new_clean_nb(read_nb(os.path.join(DIRECTORY, FILE)))\n",
    "nb = truncate_nb(nb, end=find_all_cell_indices(nb, \"code\", \"grader.check('q11')\")[-1])\n",
    "\n",
    "results[rubric_item] = parse_nb(run_nb(nb, os.path.join(directories[rubric_item], FILE)))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a47f517e",
   "metadata": {},
   "source": [
    "# END q11: incorrect logic is used to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "08099712",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"update public_tests\"\"\"\n",
    "\n",
    "gen_public_tests.gen_public_tests(os.path.join(directories[rubric_item], FILE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf31575",
   "metadata": {},
   "source": [
    "### q11: `stars_dict` data structure is not used to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "8b5d6cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"update readme\"\"\"\n",
    "\n",
    "rubric_item = \"q11: `stars_dict` data structure is not used to answer\"\n",
    "readme_text = \"\"\"You need to access the `Star` objects in the \n",
    "`stars_dict` dictionary. The dictionary already \n",
    "contains all the data about the stars in \n",
    "the dataset. Make sure to use the data\n",
    "from the `stars_dict` dictionary to answer the\n",
    "question. A modified version of the dictionary is\n",
    "provided right before the answer to this question.\n",
    "If your answer does not use this modified data\n",
    "structure, you may not have used the data\n",
    "correctly.\"\"\" \n",
    "\n",
    "write_readme(readme_text, os.path.join(directories[rubric_item], \"README.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "6a40893f",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_data(directories[rubric_item], 50)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9f752e2b",
   "metadata": {},
   "source": [
    "# BEGIN q11: `stars_dict` data structure is not used to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "61b1222a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "rubric_item = \"q11: `stars_dict` data structure is not used to answer\"\n",
    "nb = new_clean_nb(read_nb(os.path.join(DIRECTORY, FILE)))\n",
    "nb = truncate_nb(nb, end=find_all_cell_indices(nb, \"code\", \"grader.check('q11')\")[-1])\n",
    "\n",
    "randomized_stars_dict = true_data_structures[\"stars_dict\"] + '''\n",
    "import random\n",
    "\n",
    "random.seed(0)\n",
    "stars_dict_keys = list(stars_dict.keys())\n",
    "stars_dict_values = list(stars_dict.values())\n",
    "random.shuffle(stars_dict_keys)\n",
    "random.shuffle(stars_dict_values)\n",
    "\n",
    "stars_dict = {}\n",
    "for i in range(len(stars_dict_keys)):\n",
    "    if stars_dict_keys[i].startswith('Kepler') and stars_dict_values[i].stellar_age != None:\n",
    "        stars_dict_values[i] = stars_dict_values[i]._replace(stellar_age=stars_dict_values[i].stellar_age+20)\n",
    "    stars_dict[stars_dict_keys[i]] = stars_dict_values[i]\n",
    "'''\n",
    "nb = replace_with_false_data_structure(nb, 'stars_dict', randomized_stars_dict)\n",
    "\n",
    "results[rubric_item] = parse_nb(run_nb(nb, os.path.join(directories[rubric_item], FILE)))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8e216bad",
   "metadata": {},
   "source": [
    "# END q11: `stars_dict` data structure is not used to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "d8d37669",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"update public_tests\"\"\"\n",
    "\n",
    "gen_public_tests.gen_public_tests(os.path.join(directories[rubric_item], FILE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297e766e",
   "metadata": {},
   "source": [
    "### Planet: data structure is defined more than once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "a29f4c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"update readme\"\"\"\n",
    "\n",
    "rubric_item = \"Planet: data structure is defined more than once\"\n",
    "readme_text = \"\"\"This test is checking if you have defined your\n",
    "namedtuple class multiple times. Try to ensure you\n",
    "define your classes where you are asked to,\n",
    "and not inside functions, which could result in\n",
    "the class being redefined every time the function\n",
    "is called. This could lead to unnecessary\n",
    "performance issues and possible conflicts if\n",
    "definitions don't align.\"\"\" \n",
    "\n",
    "write_readme(readme_text, os.path.join(directories[rubric_item], \"README.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "35525672",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_data(directories[rubric_item], 50)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "168a5989",
   "metadata": {},
   "source": [
    "# BEGIN Planet: data structure is defined more than once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "647ee2bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "rubric_item = \"Planet: data structure is defined more than once\"\n",
    "nb = new_clean_nb(read_nb(os.path.join(DIRECTORY, FILE)))\n",
    "\n",
    "hidn_namedtuple_count = '''\n",
    "from collections import namedtuple\n",
    "\n",
    "old_namedtuple = namedtuple\n",
    "hidn_namedtuple_count = {}\n",
    "def namedtuple(name, attributes):\n",
    "    global hidn_namedtuple_count\n",
    "    if name not in hidn_namedtuple_count:\n",
    "        hidn_namedtuple_count[name] = 0\n",
    "    hidn_namedtuple_count[name] += 1\n",
    "    return old_namedtuple(name, attributes)'''\n",
    "\n",
    "nb = inject_code(nb, find_all_cell_indices(nb, \"markdown\", \"**Question 1:**\")[-1], hidn_namedtuple_count)\n",
    "code = \"\"\"\n",
    "if hidn_namedtuple_count['Planet'] == 1:\n",
    "    test_output = \"Planet results: All test cases passed!\"\n",
    "\"\"\"\n",
    "nb = inject_code(nb, len(nb['cells']), get_test_text('Planet', code))\n",
    "\n",
    "results[rubric_item] = parse_nb(run_nb(nb, os.path.join(directories[rubric_item], FILE)))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5eacf713",
   "metadata": {},
   "source": [
    "# END Planet: data structure is defined more than once"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f4025b",
   "metadata": {},
   "source": [
    "### Planet: data structure is defined incorrectly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "4f3a40a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"update readme\"\"\"\n",
    "\n",
    "rubric_item = \"Planet: data structure is defined incorrectly\"\n",
    "readme_text = \"\"\"This test is attempting to\n",
    "ensure that you have defined your Planet namedtuple\n",
    "correctly. It tries to create a new Planet object\n",
    "using your definition. The successful creation of\n",
    "this object would confirm that the planet object\n",
    "meets the necessary structure that will be used in\n",
    "the later parts of the project.\"\"\" \n",
    "\n",
    "write_readme(readme_text, os.path.join(directories[rubric_item], \"README.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "9dba00f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_data(directories[rubric_item], 50)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8937b321",
   "metadata": {},
   "source": [
    "# BEGIN Planet: data structure is defined incorrectly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "881fd37f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "rubric_item = \"Planet: data structure is defined incorrectly\"\n",
    "nb = new_clean_nb(read_nb(os.path.join(DIRECTORY, FILE)))\n",
    "nb = truncate_nb(nb, end=find_all_cell_indices(nb, \"code\", \"grader.check('Planet')\")[-1])\n",
    "\n",
    "code = \"\"\"\n",
    "jupiter = None\n",
    "try:\n",
    "    jupiter = Planet('Jupiter', 'Sun', 'Imaging', 1610, False, 4333.0, 11.209, 317.828, 5.2038, 0.0489, 110, 0.0345)\n",
    "except:\n",
    "    pass\"\"\"\n",
    "nb = inject_code(nb, find_all_cell_indices(nb, \"code\", \"grader.check('Planet')\")[-1], code)\n",
    "\n",
    "results[rubric_item] = parse_nb(run_nb(nb, os.path.join(directories[rubric_item], FILE)))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b2ff3454",
   "metadata": {},
   "source": [
    "# END Planet: data structure is defined incorrectly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "dca72892",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"update public_tests\"\"\"\n",
    "\n",
    "gen_public_tests.gen_public_tests(os.path.join(directories[rubric_item], FILE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6483ce",
   "metadata": {},
   "source": [
    "### planet_cell: function does not typecast values based on columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "94f5b160",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"update readme\"\"\"\n",
    "\n",
    "rubric_item = \"planet_cell: function does not typecast values based on columns\"\n",
    "readme_text = \"\"\"This test checks whether your function correctly\n",
    "preprocesses and typecasts values according to\n",
    "their corresponding column types. For example,\n",
    "numeric columns should return float values, and\n",
    "textual columns should return string values. This\n",
    "is checked by running your function on various\n",
    "columns and analyzing the data types of the\n",
    "returned values. The intention is to ensure your\n",
    "function effectively automates this process, thus\n",
    "reducing the need for additional manual\n",
    "typecasting.\"\"\" \n",
    "\n",
    "write_readme(readme_text, os.path.join(directories[rubric_item], \"README.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "aa6e8364",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_data(directories[rubric_item], 50)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "025ba564",
   "metadata": {},
   "source": [
    "# BEGIN planet_cell: function does not typecast values based on columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "5ceb276d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "rubric_item = \"planet_cell: function does not typecast values based on columns\"\n",
    "nb = new_clean_nb(read_nb(os.path.join(DIRECTORY, FILE)))\n",
    "nb = truncate_nb(nb, end=find_all_cell_indices(nb, \"code\", \"grader.check('planet_cell')\")[-1])\n",
    "\n",
    "var_inputs_code = \"\"\"\n",
    "var_inputs = []\n",
    "import os\n",
    "import csv\n",
    "def process_csv(filename):\n",
    "    csv_file = open(filename, encoding=\"utf-8\")\n",
    "    csv_reader = csv.reader(csv_file)\n",
    "    csv_data = list(csv_reader)\n",
    "    csv_file.close()\n",
    "    return csv_data\n",
    "\n",
    "_planets_rows = []\n",
    "for i in range(1, 3):\n",
    "    _planets_csv = process_csv(os.path.join(\"data\", \"planets_%d.csv\" % (i)))\n",
    "    _planets_rows.append(_planets_csv[1:])\n",
    "    _cols = _planets_csv[0]\n",
    "    \n",
    "for _col in _cols:\n",
    "    for _rows in _planets_rows:\n",
    "        var_inputs.append((0, _col, _rows))\n",
    "\"\"\"\n",
    "nb = inject_function_logic_check(nb, 'planet_cell', var_inputs_code, 'TEXT_FORMAT')\n",
    "src = 'check = public_tests.compare(expected_val, actual_val, test_format)'\n",
    "trgt = 'check = public_tests.compare(type(expected_val), type(actual_val), test_format)'\n",
    "nb['cells'][-2]['source'] = nb['cells'][-2]['source'].replace(src, trgt)\n",
    "\n",
    "results[rubric_item] = parse_nb(run_nb(nb, os.path.join(directories[rubric_item], FILE)))\n",
    "test_output = results[rubric_item][rubric_item.split(\":\")[0]]\n",
    "if test_output != 'All test cases passed!':\n",
    "    comments[rubric_item] += '\\nFAILED TEST CASE: ' + test_output"
   ]
  },
  {
   "cell_type": "raw",
   "id": "13f5a24f",
   "metadata": {},
   "source": [
    "# END planet_cell: function does not typecast values based on columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b457f9fe",
   "metadata": {},
   "source": [
    "### planet_cell: column indices are hardcoded instead of using column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "4f6aa471",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"update readme\"\"\"\n",
    "\n",
    "rubric_item = \"planet_cell: column indices are hardcoded instead of using column names\"\n",
    "readme_text = \"\"\"This test checks if your function correctly uses\n",
    "column names to find the index, instead of relying\n",
    "on hardcoded indices. To do this, the columns in\n",
    "the datasets are shuffled around in various ways.\n",
    "If your function relies on hardcoded indices, this\n",
    "test can highlight that issue since the correct\n",
    "data will not be extracted due to the permutation\n",
    "of columns.\"\"\" \n",
    "\n",
    "write_readme(readme_text, os.path.join(directories[rubric_item], \"README.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "eeacaed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_data(directory):\n",
    "    col_order = None\n",
    "    for i in range(1, 6):\n",
    "        planets_df = pd.read_csv(os.path.join(directory, \"data\", 'planets_%d.csv' % (i)), encoding='utf-8')\n",
    "        if col_order == None:\n",
    "            col_order = list(np.random.permutation(planets_df.columns)) # come up with random permutation\n",
    "\n",
    "        # Randomly permute the order of the columns in the dataframe and save the dataframe\n",
    "        planets_df = planets_df[col_order]\n",
    "\n",
    "        planets_df.to_csv(os.path.join(directory, \"data\", 'planets_%d.csv' % (i)), index=False, encoding='utf-8')\n",
    "    \n",
    "random_data(directories[rubric_item], 50)\n",
    "modify_data(directories[rubric_item])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "46daa114",
   "metadata": {},
   "source": [
    "# BEGIN planet_cell: column indices are hardcoded instead of using column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "e634859f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "rubric_item = \"planet_cell: column indices are hardcoded instead of using column names\"\n",
    "nb = new_clean_nb(read_nb(os.path.join(DIRECTORY, FILE)))\n",
    "nb = truncate_nb(nb, end=find_all_cell_indices(nb, \"code\", \"grader.check('planet_cell')\")[-1])\n",
    "\n",
    "var_inputs_code = \"\"\"\n",
    "var_inputs = []\n",
    "import os\n",
    "import csv\n",
    "def process_csv(filename):\n",
    "    csv_file = open(filename, encoding=\"utf-8\")\n",
    "    csv_reader = csv.reader(csv_file)\n",
    "    csv_data = list(csv_reader)\n",
    "    csv_file.close()\n",
    "    return csv_data\n",
    "\n",
    "_planets_rows = []\n",
    "for i in range(1, 3):\n",
    "    _planets_csv = process_csv(os.path.join(\"data\", \"planets_%d.csv\" % (i)))\n",
    "    _planets_rows.append(_planets_csv[1:])\n",
    "    _cols = _planets_csv[0]\n",
    "    \n",
    "for _col in _cols:\n",
    "    for _rows in _planets_rows:\n",
    "        var_inputs.append((0, _col, _rows))\n",
    "\"\"\"\n",
    "nb = inject_function_logic_check(nb, 'planet_cell', var_inputs_code, 'TEXT_FORMAT')\n",
    "\n",
    "results[rubric_item] = parse_nb(run_nb(nb, os.path.join(directories[rubric_item], FILE)))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fd4020e9",
   "metadata": {},
   "source": [
    "# END planet_cell: column indices are hardcoded instead of using column names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faeacb5e",
   "metadata": {},
   "source": [
    "### planet_cell: boolean values are not typecasted correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "73b8ded7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"update readme\"\"\"\n",
    "\n",
    "rubric_item = \"planet_cell: boolean values are not typecasted correctly\"\n",
    "readme_text = \"\"\"The test is checking if your code correctly\n",
    "typecasts boolean values. The dataset has been\n",
    "modified and some values in the `Controversial\n",
    "Flag` column have been changed. Around half of the\n",
    "values are now set to 0 and the other half to 1.\n",
    "Make sure your code correctly interprets these\n",
    "values and returns the corresponding boolean\n",
    "values.\"\"\" \n",
    "\n",
    "write_readme(readme_text, os.path.join(directories[rubric_item], \"README.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "58303177",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_data(path):\n",
    "    # Read the planets dataframes\n",
    "    planets_df = pd.read_csv(os.path.join(path, \"data\", 'planets_1.csv'), encoding='utf-8')\n",
    "    \n",
    "    # Modify the Controversial Flag column in planets DataFrame\n",
    "    planets_df['Controversial Flag'] = pd.Series([0 if i < len(planets_df) / 2 else 1 for i in range(len(planets_df))])\n",
    "    \n",
    "    # Save the modified dataframes\n",
    "    planets_df.to_csv(os.path.join(path, \"data\", 'planets_1.csv'), index=False, encoding='utf-8')\n",
    "    \n",
    "random_data(directories[rubric_item], 50)\n",
    "modify_data(directories[rubric_item])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "53957b72",
   "metadata": {},
   "source": [
    "# BEGIN planet_cell: boolean values are not typecasted correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "336ab5c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "rubric_item = \"planet_cell: boolean values are not typecasted correctly\"\n",
    "nb = new_clean_nb(read_nb(os.path.join(DIRECTORY, FILE)))\n",
    "nb = truncate_nb(nb, end=find_all_cell_indices(nb, \"code\", \"grader.check('planet_cell')\")[-1])\n",
    "\n",
    "var_inputs_code = \"\"\"\n",
    "var_inputs = []\n",
    "import os\n",
    "import csv\n",
    "def process_csv(filename):\n",
    "    csv_file = open(filename, encoding=\"utf-8\")\n",
    "    csv_reader = csv.reader(csv_file)\n",
    "    csv_data = list(csv_reader)\n",
    "    csv_file.close()\n",
    "    return csv_data\n",
    "\n",
    "_planets_rows = []\n",
    "for i in range(1, 6):\n",
    "    _planets_csv = process_csv(os.path.join(\"data\", \"planets_%d.csv\" % (i)))\n",
    "    _planets_rows.append(_planets_csv[1:])\n",
    "    _cols = _planets_csv[0]\n",
    "    \n",
    "for _rows in _planets_rows:\n",
    "    for _idx in range(len(_rows)):\n",
    "        var_inputs.append((_idx, 'Controversial Flag', _rows))\n",
    "\"\"\"\n",
    "nb = inject_function_logic_check(nb, 'planet_cell', var_inputs_code, 'TEXT_FORMAT')\n",
    "\n",
    "results[rubric_item] = parse_nb(run_nb(nb, os.path.join(directories[rubric_item], FILE)))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6df43a87",
   "metadata": {},
   "source": [
    "# END planet_cell: boolean values are not typecasted correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30577d92",
   "metadata": {},
   "source": [
    "### planet_cell: function logic is incorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "181bccbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"update readme\"\"\"\n",
    "\n",
    "rubric_item = \"planet_cell: function logic is incorrect\"\n",
    "readme_text = \"\"\"The test is evaluating the\n",
    "'planet_cell' function implementation which you have\n",
    "written. It specifically checks whether the\n",
    "function correctly extracts values from the list\n",
    "of lists 'planets_rows' given the row index and\n",
    "column name. The test will verify if the function\n",
    "accurately handles missing values and typecasts\n",
    "different values based on the column name. The\n",
    "test will run the function on a variety of\n",
    "possible inputs.\"\"\" \n",
    "\n",
    "write_readme(readme_text, os.path.join(directories[rubric_item], \"README.txt\"))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e6efc128",
   "metadata": {},
   "source": [
    "# BEGIN planet_cell: function logic is incorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "1dbb903e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "rubric_item = \"planet_cell: function logic is incorrect\"\n",
    "nb = new_clean_nb(read_nb(os.path.join(DIRECTORY, FILE)))\n",
    "nb = truncate_nb(nb, end=find_all_cell_indices(nb, \"code\", \"grader.check('planet_cell')\")[-1])\n",
    "\n",
    "var_inputs_code = \"\"\"\n",
    "var_inputs = []\n",
    "import os\n",
    "import csv\n",
    "def process_csv(filename):\n",
    "    csv_file = open(filename, encoding=\"utf-8\")\n",
    "    csv_reader = csv.reader(csv_file)\n",
    "    csv_data = list(csv_reader)\n",
    "    csv_file.close()\n",
    "    return csv_data\n",
    "\n",
    "_planets_rows = []\n",
    "for i in [1, 2, 3, 5]:\n",
    "    _planets_csv = process_csv(os.path.join(\"data\", \"planets_%d.csv\" % (i)))\n",
    "    _planets_rows.append(_planets_csv[1:])\n",
    "    _cols = _planets_csv[0]\n",
    "    \n",
    "for _rows in _planets_rows:\n",
    "    for _col in _cols:\n",
    "        for _idx in range(len(_rows)):\n",
    "            var_inputs.append((_idx, _col, _rows))\n",
    "\"\"\"\n",
    "nb = inject_function_logic_check(nb, 'planet_cell', var_inputs_code, 'TEXT_FORMAT')\n",
    "\n",
    "results[rubric_item] = parse_nb(run_nb(nb, os.path.join(directories[rubric_item], FILE)))\n",
    "test_output = results[rubric_item][rubric_item.split(\":\")[0]]\n",
    "if test_output != 'All test cases passed!':\n",
    "    comments[rubric_item] += '\\nFAILED TEST CASE: ' + test_output"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a5b3b60d",
   "metadata": {},
   "source": [
    "# END planet_cell: function logic is incorrect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79f2709",
   "metadata": {},
   "source": [
    "### planet_cell: function is defined more than once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "df272e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"update readme\"\"\"\n",
    "\n",
    "rubric_item = \"planet_cell: function is defined more than once\"\n",
    "readme_text = \"\"\"This test is designed to ensure that your function\n",
    "'planet_cell' is defined only once in your notebook.\n",
    "Having multiple definitions can lead to unexpected\n",
    "results if notebook cells are executed out of\n",
    "order. The test reads through your code and counts\n",
    "definitions of the function 'planet_cell'. It may\n",
    "fail if more than one definition is found. Please\n",
    "ensure your function is defined only once.\"\"\" \n",
    "\n",
    "write_readme(readme_text, os.path.join(directories[rubric_item], \"README.txt\"))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "43d27864",
   "metadata": {},
   "source": [
    "# BEGIN planet_cell: function is defined more than once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "d86d6c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "rubric_item = \"planet_cell: function is defined more than once\"\n",
    "nb = new_clean_nb(read_nb(os.path.join(DIRECTORY, FILE)))\n",
    "\n",
    "results[rubric_item] = {}\n",
    "if count_defns(nb, 'planet_cell') != 1:\n",
    "    results[rubric_item][rubric_item.split(\":\")[0]] = \"function is defined more than once\"\n",
    "else:\n",
    "    results[rubric_item][rubric_item.split(\":\")[0]] = \"All test cases passed!\""
   ]
  },
  {
   "cell_type": "raw",
   "id": "b2b2bcdc",
   "metadata": {},
   "source": [
    "# END planet_cell: function is defined more than once"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac81206",
   "metadata": {},
   "source": [
    "### q12: `planet_cell` function is not used to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "782d739c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"update readme\"\"\"\n",
    "\n",
    "rubric_item = \"q12: `planet_cell` function is not used to answer\"\n",
    "readme_text = \"\"\"This test is checking if you are using the\n",
    "`planet_cell` function to answer the question. A\n",
    "modification has been made to the `planet_cell`\n",
    "function so that it reads from a different\n",
    "dataset. If your answer does not change\n",
    "accordingly, it suggests that you did not use the\n",
    "`planet_cell` function. Remember to utilize the\n",
    "provided functions instead of reading the data\n",
    "directly from the csv again.\"\"\" \n",
    "\n",
    "write_readme(readme_text, os.path.join(directories[rubric_item], \"README.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "afbe126e",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_data(directories[rubric_item], 50)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0ee86a80",
   "metadata": {},
   "source": [
    "# BEGIN q12: `planet_cell` function is not used to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "5f63ebaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "rubric_item = \"q12: `planet_cell` function is not used to answer\"\n",
    "nb = new_clean_nb(read_nb(os.path.join(DIRECTORY, FILE)))\n",
    "nb = truncate_nb(nb, end=find_all_cell_indices(nb, \"code\", \"grader.check('q12')\")[-1])\n",
    "\n",
    "false_planet_cell = \"\"\"\n",
    "import os\n",
    "import csv\n",
    "import copy\n",
    "import random\n",
    "\n",
    "def process_csv(filename):\n",
    "    csv_file = open(filename, encoding='utf-8')\n",
    "    csv_reader = csv.reader(csv_file)\n",
    "    csv_data = list(csv_reader)\n",
    "    csv_file.close()\n",
    "    return csv_data\n",
    "    \n",
    "planets_1_csv = process_csv(os.path.join('data', 'planets_1.csv'))\n",
    "planets_header = planets_1_csv[0]\n",
    "planets_1_rows = planets_1_csv[1:]\n",
    "\n",
    "def planet_cell(row_idx, col_name, planets_rows, header=planets_header):\n",
    "    planets_rows = copy.deepcopy(planets_rows)\n",
    "    random.seed(0)\n",
    "    rows_in_cols = {}\n",
    "    for i in range(len(planets_rows[0])):\n",
    "        rows_in_cols[i] = []\n",
    "        for j in range(len(planets_rows)):\n",
    "            rows_in_cols[i].append(planets_rows[j][i])\n",
    "        random.shuffle(rows_in_cols[i])\n",
    "        \n",
    "    for j in range(len(planets_rows)):\n",
    "        for i in range(len(planets_rows[0])):\n",
    "            planets_rows[j][i] = rows_in_cols[i][j]\n",
    "            \n",
    "    col_idx = header.index(col_name)\n",
    "    val = planets_rows[row_idx][col_idx]\n",
    "    if val == '':\n",
    "        return None\n",
    "    if col_name in ['Controversial Flag']:\n",
    "        if val == '1':\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    elif col_name in ['Discovery Year']:\n",
    "        return int(val)\n",
    "    elif col_name in ['Orbital Period [days]', 'Planet Radius [Earth Radius]', 'Planet Mass [Earth Mass]', 'Orbit Semi-Major Axis [au]', 'Eccentricity', 'Equilibrium Temperature [K]', 'Insolation Flux [Earth Flux]']:\n",
    "        return float(val)\n",
    "    else:\n",
    "        return val\n",
    "\"\"\"\n",
    "\n",
    "nb = replace_with_false_function(nb, 'planet_cell', false_planet_cell)\n",
    "\n",
    "results[rubric_item] = parse_nb(run_nb(nb, os.path.join(directories[rubric_item], FILE)))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b26c9921",
   "metadata": {},
   "source": [
    "# END q12: `planet_cell` function is not used to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "516ed8a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"update public_tests\"\"\"\n",
    "\n",
    "gen_public_tests.gen_public_tests(os.path.join(directories[rubric_item], FILE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ab076a",
   "metadata": {},
   "source": [
    "### q12: `mapping_1_json` data structure is not used to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "cb1adbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"update readme\"\"\"\n",
    "\n",
    "rubric_item = \"q12: `mapping_1_json` data structure is not used to answer\"\n",
    "readme_text = \"\"\"You need to use the `mapping_1_json` data structure\n",
    "to access the `host_name` of the fifth star. The\n",
    "dictionary already contains the `host_name` data about\n",
    "all planets in `planets_1.csv`. Make sure to use the data\n",
    "from the `mapping_1_json` dictionary to answer the\n",
    "question. A modified version of the dictionary is\n",
    "provided right before the answer to this question.\n",
    "If your answer does not use this modified data\n",
    "structure, you may not have used the data\n",
    "correctly.\"\"\" \n",
    "\n",
    "write_readme(readme_text, os.path.join(directories[rubric_item], \"README.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "456c82bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_data(directories[rubric_item], 50)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e71adb51",
   "metadata": {},
   "source": [
    "# BEGIN q12: `mapping_1_json` data structure is not used to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "04f92524",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "rubric_item = \"q12: `mapping_1_json` data structure is not used to answer\"\n",
    "nb = new_clean_nb(read_nb(os.path.join(DIRECTORY, FILE)))\n",
    "nb = truncate_nb(nb, end=find_all_cell_indices(nb, \"code\", \"grader.check('q12')\")[-1])\n",
    "\n",
    "randomized_mapping_1_json = '''\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "\n",
    "def read_json(path):\n",
    "    with open(path, encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "mapping_1_json = read_json(os.path.join(\"data\", \"mapping_1.json\"))\n",
    "\n",
    "random.seed(0)\n",
    "mapping_1_json_keys = list(mapping_1_json.keys())\n",
    "mapping_1_json_values = list(mapping_1_json.values())\n",
    "random.shuffle(mapping_1_json_keys)\n",
    "random.shuffle(mapping_1_json_values)\n",
    "\n",
    "mapping_1_json = {}\n",
    "for i in range(len(mapping_1_json_keys)):\n",
    "    mapping_1_json[mapping_1_json_keys[i]] = mapping_1_json_values[i]\n",
    "'''\n",
    "nb = inject_code(nb, find_all_cell_indices(nb, \"markdown\", \"**Question 12:**\")[-1], randomized_mapping_1_json)\n",
    "\n",
    "results[rubric_item] = parse_nb(run_nb(nb, os.path.join(directories[rubric_item], FILE)))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4be3f18b",
   "metadata": {},
   "source": [
    "# END q12: `mapping_1_json` data structure is not used to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "ad875bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"update public_tests\"\"\"\n",
    "\n",
    "gen_public_tests.gen_public_tests(os.path.join(directories[rubric_item], FILE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97a0937",
   "metadata": {},
   "source": [
    "### q12: answer unnecessarily iterates over the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "c73fffde",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"update readme\"\"\"\n",
    "\n",
    "rubric_item = \"q12: answer unnecessarily iterates over the entire dataset\"\n",
    "readme_text = \"\"\"The test is checking whether you are unnecessarily\n",
    "iterating over the entire dataset in order to\n",
    "extract the data for the fifth Planet. Make sure you\n",
    "are only using the row index of the fifth planet to\n",
    "extract its data, without iterating over all the\n",
    "rows. There is code injected that tracks how\n",
    "many times the `planet_cell` function is called, so\n",
    "be careful to use the correct method for\n",
    "extracting the data.\"\"\" \n",
    "\n",
    "write_readme(readme_text, os.path.join(directories[rubric_item], \"README.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "d4ee357b",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_data(directories[rubric_item], 50)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dd7af5b3",
   "metadata": {},
   "source": [
    "# BEGIN q12: answer unnecessarily iterates over the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "db29a8f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "rubric_item = \"q12: answer unnecessarily iterates over the entire dataset\"\n",
    "nb = new_clean_nb(read_nb(os.path.join(DIRECTORY, FILE)))\n",
    "nb = truncate_nb(nb, end=find_all_cell_indices(nb, \"code\", \"grader.check('q12')\")[-1])\n",
    "\n",
    "false_planet_cell = \"\"\"\n",
    "import os\n",
    "import csv\n",
    "\n",
    "def process_csv(filename):\n",
    "    csv_file = open(filename, encoding='utf-8')\n",
    "    csv_reader = csv.reader(csv_file)\n",
    "    csv_data = list(csv_reader)\n",
    "    csv_file.close()\n",
    "    return csv_data\n",
    "\n",
    "planets_1_csv = process_csv(os.path.join(\"data\", \"planets_1.csv\"))\n",
    "planets_header = planets_1_csv[0]\n",
    "planets_1_rows = planets_1_csv[1:]\n",
    "\n",
    "hidden_count = 0\n",
    "\n",
    "def planet_cell(row_idx, col_name, planets_rows, header=planets_header):\n",
    "    global hidden_count\n",
    "    hidden_count += 1\n",
    "    col_idx = header.index(col_name)\n",
    "    val = planets_rows[row_idx][col_idx]\n",
    "    if val == '':\n",
    "        return None\n",
    "    if col_name in ['Controversial Flag']:\n",
    "        if val == '1':\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    elif col_name in ['Discovery Year']:\n",
    "        return int(val)\n",
    "    elif col_name in ['Orbital Period [days]', 'Planet Radius [Earth Radius]', 'Planet Mass [Earth Mass]', 'Orbit Semi-Major Axis [au]', 'Eccentricity', 'Equilibrium Temperature [K]', 'Insolation Flux [Earth Flux]']:\n",
    "        return float(val)\n",
    "    else:\n",
    "        return val\"\"\"\n",
    "nb = replace_with_false_function(nb, 'planet_cell', false_planet_cell)\n",
    "\n",
    "nb = inject_code(nb, find_all_cell_indices(nb, \"markdown\", \"**Question 12:**\")[-1], 'hidden_count = 0')\n",
    "\n",
    "code = \"\"\"\n",
    "if hidden_count <= 2 + len(planets_header):\n",
    "    test_output = 'q12 results: All test cases passed!'\"\"\"\n",
    "nb = inject_code(nb, len(nb['cells']), get_test_text('q12', code))\n",
    "\n",
    "results[rubric_item] = parse_nb(run_nb(nb, os.path.join(directories[rubric_item], FILE)))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d64c8c6f",
   "metadata": {},
   "source": [
    "# END q12: answer unnecessarily iterates over the entire dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adeb887",
   "metadata": {},
   "source": [
    "### q12: paths are hardcoded using slashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "f2ee07c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"update readme\"\"\"\n",
    "\n",
    "rubric_item = \"q12: paths are hardcoded using slashes\"\n",
    "readme_text = \"\"\"The test is checking for the\n",
    "robustness of your code across different operating\n",
    "systems. If paths have been hardcoded using \"/\" or\n",
    "\"\\\\\\\\\", the code may fail on some systems. The code\n",
    "injection is carrying out alterations to evaluate\n",
    "whether your code can function correctly in\n",
    "different operating system environments.\n",
    "Therefore, ensure that you're using `os.path.join`\n",
    "instead of hardcoding slashes.\"\"\" \n",
    "\n",
    "write_readme(readme_text, os.path.join(directories[rubric_item], \"README.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "0725fd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_data(directories[rubric_item], 50)\n",
    "for i in range(1, 6):\n",
    "    file_copy(os.path.join(directories[rubric_item], 'data', 'stars_%d.csv' % (i)), os.path.join(directories[rubric_item], 'data&stars_%d.csv' % (i)))\n",
    "    file_copy(os.path.join(directories[rubric_item], 'data', 'planets_%d.csv' % (i)), os.path.join(directories[rubric_item], 'data&planets_%d.csv' % (i)))\n",
    "    file_copy(os.path.join(directories[rubric_item], 'data', 'mapping_%d.json' % (i)), os.path.join(directories[rubric_item], 'data&mapping_%d.json' % (i)))\n",
    "random_data(directories[rubric_item], 50)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f3bf40db",
   "metadata": {},
   "source": [
    "# BEGIN q12: paths are hardcoded using slashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "d2dcd048",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "rubric_item = \"q12: paths are hardcoded using slashes\"\n",
    "nb = new_clean_nb(read_nb(os.path.join(DIRECTORY, FILE)))\n",
    "nb = truncate_nb(nb, end=find_all_cell_indices(nb, \"code\", \"grader.check('q12')\")[-1])\n",
    "\n",
    "path_redefine = '''\n",
    "import os\n",
    "\n",
    "def new_join(*paths):\n",
    "    return '&'.join(paths)\n",
    "    \n",
    "def new_basename(path):\n",
    "    return path.split('&')[-1]\n",
    "    \n",
    "def new_dirname(path):\n",
    "    return '&'.join(path.split('&')[:-1])\n",
    "    \n",
    "def new_split(path):\n",
    "    return tuple(['&'.join(path.split('&')[:-1]), path.split('&')[-1]])'''\n",
    "\n",
    "nb = inject_code(nb, find_all_cell_indices(nb, \"markdown\", \"**Question 1:**\")[-1], path_redefine)\n",
    "nb = replace_code(nb, 'os.path.join', 'new_join')\n",
    "nb = replace_code(nb, 'os.path.basename', 'new_basename')\n",
    "nb = replace_code(nb, 'os.path.dirname', 'new_dirname')\n",
    "nb = replace_code(nb, 'os.path.split', 'new_split')\n",
    "nb = replace_code(nb, 'os.path.sep', \"'&'\")\n",
    "\n",
    "results[rubric_item] = parse_nb(run_nb(nb, os.path.join(directories[rubric_item], FILE)))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e8c5119e",
   "metadata": {},
   "source": [
    "# END q12: paths are hardcoded using slashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "c49531ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"update public_tests\"\"\"\n",
    "\n",
    "gen_public_tests.gen_public_tests(os.path.join(directories[rubric_item], FILE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9694d5c2",
   "metadata": {},
   "source": [
    "### get_planets: function logic is incorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "6f5fde98",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"update readme\"\"\"\n",
    "\n",
    "rubric_item = \"get_planets: function logic is incorrect\"\n",
    "readme_text = \"\"\"This test is checking if your `get_planets` function\n",
    "is implemented correctly. Your function should\n",
    "take a planet CSV file path and a mapping JSON \n",
    "file path as input, read the data from both files,\n",
    "and return a list containing `Planet` objects\n",
    "containing all the details of the planets in\n",
    "the CSV file. To test your function, it is being\n",
    "called with different inputs and the output is\n",
    "compared to the expected output. Make sure your\n",
    "function returns the correct list for all\n",
    "possible inputs.\"\"\" \n",
    "\n",
    "write_readme(readme_text, os.path.join(directories[rubric_item], \"README.txt\"))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1035f056",
   "metadata": {},
   "source": [
    "# BEGIN get_planets: function logic is incorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "cdb25621",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "rubric_item = \"get_planets: function logic is incorrect\"\n",
    "nb = new_clean_nb(read_nb(os.path.join(DIRECTORY, FILE)))\n",
    "nb = truncate_nb(nb, end=find_all_cell_indices(nb, \"code\", \"grader.check('get_planets')\")[-1])\n",
    "\n",
    "var_inputs_code = \"\"\"\n",
    "import os\n",
    "var_inputs = []\n",
    "for i in range(1, 6):\n",
    "    var_inputs.append((os.path.join('data', 'planets_%d.csv' % (i)), os.path.join('data', 'mapping_%d.json' % (i))))\n",
    "\"\"\"\n",
    "nb = inject_function_logic_check(nb, 'get_planets', var_inputs_code, 'TEXT_FORMAT_ORDERED_LIST')\n",
    "\n",
    "results[rubric_item] = parse_nb(run_nb(nb, os.path.join(directories[rubric_item], FILE)))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "88dbfefb",
   "metadata": {},
   "source": [
    "# END get_planets: function logic is incorrect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8d2295",
   "metadata": {},
   "source": [
    "### get_planets: hardcoded the name of directory inside the function instead of passing it as a part of the input argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "90bf16c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"update readme\"\"\"\n",
    "\n",
    "rubric_item = \"get_planets: hardcoded the name of directory inside the function instead of passing it as a part of the input argument\"\n",
    "readme_text = \"\"\"The test is checking if you have hardcoded the\n",
    "name of the directory in the `get_planets` function\n",
    "instead of passing it as a part of the input\n",
    "arguments. The test injects code that calls the\n",
    "function on files that are not inside the `data`\n",
    "directory. If your function is not able to read\n",
    "these files correctly, it suggests that the\n",
    "directories may be hardcoded in your function.\n",
    "Make sure to pass the directory as a part of the\n",
    "input argument to make your function more\n",
    "flexible.\"\"\" \n",
    "\n",
    "write_readme(readme_text, os.path.join(directories[rubric_item], \"README.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "2d5697cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(directories[rubric_item], 'false_data')):\n",
    "    shutil.rmtree(os.path.join(directories[rubric_item], 'false_data'))\n",
    "os.mkdir(os.path.join(directories[rubric_item], 'false_data'))\n",
    "file_copy(os.path.join(directories[rubric_item], 'data', 'planets_2.csv'), os.path.join(directories[rubric_item], 'false_data', 'planets_1.csv'))\n",
    "file_copy(os.path.join(directories[rubric_item], 'data', 'mapping_2.json'), os.path.join(directories[rubric_item], 'false_data', 'mapping_1.json'))\n",
    "file_copy(os.path.join(directories[rubric_item], 'data', 'planets_3.csv'), os.path.join(directories[rubric_item], 'false_data', 'planets_2.csv'))\n",
    "file_copy(os.path.join(directories[rubric_item], 'data', 'mapping_3.json'), os.path.join(directories[rubric_item], 'new_mapping.json'))\n",
    "file_copy(os.path.join(directories[rubric_item], 'data', 'planets_1.csv'), os.path.join(directories[rubric_item], 'new_planets.csv'))\n",
    "file_copy(os.path.join(directories[rubric_item], 'data', 'mapping_1.json'), os.path.join(directories[rubric_item], 'false_data', 'mapping_2.json'))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "218acca6",
   "metadata": {},
   "source": [
    "# BEGIN get_planets: hardcoded the name of directory inside the function instead of passing it as a part of the input argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "79177e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "rubric_item = \"get_planets: hardcoded the name of directory inside the function instead of passing it as a part of the input argument\"\n",
    "nb = new_clean_nb(read_nb(os.path.join(DIRECTORY, FILE)))\n",
    "nb = truncate_nb(nb, end=find_all_cell_indices(nb, \"code\", \"grader.check('get_planets')\")[-1])\n",
    "\n",
    "\n",
    "var_inputs_code = \"\"\"\n",
    "import os\n",
    "var_inputs = [(os.path.join('false_data', 'planets_1.csv'), os.path.join('false_data', 'mapping_1.json')),\n",
    "                (os.path.join('false_data', 'planets_2.csv'), 'new_mapping.json'),\n",
    "                ('new_planets.csv', os.path.join('false_data', 'mapping_2.json'))]\n",
    "\"\"\"\n",
    "nb = inject_function_logic_check(nb, 'get_planets', var_inputs_code, 'TEXT_FORMAT_ORDERED_LIST')\n",
    "\n",
    "results[rubric_item] = parse_nb(run_nb(nb, os.path.join(directories[rubric_item], FILE)))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "94695d9a",
   "metadata": {},
   "source": [
    "# END get_planets: hardcoded the name of directory inside the function instead of passing it as a part of the input argument"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945cae92",
   "metadata": {},
   "source": [
    "### get_planets: function is called more than twice with the same dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "b5cba269",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"update readme\"\"\"\n",
    "\n",
    "rubric_item = \"get_planets: function is called more than twice with the same dataset\"\n",
    "readme_text = \"\"\"You are tasked with writing a function that reads\n",
    "data from a CSV file and a JSON file and returns a list\n",
    "containing detailsstar of planets. However, you\n",
    "need to make sure that you do not read the same\n",
    "file multiple times, as it is time-consuming.\n",
    "Instead, you should store the data in a variable\n",
    "after reading it once, and access the variable in\n",
    "future calls. Be aware that there may be injected\n",
    "code that tracks how many times each file is\n",
    "provided as input. Make sure your function is not\n",
    "called on any file more than twice.\"\"\" \n",
    "\n",
    "write_readme(readme_text, os.path.join(directories[rubric_item], \"README.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "8d3bf690",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_data(directories[rubric_item], 50)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fb0f1d91",
   "metadata": {},
   "source": [
    "# BEGIN get_planets: function is called more than twice with the same dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "e6e1f875",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "rubric_item = \"get_planets: function is called more than twice with the same dataset\"\n",
    "nb = new_clean_nb(read_nb(os.path.join(DIRECTORY, FILE)))\n",
    "\n",
    "false_get_planets = \"\"\"\n",
    "import os\n",
    "import csv\n",
    "import json\n",
    "\n",
    "def process_csv(filename):\n",
    "    csv_file = open(filename, encoding='utf-8')\n",
    "    csv_reader = csv.reader(csv_file)\n",
    "    csv_data = list(csv_reader)\n",
    "    csv_file.close()\n",
    "    return csv_data\n",
    "\n",
    "def read_json(path):\n",
    "    with open(path, encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "hidden_count = {}\n",
    "\n",
    "def get_planets(planet_file, mapping_file):\n",
    "    global hidden_count\n",
    "    _files = (os.path.basename(planet_file), os.path.basename(mapping_file))\n",
    "    if _files not in hidden_count:\n",
    "        hidden_count[_files] = 0\n",
    "    hidden_count[_files] += 1\n",
    "    if 'data' not in planet_file:\n",
    "        planet_file = os.path.join('data', planet_file)\n",
    "    if 'data' not in mapping_file:\n",
    "        mapping_file = os.path.join('data', mapping_file)\n",
    "    planets = []\n",
    "    try:\n",
    "        mapping_dict = read_json(mapping_file)\n",
    "    except json.JSONDecodeError:\n",
    "        return []\n",
    "    planets_csv = process_csv(planet_file)\n",
    "    planets_header = planets_csv[0]\n",
    "    planets_rows = planets_csv[1:]\n",
    "    for row_idx in range(len(planets_rows)):\n",
    "        try:\n",
    "            planet_name = planet_cell(row_idx, 'Planet Name', planets_rows)\n",
    "            host_name = mapping_dict[planet_name]\n",
    "            discovery_method = planet_cell(row_idx, 'Discovery Method', planets_rows)\n",
    "            discovery_year = planet_cell(row_idx, 'Discovery Year', planets_rows)\n",
    "            controversial_flag = planet_cell(row_idx, 'Controversial Flag', planets_rows)\n",
    "            orbital_period = planet_cell(row_idx, 'Orbital Period [days]', planets_rows)\n",
    "            planet_radius = planet_cell(row_idx, 'Planet Radius [Earth Radius]', planets_rows)\n",
    "            planet_mass = planet_cell(row_idx, 'Planet Mass [Earth Mass]', planets_rows)\n",
    "            semi_major_radius = planet_cell(row_idx, 'Orbit Semi-Major Axis [au]', planets_rows)\n",
    "            eccentricity = planet_cell(row_idx, 'Eccentricity', planets_rows)\n",
    "            equilibrium_temperature = planet_cell(row_idx, 'Equilibrium Temperature [K]', planets_rows)\n",
    "            insolation_flux = planet_cell(row_idx, 'Insolation Flux [Earth Flux]', planets_rows)\n",
    "            planet = Planet(planet_name, host_name, discovery_method, discovery_year, controversial_flag, orbital_period, planet_radius, planet_mass, semi_major_radius, eccentricity, equilibrium_temperature, insolation_flux)\n",
    "            planets.append(planet)\n",
    "        except IndexError:\n",
    "            continue\n",
    "        except ValueError:\n",
    "            continue\n",
    "        except KeyError:\n",
    "            continue\n",
    "    return planets\"\"\"\n",
    "nb = replace_with_false_function(nb, 'get_planets', false_get_planets)\n",
    "\n",
    "code = \"\"\"\n",
    "if len(hidden_count) > 0 and max(hidden_count.values()) <= 2:\n",
    "    test_output = 'get_planets results: All test cases passed!'\"\"\"\n",
    "nb = inject_code(nb, len(nb['cells']), get_test_text('get_planets', code))\n",
    "\n",
    "results[rubric_item] = parse_nb(run_nb(nb, os.path.join(directories[rubric_item], FILE)))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "136df056",
   "metadata": {},
   "source": [
    "# END get_planets: function is called more than twice with the same dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835ba100",
   "metadata": {},
   "source": [
    "### get_planets: `planet_cell` function is not used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "1b1442f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"update readme\"\"\"\n",
    "\n",
    "rubric_item = \"get_planets: `planet_cell` function is not used\"\n",
    "readme_text = \"\"\"This test is checking if you are using the\n",
    "`planet_cell` function to define this function. A\n",
    "modification has been made to the `planet_cell`\n",
    "function so that it reads from a different\n",
    "dataset. If the output of this function does not change\n",
    "accordingly, it suggests that you did not use the\n",
    "`planet_cell` function. Remember to utilize the\n",
    "provided functions instead of reading the data\n",
    "directly from the csv again.\"\"\" \n",
    "\n",
    "write_readme(readme_text, os.path.join(directories[rubric_item], \"README.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "3a3a67f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_data(directories[rubric_item], 50)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5c64a4e3",
   "metadata": {},
   "source": [
    "# BEGIN get_planets: `planet_cell` function is not used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "4e4ad817",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "rubric_item = \"get_planets: `planet_cell` function is not used\"\n",
    "nb = new_clean_nb(read_nb(os.path.join(DIRECTORY, FILE)))\n",
    "nb = truncate_nb(nb, end=find_all_cell_indices(nb, \"code\", \"grader.check('get_planets')\")[-1])\n",
    "\n",
    "var_inputs_code = \"\"\"\n",
    "import os\n",
    "var_inputs = [(os.path.join('data', 'planets_1.csv'), os.path.join('data', 'mapping_1.json'))]\n",
    "\"\"\"\n",
    "nb = inject_function_logic_check(nb, 'get_planets', var_inputs_code, 'TEXT_FORMAT_ORDERED_LIST')\n",
    "\n",
    "false_planet_cell = \"\"\"\n",
    "import os\n",
    "import csv\n",
    "import copy\n",
    "import random\n",
    "\n",
    "def process_csv(filename):\n",
    "    csv_file = open(filename, encoding='utf-8')\n",
    "    csv_reader = csv.reader(csv_file)\n",
    "    csv_data = list(csv_reader)\n",
    "    csv_file.close()\n",
    "    return csv_data\n",
    "    \n",
    "planets_1_csv = process_csv(os.path.join('data', 'planets_1.csv'))\n",
    "planets_header = planets_1_csv[0]\n",
    "planets_1_rows = planets_1_csv[1:]\n",
    "\n",
    "def planet_cell(row_idx, col_name, planets_rows, header=planets_header):\n",
    "    planets_rows = copy.deepcopy(planets_rows)\n",
    "    random.seed(0)\n",
    "    rows_in_cols = {}\n",
    "    for i in range(len(planets_rows[0])):\n",
    "        rows_in_cols[i] = []\n",
    "        for j in range(len(planets_rows)):\n",
    "            rows_in_cols[i].append(planets_rows[j][i])\n",
    "        random.shuffle(rows_in_cols[i])\n",
    "        \n",
    "    for j in range(len(planets_rows)):\n",
    "        for i in range(len(planets_rows[0])):\n",
    "            planets_rows[j][i] = rows_in_cols[i][j]\n",
    "            \n",
    "    col_idx = header.index(col_name)\n",
    "    val = planets_rows[row_idx][col_idx]\n",
    "    if val == '':\n",
    "        return None\n",
    "    if col_name in ['Controversial Flag']:\n",
    "        if val == '1':\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    elif col_name in ['Discovery Year']:\n",
    "        return int(val)\n",
    "    elif col_name in ['Orbital Period [days]', 'Planet Radius [Earth Radius]', 'Planet Mass [Earth Mass]', 'Orbit Semi-Major Axis [au]', 'Eccentricity', 'Equilibrium Temperature [K]', 'Insolation Flux [Earth Flux]']:\n",
    "        return float(val)\n",
    "    else:\n",
    "        return val\n",
    "\"\"\"\n",
    "nb = replace_with_false_function(nb, 'planet_cell', false_planet_cell)\n",
    "\n",
    "results[rubric_item] = parse_nb(run_nb(nb, os.path.join(directories[rubric_item], FILE)))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ca3483b3",
   "metadata": {},
   "source": [
    "# END get_planets: `planet_cell` function is not used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f220a202",
   "metadata": {},
   "source": [
    "### get_planets: function is defined more than once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "fc248ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"update readme\"\"\"\n",
    "\n",
    "rubric_item = \"get_planets: function is defined more than once\"\n",
    "readme_text = \"\"\"This test is designed to ensure that your function\n",
    "'get_planets' is defined only once in your notebook.\n",
    "Having multiple definitions can lead to unexpected\n",
    "results if notebook cells are executed out of\n",
    "order. The test reads through your code and counts\n",
    "definitions of the function 'get_planets'. It may\n",
    "fail if more than one definition is found. Please\n",
    "ensure your function is defined only once.\"\"\" \n",
    "\n",
    "write_readme(readme_text, os.path.join(directories[rubric_item], \"README.txt\"))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "754cacf5",
   "metadata": {},
   "source": [
    "# BEGIN get_planets: function is defined more than once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "ff3ef5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rubric_item = \"get_planets: function is defined more than once\"\n",
    "nb = new_clean_nb(read_nb(os.path.join(DIRECTORY, FILE)))\n",
    "\n",
    "results[rubric_item] = {}\n",
    "if count_defns(nb, 'get_planets') != 1:\n",
    "    results[rubric_item][rubric_item.split(\":\")[0]] = \"function is defined more than once\"\n",
    "else:\n",
    "    results[rubric_item][rubric_item.split(\":\")[0]] = \"All test cases passed!\""
   ]
  },
  {
   "cell_type": "raw",
   "id": "2df3405f",
   "metadata": {},
   "source": [
    "# END get_planets: function is defined more than once"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660619fb",
   "metadata": {},
   "source": [
    "### q13: `get_planets` function is not used to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "ece6b29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"update readme\"\"\"\n",
    "\n",
    "rubric_item = \"q13: `get_planets` function is not used to answer\"\n",
    "readme_text = \"\"\"This test is checking if you are using the\n",
    "`get_planets` function to answer the question. A\n",
    "modification has been made to the `get_planets`\n",
    "function so that it reads from different\n",
    "files. If your answer does not change\n",
    "accordingly, it suggests that you did not use the\n",
    "`get_planets` function. Remember to utilize the\n",
    "provided functions instead of reading the data\n",
    "directly from the csv and json files again.\"\"\" \n",
    "\n",
    "write_readme(readme_text, os.path.join(directories[rubric_item], \"README.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "926baad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_data(directories[rubric_item], 50)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "168180f0",
   "metadata": {},
   "source": [
    "# BEGIN q13: `get_planets` function is not used to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "2d1a8a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "rubric_item = \"q13: `get_planets` function is not used to answer\"\n",
    "nb = new_clean_nb(read_nb(os.path.join(DIRECTORY, FILE)))\n",
    "nb = truncate_nb(nb, end=find_all_cell_indices(nb, \"code\", \"grader.check('q13')\")[-1])\n",
    "\n",
    "false_get_planets = \"\"\"\n",
    "import os\n",
    "import csv\n",
    "import json\n",
    "import random\n",
    "\n",
    "def process_csv(filename):\n",
    "    csv_file = open(filename, encoding='utf-8')\n",
    "    csv_reader = csv.reader(csv_file)\n",
    "    csv_data = list(csv_reader)\n",
    "    csv_file.close()\n",
    "    return csv_data\n",
    "\n",
    "def read_json(path):\n",
    "    with open(path, encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def get_planets(planet_file, mapping_file):\n",
    "    if 'data' not in planet_file:\n",
    "        planet_file = os.path.join('data', planet_file)\n",
    "    if 'data' not in mapping_file:\n",
    "        mapping_file = os.path.join('data', mapping_file)\n",
    "    planets = []\n",
    "    try:\n",
    "        mapping_dict = read_json(mapping_file)\n",
    "    except json.JSONDecodeError:\n",
    "        return []\n",
    "    planets_csv = process_csv(planet_file)\n",
    "    planets_header = planets_csv[0]\n",
    "    planets_rows = planets_csv[1:]\n",
    "    random.seed(0)\n",
    "    rows_in_cols = {}\n",
    "    for i in range(len(planets_rows[0])):\n",
    "        rows_in_cols[i] = []\n",
    "        for j in range(len(planets_rows)):\n",
    "            rows_in_cols[i].append(planets_rows[j][i])\n",
    "        random.shuffle(rows_in_cols[i])\n",
    "        \n",
    "    for j in range(len(planets_rows)):\n",
    "        for i in range(len(planets_rows[0])):\n",
    "            planets_rows[j][i] = rows_in_cols[i][j]\n",
    "            \n",
    "    mapping_dict_keys = list(mapping_dict.keys())\n",
    "    mapping_dict_values = list(mapping_dict.values())\n",
    "    random.shuffle(mapping_dict_keys)\n",
    "    random.shuffle(mapping_dict_values)\n",
    "    mapping_dict = {}\n",
    "    for i in range(len(mapping_dict_keys)):\n",
    "        mapping_dict[mapping_dict_keys[i]] = mapping_dict_values[i]\n",
    "            \n",
    "    for row_idx in range(len(planets_rows)):\n",
    "        try:\n",
    "            planet_name = planet_cell(row_idx, 'Planet Name', planets_rows)\n",
    "            host_name = mapping_dict[planet_name]\n",
    "            discovery_method = planet_cell(row_idx, 'Discovery Method', planets_rows)\n",
    "            discovery_year = planet_cell(row_idx, 'Discovery Year', planets_rows)\n",
    "            controversial_flag = planet_cell(row_idx, 'Controversial Flag', planets_rows)\n",
    "            orbital_period = planet_cell(row_idx, 'Orbital Period [days]', planets_rows)\n",
    "            planet_radius = planet_cell(row_idx, 'Planet Radius [Earth Radius]', planets_rows)\n",
    "            planet_mass = planet_cell(row_idx, 'Planet Mass [Earth Mass]', planets_rows)\n",
    "            semi_major_radius = planet_cell(row_idx, 'Orbit Semi-Major Axis [au]', planets_rows)\n",
    "            eccentricity = planet_cell(row_idx, 'Eccentricity', planets_rows)\n",
    "            equilibrium_temperature = planet_cell(row_idx, 'Equilibrium Temperature [K]', planets_rows)\n",
    "            insolation_flux = planet_cell(row_idx, 'Insolation Flux [Earth Flux]', planets_rows)\n",
    "            planet = Planet(planet_name, host_name, discovery_method, discovery_year, controversial_flag, orbital_period, planet_radius, planet_mass, semi_major_radius, eccentricity, equilibrium_temperature, insolation_flux)\n",
    "            planets.append(planet)\n",
    "        except IndexError:\n",
    "            continue\n",
    "        except ValueError:\n",
    "            continue\n",
    "        except KeyError:\n",
    "            continue\n",
    "    return planets\"\"\"\n",
    "nb = replace_with_false_function(nb, 'get_planets', false_get_planets)\n",
    "\n",
    "results[rubric_item] = parse_nb(run_nb(nb, os.path.join(directories[rubric_item], FILE)))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "626a9296",
   "metadata": {},
   "source": [
    "# END q13: `get_planets` function is not used to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "2383c2af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"update public_tests\"\"\"\n",
    "\n",
    "gen_public_tests.gen_public_tests(os.path.join(directories[rubric_item], FILE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffefb81",
   "metadata": {},
   "source": [
    "### q13: paths are hardcoded using slashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "7afa24ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"update readme\"\"\"\n",
    "\n",
    "rubric_item = \"q13: paths are hardcoded using slashes\"\n",
    "readme_text = \"\"\"The test is checking for the\n",
    "robustness of your code across different operating\n",
    "systems. If paths have been hardcoded using \"/\" or\n",
    "\"\\\\\\\\\", the code may fail on some systems. The code\n",
    "injection is carrying out alterations to evaluate\n",
    "whether your code can function correctly in\n",
    "different operating system environments.\n",
    "Therefore, ensure that you're using `os.path.join`\n",
    "instead of hardcoding slashes.\"\"\" \n",
    "\n",
    "write_readme(readme_text, os.path.join(directories[rubric_item], \"README.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "f7a3de06",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_data(directories[rubric_item], 50)\n",
    "for i in range(1, 6):\n",
    "    file_copy(os.path.join(directories[rubric_item], 'data', 'stars_%d.csv' % (i)), os.path.join(directories[rubric_item], 'data&stars_%d.csv' % (i)))\n",
    "    file_copy(os.path.join(directories[rubric_item], 'data', 'planets_%d.csv' % (i)), os.path.join(directories[rubric_item], 'data&planets_%d.csv' % (i)))\n",
    "    file_copy(os.path.join(directories[rubric_item], 'data', 'mapping_%d.json' % (i)), os.path.join(directories[rubric_item], 'data&mapping_%d.json' % (i)))\n",
    "random_data(directories[rubric_item], 50)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1a5c342d",
   "metadata": {},
   "source": [
    "# BEGIN q13: paths are hardcoded using slashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "67a7a0e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "rubric_item = \"q13: paths are hardcoded using slashes\"\n",
    "nb = new_clean_nb(read_nb(os.path.join(DIRECTORY, FILE)))\n",
    "nb = truncate_nb(nb, end=find_all_cell_indices(nb, \"code\", \"grader.check('q13')\")[-1])\n",
    "\n",
    "path_redefine = '''\n",
    "import os\n",
    "\n",
    "def new_join(*paths):\n",
    "    return '&'.join(paths)\n",
    "    \n",
    "def new_basename(path):\n",
    "    return path.split('&')[-1]\n",
    "    \n",
    "def new_dirname(path):\n",
    "    return '&'.join(path.split('&')[:-1])\n",
    "    \n",
    "def new_split(path):\n",
    "    return tuple(['&'.join(path.split('&')[:-1]), path.split('&')[-1]])'''\n",
    "\n",
    "nb = inject_code(nb, find_all_cell_indices(nb, \"markdown\", \"**Question 1:**\")[-1], path_redefine)\n",
    "nb = replace_code(nb, 'os.path.join', 'new_join')\n",
    "nb = replace_code(nb, 'os.path.basename', 'new_basename')\n",
    "nb = replace_code(nb, 'os.path.dirname', 'new_dirname')\n",
    "nb = replace_code(nb, 'os.path.split', 'new_split')\n",
    "nb = replace_code(nb, 'os.path.sep', \"'&'\")\n",
    "\n",
    "results[rubric_item] = parse_nb(run_nb(nb, os.path.join(directories[rubric_item], FILE)))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9dd293fc",
   "metadata": {},
   "source": [
    "# END q13: paths are hardcoded using slashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "1896d5f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"update public_tests\"\"\"\n",
    "\n",
    "gen_public_tests.gen_public_tests(os.path.join(directories[rubric_item], FILE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944694e3",
   "metadata": {},
   "source": [
    "### q14: incorrect logic is used to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "50266585",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"update readme\"\"\"\n",
    "\n",
    "rubric_item = \"q14: incorrect logic is used to answer\"\n",
    "readme_text = \"\"\"The code is attempting to find the Planet objects\n",
    "whose controversial_flag attribute is True in a\n",
    "given list. To test if your code is correctly\n",
    "identifying these planets, we have modified the\n",
    "dataset completely. Make sure your code is not\n",
    "just relying on specific values in the original\n",
    "dataset, but instead is correctly identifying\n",
    "planets with the controversial_flag set to True in\n",
    "any dataset.\"\"\" \n",
    "\n",
    "write_readme(readme_text, os.path.join(directories[rubric_item], \"README.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "d7ca76c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_data(path):\n",
    "    # Read the planets dataframes\n",
    "    f = open(os.path.join(path, \"data\", 'planets_2.csv'), encoding='utf-8')\n",
    "    data = list(csv.reader(f))\n",
    "    f.close()\n",
    "    \n",
    "    for i in range(1, len(data)):\n",
    "        row = data[i]\n",
    "        row[data[0].index('Controversial Flag')] = ['0', '1', ''][i%3]\n",
    "    \n",
    "    f = open(os.path.join(path, \"data\", 'planets_2.csv'), 'w', encoding='utf-8', newline='')\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(data)\n",
    "    \n",
    "random_data(directories[rubric_item], 50)\n",
    "modify_data(directories[rubric_item])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7ffa615b",
   "metadata": {},
   "source": [
    "# BEGIN q14: incorrect logic is used to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "243b82d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "rubric_item = \"q14: incorrect logic is used to answer\"\n",
    "nb = new_clean_nb(read_nb(os.path.join(DIRECTORY, FILE)))\n",
    "nb = truncate_nb(nb, end=find_all_cell_indices(nb, \"code\", \"grader.check('q14')\")[-1])\n",
    "\n",
    "results[rubric_item] = parse_nb(run_nb(nb, os.path.join(directories[rubric_item], FILE)))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "980a9726",
   "metadata": {},
   "source": [
    "# END q14: incorrect logic is used to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "d20d9b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"update public_tests\"\"\"\n",
    "\n",
    "gen_public_tests.gen_public_tests(os.path.join(directories[rubric_item], FILE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e0efff",
   "metadata": {},
   "source": [
    "### q14: `get_planets` function is not used to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "542be963",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"update readme\"\"\"\n",
    "\n",
    "rubric_item = \"q14: `get_planets` function is not used to answer\"\n",
    "readme_text = \"\"\"This test is checking if you are using the\n",
    "`get_planets` function to answer the question. A\n",
    "modification has been made to the `get_planets`\n",
    "function so that it reads from different\n",
    "files. If your answer does not change\n",
    "accordingly, it suggests that you did not use the\n",
    "`get_planets` function. Remember to utilize the\n",
    "provided functions instead of reading the data\n",
    "directly from the csv and json files again.\"\"\" \n",
    "\n",
    "write_readme(readme_text, os.path.join(directories[rubric_item], \"README.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "8a4a6bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_data(directories[rubric_item], 50)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ab3bc3e7",
   "metadata": {},
   "source": [
    "# BEGIN q14: `get_planets` function is not used to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "6f6a0bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "rubric_item = \"q14: `get_planets` function is not used to answer\"\n",
    "nb = new_clean_nb(read_nb(os.path.join(DIRECTORY, FILE)))\n",
    "nb = truncate_nb(nb, end=find_all_cell_indices(nb, \"code\", \"grader.check('q14')\")[-1])\n",
    "\n",
    "false_get_planets = \"\"\"\n",
    "import os\n",
    "import csv\n",
    "import json\n",
    "import random\n",
    "\n",
    "def process_csv(filename):\n",
    "    csv_file = open(filename, encoding='utf-8')\n",
    "    csv_reader = csv.reader(csv_file)\n",
    "    csv_data = list(csv_reader)\n",
    "    csv_file.close()\n",
    "    return csv_data\n",
    "\n",
    "def read_json(path):\n",
    "    with open(path, encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def get_planets(planet_file, mapping_file):\n",
    "    if 'data' not in planet_file:\n",
    "        planet_file = os.path.join('data', planet_file)\n",
    "    if 'data' not in mapping_file:\n",
    "        mapping_file = os.path.join('data', mapping_file)\n",
    "    planets = []\n",
    "    try:\n",
    "        mapping_dict = read_json(mapping_file)\n",
    "    except json.JSONDecodeError:\n",
    "        return []\n",
    "    planets_csv = process_csv(planet_file)\n",
    "    planets_header = planets_csv[0]\n",
    "    planets_rows = planets_csv[1:]\n",
    "    random.seed(0)\n",
    "    rows_in_cols = {}\n",
    "    for i in range(len(planets_rows[0])):\n",
    "        rows_in_cols[i] = []\n",
    "        for j in range(len(planets_rows)):\n",
    "            rows_in_cols[i].append(planets_rows[j][i])\n",
    "        random.shuffle(rows_in_cols[i])\n",
    "        \n",
    "    for j in range(len(planets_rows)):\n",
    "        for i in range(len(planets_rows[0])):\n",
    "            planets_rows[j][i] = rows_in_cols[i][j]\n",
    "            \n",
    "    mapping_dict_keys = list(mapping_dict.keys())\n",
    "    mapping_dict_values = list(mapping_dict.values())\n",
    "    random.shuffle(mapping_dict_keys)\n",
    "    random.shuffle(mapping_dict_values)\n",
    "    mapping_dict = {}\n",
    "    for i in range(len(mapping_dict_keys)):\n",
    "        mapping_dict[mapping_dict_keys[i]] = mapping_dict_values[i]\n",
    "            \n",
    "    for row_idx in range(len(planets_rows)):\n",
    "        try:\n",
    "            planet_name = planet_cell(row_idx, 'Planet Name', planets_rows)\n",
    "            host_name = mapping_dict[planet_name]\n",
    "            discovery_method = planet_cell(row_idx, 'Discovery Method', planets_rows)\n",
    "            discovery_year = planet_cell(row_idx, 'Discovery Year', planets_rows)\n",
    "            controversial_flag = planet_cell(row_idx, 'Controversial Flag', planets_rows)\n",
    "            orbital_period = planet_cell(row_idx, 'Orbital Period [days]', planets_rows)\n",
    "            planet_radius = planet_cell(row_idx, 'Planet Radius [Earth Radius]', planets_rows)\n",
    "            planet_mass = planet_cell(row_idx, 'Planet Mass [Earth Mass]', planets_rows)\n",
    "            semi_major_radius = planet_cell(row_idx, 'Orbit Semi-Major Axis [au]', planets_rows)\n",
    "            eccentricity = planet_cell(row_idx, 'Eccentricity', planets_rows)\n",
    "            equilibrium_temperature = planet_cell(row_idx, 'Equilibrium Temperature [K]', planets_rows)\n",
    "            insolation_flux = planet_cell(row_idx, 'Insolation Flux [Earth Flux]', planets_rows)\n",
    "            planet = Planet(planet_name, host_name, discovery_method, discovery_year, controversial_flag, orbital_period, planet_radius, planet_mass, semi_major_radius, eccentricity, equilibrium_temperature, insolation_flux)\n",
    "            planets.append(planet)\n",
    "        except IndexError:\n",
    "            continue\n",
    "        except ValueError:\n",
    "            continue\n",
    "        except KeyError:\n",
    "            continue\n",
    "    return planets\"\"\"\n",
    "nb = replace_with_false_function(nb, 'get_planets', false_get_planets)\n",
    "\n",
    "results[rubric_item] = parse_nb(run_nb(nb, os.path.join(directories[rubric_item], FILE)))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d3fc0e8c",
   "metadata": {},
   "source": [
    "# END q14: `get_planets` function is not used to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "8bb27a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"update public_tests\"\"\"\n",
    "\n",
    "gen_public_tests.gen_public_tests(os.path.join(directories[rubric_item], FILE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd4e3c7",
   "metadata": {},
   "source": [
    "### q14: paths are hardcoded using slashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "a2d1ae8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"update readme\"\"\"\n",
    "\n",
    "rubric_item = \"q14: paths are hardcoded using slashes\"\n",
    "readme_text = \"\"\"The test is checking for the\n",
    "robustness of your code across different operating\n",
    "systems. If paths have been hardcoded using \"/\" or\n",
    "\"\\\\\\\\\", the code may fail on some systems. The code\n",
    "injection is carrying out alterations to evaluate\n",
    "whether your code can function correctly in\n",
    "different operating system environments.\n",
    "Therefore, ensure that you're using `os.path.join`\n",
    "instead of hardcoding slashes.\"\"\" \n",
    "\n",
    "write_readme(readme_text, os.path.join(directories[rubric_item], \"README.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "0f7127b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_data(directories[rubric_item], 50)\n",
    "for i in range(1, 6):\n",
    "    file_copy(os.path.join(directories[rubric_item], 'data', 'stars_%d.csv' % (i)), os.path.join(directories[rubric_item], 'data&stars_%d.csv' % (i)))\n",
    "    file_copy(os.path.join(directories[rubric_item], 'data', 'planets_%d.csv' % (i)), os.path.join(directories[rubric_item], 'data&planets_%d.csv' % (i)))\n",
    "    file_copy(os.path.join(directories[rubric_item], 'data', 'mapping_%d.json' % (i)), os.path.join(directories[rubric_item], 'data&mapping_%d.json' % (i)))\n",
    "random_data(directories[rubric_item], 50)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "49375cca",
   "metadata": {},
   "source": [
    "# BEGIN q14: paths are hardcoded using slashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "60ffc68c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "rubric_item = \"q14: paths are hardcoded using slashes\"\n",
    "nb = new_clean_nb(read_nb(os.path.join(DIRECTORY, FILE)))\n",
    "nb = truncate_nb(nb, end=find_all_cell_indices(nb, \"code\", \"grader.check('q14')\")[-1])\n",
    "\n",
    "path_redefine = '''\n",
    "import os\n",
    "\n",
    "def new_join(*paths):\n",
    "    return '&'.join(paths)\n",
    "    \n",
    "def new_basename(path):\n",
    "    return path.split('&')[-1]\n",
    "    \n",
    "def new_dirname(path):\n",
    "    return '&'.join(path.split('&')[:-1])\n",
    "    \n",
    "def new_split(path):\n",
    "    return tuple(['&'.join(path.split('&')[:-1]), path.split('&')[-1]])'''\n",
    "\n",
    "nb = inject_code(nb, find_all_cell_indices(nb, \"markdown\", \"**Question 1:**\")[-1], path_redefine)\n",
    "nb = replace_code(nb, 'os.path.join', 'new_join')\n",
    "nb = replace_code(nb, 'os.path.basename', 'new_basename')\n",
    "nb = replace_code(nb, 'os.path.dirname', 'new_dirname')\n",
    "nb = replace_code(nb, 'os.path.split', 'new_split')\n",
    "nb = replace_code(nb, 'os.path.sep', \"'&'\")\n",
    "\n",
    "results[rubric_item] = parse_nb(run_nb(nb, os.path.join(directories[rubric_item], FILE)))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5ba57cb3",
   "metadata": {},
   "source": [
    "# END q14: paths are hardcoded using slashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "b2576129",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"update public_tests\"\"\"\n",
    "\n",
    "gen_public_tests.gen_public_tests(os.path.join(directories[rubric_item], FILE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2b1684",
   "metadata": {},
   "source": [
    "### q15: `get_planets` function is not used to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "404fb607",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"update readme\"\"\"\n",
    "\n",
    "rubric_item = \"q15: `get_planets` function is not used to answer\"\n",
    "readme_text = \"\"\"This test is checking if you are using the\n",
    "`get_planets` function to answer the question. A\n",
    "modification has been made to the `get_planets`\n",
    "function so that it reads from different\n",
    "files. If your answer does not change\n",
    "accordingly, it suggests that you did not use the\n",
    "`get_planets` function. Remember to utilize the\n",
    "provided functions instead of reading the data\n",
    "directly from the csv and json files again.\"\"\" \n",
    "\n",
    "write_readme(readme_text, os.path.join(directories[rubric_item], \"README.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "e028fa9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_data(directories[rubric_item], 50)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "793a218b",
   "metadata": {},
   "source": [
    "# BEGIN q15: `get_planets` function is not used to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "d4c8e195",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "rubric_item = \"q15: `get_planets` function is not used to answer\"\n",
    "nb = new_clean_nb(read_nb(os.path.join(DIRECTORY, FILE)))\n",
    "nb = truncate_nb(nb, end=find_all_cell_indices(nb, \"code\", \"grader.check('q15')\")[-1])\n",
    "\n",
    "false_get_planets = \"\"\"\n",
    "import os\n",
    "import csv\n",
    "import json\n",
    "import random\n",
    "\n",
    "def process_csv(filename):\n",
    "    csv_file = open(filename, encoding='utf-8')\n",
    "    csv_reader = csv.reader(csv_file)\n",
    "    csv_data = list(csv_reader)\n",
    "    csv_file.close()\n",
    "    return csv_data\n",
    "\n",
    "def read_json(path):\n",
    "    with open(path, encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def get_planets(planet_file, mapping_file):\n",
    "    if 'data' not in planet_file:\n",
    "        planet_file = os.path.join('data', planet_file)\n",
    "    if 'data' not in mapping_file:\n",
    "        mapping_file = os.path.join('data', mapping_file)\n",
    "    planets = []\n",
    "    try:\n",
    "        mapping_dict = read_json(mapping_file)\n",
    "    except json.JSONDecodeError:\n",
    "        return []\n",
    "    planets_csv = process_csv(planet_file)\n",
    "    planets_header = planets_csv[0]\n",
    "    planets_rows = planets_csv[1:]\n",
    "    random.seed(0)\n",
    "    rows_in_cols = {}\n",
    "    for i in range(len(planets_rows[0])):\n",
    "        rows_in_cols[i] = []\n",
    "        for j in range(len(planets_rows)):\n",
    "            rows_in_cols[i].append(planets_rows[j][i])\n",
    "        random.shuffle(rows_in_cols[i])\n",
    "        \n",
    "    for j in range(len(planets_rows)):\n",
    "        for i in range(len(planets_rows[0])):\n",
    "            planets_rows[j][i] = rows_in_cols[i][j]\n",
    "            \n",
    "    mapping_dict_keys = list(mapping_dict.keys())\n",
    "    mapping_dict_values = list(mapping_dict.values())\n",
    "    random.shuffle(mapping_dict_keys)\n",
    "    random.shuffle(mapping_dict_values)\n",
    "    mapping_dict = {}\n",
    "    for i in range(len(mapping_dict_keys)):\n",
    "        mapping_dict[mapping_dict_keys[i]] = mapping_dict_values[i]\n",
    "            \n",
    "    for row_idx in range(len(planets_rows)):\n",
    "        try:\n",
    "            planet_name = planet_cell(row_idx, 'Planet Name', planets_rows)\n",
    "            host_name = mapping_dict[planet_name]\n",
    "            discovery_method = planet_cell(row_idx, 'Discovery Method', planets_rows)\n",
    "            discovery_year = planet_cell(row_idx, 'Discovery Year', planets_rows)\n",
    "            controversial_flag = planet_cell(row_idx, 'Controversial Flag', planets_rows)\n",
    "            orbital_period = planet_cell(row_idx, 'Orbital Period [days]', planets_rows)\n",
    "            planet_radius = planet_cell(row_idx, 'Planet Radius [Earth Radius]', planets_rows)\n",
    "            planet_mass = planet_cell(row_idx, 'Planet Mass [Earth Mass]', planets_rows)\n",
    "            semi_major_radius = planet_cell(row_idx, 'Orbit Semi-Major Axis [au]', planets_rows)\n",
    "            eccentricity = planet_cell(row_idx, 'Eccentricity', planets_rows)\n",
    "            equilibrium_temperature = planet_cell(row_idx, 'Equilibrium Temperature [K]', planets_rows)\n",
    "            insolation_flux = planet_cell(row_idx, 'Insolation Flux [Earth Flux]', planets_rows)\n",
    "            planet = Planet(planet_name, host_name, discovery_method, discovery_year, controversial_flag, orbital_period, planet_radius, planet_mass, semi_major_radius, eccentricity, equilibrium_temperature, insolation_flux)\n",
    "            planets.append(planet)\n",
    "        except IndexError:\n",
    "            continue\n",
    "        except ValueError:\n",
    "            continue\n",
    "        except KeyError:\n",
    "            continue\n",
    "    return planets\"\"\"\n",
    "nb = replace_with_false_function(nb, 'get_planets', false_get_planets)\n",
    "\n",
    "results[rubric_item] = parse_nb(run_nb(nb, os.path.join(directories[rubric_item], FILE)))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9ec9b163",
   "metadata": {},
   "source": [
    "# END q15: `get_planets` function is not used to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "832a5b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"update public_tests\"\"\"\n",
    "\n",
    "gen_public_tests.gen_public_tests(os.path.join(directories[rubric_item], FILE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820ecee9",
   "metadata": {},
   "source": [
    "### q15: paths are hardcoded using slashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "a1009e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"update readme\"\"\"\n",
    "\n",
    "rubric_item = \"q15: paths are hardcoded using slashes\"\n",
    "readme_text = \"\"\"The test is checking for the\n",
    "robustness of your code across different operating\n",
    "systems. If paths have been hardcoded using \"/\" or\n",
    "\"\\\\\\\\\", the code may fail on some systems. The code\n",
    "injection is carrying out alterations to evaluate\n",
    "whether your code can function correctly in\n",
    "different operating system environments.\n",
    "Therefore, ensure that you're using `os.path.join`\n",
    "instead of hardcoding slashes.\"\"\" \n",
    "\n",
    "write_readme(readme_text, os.path.join(directories[rubric_item], \"README.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "382978bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_data(directories[rubric_item], 50)\n",
    "for i in range(1, 6):\n",
    "    file_copy(os.path.join(directories[rubric_item], 'data', 'stars_%d.csv' % (i)), os.path.join(directories[rubric_item], 'data&stars_%d.csv' % (i)))\n",
    "    file_copy(os.path.join(directories[rubric_item], 'data', 'planets_%d.csv' % (i)), os.path.join(directories[rubric_item], 'data&planets_%d.csv' % (i)))\n",
    "    file_copy(os.path.join(directories[rubric_item], 'data', 'mapping_%d.json' % (i)), os.path.join(directories[rubric_item], 'data&mapping_%d.json' % (i)))\n",
    "random_data(directories[rubric_item], 50)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a12bda3b",
   "metadata": {},
   "source": [
    "# BEGIN q15: paths are hardcoded using slashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "4bad80da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "rubric_item = \"q15: paths are hardcoded using slashes\"\n",
    "nb = new_clean_nb(read_nb(os.path.join(DIRECTORY, FILE)))\n",
    "nb = truncate_nb(nb, end=find_all_cell_indices(nb, \"code\", \"grader.check('q15')\")[-1])\n",
    "\n",
    "path_redefine = '''\n",
    "import os\n",
    "\n",
    "def new_join(*paths):\n",
    "    return '&'.join(paths)\n",
    "    \n",
    "def new_basename(path):\n",
    "    return path.split('&')[-1]\n",
    "    \n",
    "def new_dirname(path):\n",
    "    return '&'.join(path.split('&')[:-1])\n",
    "    \n",
    "def new_split(path):\n",
    "    return tuple(['&'.join(path.split('&')[:-1]), path.split('&')[-1]])'''\n",
    "\n",
    "nb = inject_code(nb, find_all_cell_indices(nb, \"markdown\", \"**Question 1:**\")[-1], path_redefine)\n",
    "nb = replace_code(nb, 'os.path.join', 'new_join')\n",
    "nb = replace_code(nb, 'os.path.basename', 'new_basename')\n",
    "nb = replace_code(nb, 'os.path.dirname', 'new_dirname')\n",
    "nb = replace_code(nb, 'os.path.split', 'new_split')\n",
    "nb = replace_code(nb, 'os.path.sep', \"'&'\")\n",
    "\n",
    "results[rubric_item] = parse_nb(run_nb(nb, os.path.join(directories[rubric_item], FILE)))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3feddb62",
   "metadata": {},
   "source": [
    "# END q15: paths are hardcoded using slashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "9ad4171e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"update public_tests\"\"\"\n",
    "\n",
    "gen_public_tests.gen_public_tests(os.path.join(directories[rubric_item], FILE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f62ac5",
   "metadata": {},
   "source": [
    "### planets_list: data structure is defined incorrectly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "771b95bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"update readme\"\"\"\n",
    "\n",
    "rubric_item = \"planets_list: data structure is defined incorrectly\"\n",
    "readme_text = \"\"\"This test is checking if you have correctly\n",
    "defined the data structure that contains the list\n",
    "of planets with their details. It is important that you\n",
    "define this data structure correctly by parsing all five\n",
    "files, as any errors here will affect all future \n",
    "questions as  well. Make sure that you use `try/except`\n",
    "to identify the JSON file with the missing data and\n",
    "skip it. The test will compare your data structure\n",
    "against the correct one to see if they match. Make\n",
    "sure you have followed the instructions and\n",
    "defined the data structure correctly.\"\"\" \n",
    "\n",
    "write_readme(readme_text, os.path.join(directories[rubric_item], \"README.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "273587e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir(os.path.join(DIRECTORY, \"hidden\", \"original\", \"data\")):\n",
    "    if file.startswith(\".\"):\n",
    "        continue\n",
    "    file_copy(os.path.join(DIRECTORY, \"hidden\", \"original\", \"data\", file), os.path.join(directories[rubric_item], 'data', file))\n",
    "\n",
    "file_copy(os.path.join(directories[rubric_item], 'data', 'mapping_4.json'), os.path.join(directories[rubric_item], 'data', 'mapping_6.json'))\n",
    "file_copy(os.path.join(directories[rubric_item], 'data', 'mapping_5.json'), os.path.join(directories[rubric_item], 'data', 'mapping_4.json'))\n",
    "file_copy(os.path.join(directories[rubric_item], 'data', 'mapping_6.json'), os.path.join(directories[rubric_item], 'data', 'mapping_5.json'))\n",
    "\n",
    "file_copy(os.path.join(directories[rubric_item], 'data', 'planets_4.csv'), os.path.join(directories[rubric_item], 'data', 'planets_6.csv'))\n",
    "file_copy(os.path.join(directories[rubric_item], 'data', 'planets_5.csv'), os.path.join(directories[rubric_item], 'data', 'planets_4.csv'))\n",
    "file_copy(os.path.join(directories[rubric_item], 'data', 'planets_6.csv'), os.path.join(directories[rubric_item], 'data', 'planets_5.csv'))\n",
    "\n",
    "os.remove(os.path.join(directories[rubric_item], 'data', 'mapping_6.json'))\n",
    "os.remove(os.path.join(directories[rubric_item], 'data', 'planets_6.csv'))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "21493e4b",
   "metadata": {},
   "source": [
    "# BEGIN planets_list: data structure is defined incorrectly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "f4c2e47f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "rubric_item = \"planets_list: data structure is defined incorrectly\"\n",
    "nb = new_clean_nb(read_nb(os.path.join(DIRECTORY, FILE)))\n",
    "nb = truncate_nb(nb, end=find_all_cell_indices(nb, \"code\", \"grader.check('planets_list')\")[-1])\n",
    "\n",
    "nb = inject_data_structure_check(nb, 'planets_list', \"TEXT_FORMAT_ORDERED_LIST\")\n",
    "\n",
    "results[rubric_item] = parse_nb(run_nb(nb, os.path.join(directories[rubric_item], FILE)))\n",
    "test_output = results[rubric_item][rubric_item.split(\":\")[0]]\n",
    "if test_output != 'All test cases passed!':\n",
    "    comments[rubric_item] += '\\nFAILED TEST CASE: ' + test_output"
   ]
  },
  {
   "cell_type": "raw",
   "id": "16f7c196",
   "metadata": {},
   "source": [
    "# END planets_list: data structure is defined incorrectly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b53b7f7",
   "metadata": {},
   "source": [
    "### planets_list: `get_planets` function is not used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "6b91684e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"update readme\"\"\"\n",
    "\n",
    "rubric_item = \"planets_list: `get_planets` function is not used\"\n",
    "readme_text = \"\"\"This test is checking if you are using the\n",
    "`get_planets` function to define `planets_list`. A\n",
    "modification has been made to the `get_planets`\n",
    "function so that it reads from different\n",
    "files. If your answer does not change\n",
    "accordingly, it suggests that you did not use the\n",
    "`get_planets` function. Remember to utilize the\n",
    "provided functions instead of reading the data\n",
    "directly from the csv and json files again.\"\"\" \n",
    "\n",
    "write_readme(readme_text, os.path.join(directories[rubric_item], \"README.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "511b7086",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_data(directories[rubric_item], 50)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f96ca1cb",
   "metadata": {},
   "source": [
    "# BEGIN planets_list: `get_planets` function is not used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "f25877ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "rubric_item = \"planets_list: `get_planets` function is not used\"\n",
    "nb = new_clean_nb(read_nb(os.path.join(DIRECTORY, FILE)))\n",
    "nb = truncate_nb(nb, end=find_all_cell_indices(nb, \"code\", \"grader.check('planets_list')\")[-1])\n",
    "\n",
    "nb = inject_data_structure_check(nb, 'planets_list', \"TEXT_FORMAT_ORDERED_LIST\")\n",
    "\n",
    "\n",
    "false_get_planets = \"\"\"\n",
    "import os\n",
    "import csv\n",
    "import json\n",
    "import random\n",
    "\n",
    "def process_csv(filename):\n",
    "    csv_file = open(filename, encoding='utf-8')\n",
    "    csv_reader = csv.reader(csv_file)\n",
    "    csv_data = list(csv_reader)\n",
    "    csv_file.close()\n",
    "    return csv_data\n",
    "\n",
    "def read_json(path):\n",
    "    with open(path, encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def get_planets(planet_file, mapping_file):\n",
    "    if 'data' not in planet_file:\n",
    "        planet_file = os.path.join('data', planet_file)\n",
    "    if 'data' not in mapping_file:\n",
    "        mapping_file = os.path.join('data', mapping_file)\n",
    "    planets = []\n",
    "    try:\n",
    "        mapping_dict = read_json(mapping_file)\n",
    "    except json.JSONDecodeError:\n",
    "        return []\n",
    "    planets_csv = process_csv(planet_file)\n",
    "    planets_header = planets_csv[0]\n",
    "    planets_rows = planets_csv[1:]\n",
    "    random.seed(0)\n",
    "    rows_in_cols = {}\n",
    "    for i in range(len(planets_rows[0])):\n",
    "        rows_in_cols[i] = []\n",
    "        for j in range(len(planets_rows)):\n",
    "            rows_in_cols[i].append(planets_rows[j][i])\n",
    "        random.shuffle(rows_in_cols[i])\n",
    "        \n",
    "    for j in range(len(planets_rows)):\n",
    "        for i in range(len(planets_rows[0])):\n",
    "            planets_rows[j][i] = rows_in_cols[i][j]\n",
    "            \n",
    "    mapping_dict_keys = list(mapping_dict.keys())\n",
    "    mapping_dict_values = list(mapping_dict.values())\n",
    "    random.shuffle(mapping_dict_keys)\n",
    "    random.shuffle(mapping_dict_values)\n",
    "    mapping_dict = {}\n",
    "    for i in range(len(mapping_dict_keys)):\n",
    "        mapping_dict[mapping_dict_keys[i]] = mapping_dict_values[i]\n",
    "            \n",
    "    for row_idx in range(len(planets_rows)):\n",
    "        try:\n",
    "            planet_name = planet_cell(row_idx, 'Planet Name', planets_rows)\n",
    "            host_name = mapping_dict[planet_name]\n",
    "            discovery_method = planet_cell(row_idx, 'Discovery Method', planets_rows)\n",
    "            discovery_year = planet_cell(row_idx, 'Discovery Year', planets_rows)\n",
    "            controversial_flag = planet_cell(row_idx, 'Controversial Flag', planets_rows)\n",
    "            orbital_period = planet_cell(row_idx, 'Orbital Period [days]', planets_rows)\n",
    "            planet_radius = planet_cell(row_idx, 'Planet Radius [Earth Radius]', planets_rows)\n",
    "            planet_mass = planet_cell(row_idx, 'Planet Mass [Earth Mass]', planets_rows)\n",
    "            semi_major_radius = planet_cell(row_idx, 'Orbit Semi-Major Axis [au]', planets_rows)\n",
    "            eccentricity = planet_cell(row_idx, 'Eccentricity', planets_rows)\n",
    "            equilibrium_temperature = planet_cell(row_idx, 'Equilibrium Temperature [K]', planets_rows)\n",
    "            insolation_flux = planet_cell(row_idx, 'Insolation Flux [Earth Flux]', planets_rows)\n",
    "            planet = Planet(planet_name, host_name, discovery_method, discovery_year, controversial_flag, orbital_period, planet_radius, planet_mass, semi_major_radius, eccentricity, equilibrium_temperature, insolation_flux)\n",
    "            planets.append(planet)\n",
    "        except IndexError:\n",
    "            continue\n",
    "        except ValueError:\n",
    "            continue\n",
    "        except KeyError:\n",
    "            continue\n",
    "    return planets\"\"\"\n",
    "nb = replace_with_false_function(nb, 'get_planets', false_get_planets)\n",
    "\n",
    "results[rubric_item] = parse_nb(run_nb(nb, os.path.join(directories[rubric_item], FILE)))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "562dfda3",
   "metadata": {},
   "source": [
    "# END planets_list: `get_planets` function is not used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe28bcf",
   "metadata": {},
   "source": [
    "### planets_list: paths are hardcoded using slashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "ce0b5748",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"update readme\"\"\"\n",
    "\n",
    "rubric_item = \"planets_list: paths are hardcoded using slashes\"\n",
    "readme_text = \"\"\"The test is checking for the\n",
    "robustness of your code across different operating\n",
    "systems. If paths have been hardcoded using \"/\" or\n",
    "\"\\\\\\\\\", the code may fail on some systems. The code\n",
    "injection is carrying out alterations to evaluate\n",
    "whether your code can function correctly in\n",
    "different operating system environments.\n",
    "Therefore, ensure that you're using `os.path.join`\n",
    "instead of hardcoding slashes.\"\"\" \n",
    "\n",
    "write_readme(readme_text, os.path.join(directories[rubric_item], \"README.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "9d992df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_data(directories[rubric_item], 50)\n",
    "for i in range(1, 6):\n",
    "    file_copy(os.path.join(directories[rubric_item], 'data', 'stars_%d.csv' % (i)), os.path.join(directories[rubric_item], 'data&stars_%d.csv' % (i)))\n",
    "    file_copy(os.path.join(directories[rubric_item], 'data', 'planets_%d.csv' % (i)), os.path.join(directories[rubric_item], 'data&planets_%d.csv' % (i)))\n",
    "    file_copy(os.path.join(directories[rubric_item], 'data', 'mapping_%d.json' % (i)), os.path.join(directories[rubric_item], 'data&mapping_%d.json' % (i)))\n",
    "random_data(directories[rubric_item], 50)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ecc454f7",
   "metadata": {},
   "source": [
    "# BEGIN planets_list: paths are hardcoded using slashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "6c0c635e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "rubric_item = \"planets_list: paths are hardcoded using slashes\"\n",
    "nb = new_clean_nb(read_nb(os.path.join(DIRECTORY, FILE)))\n",
    "nb = truncate_nb(nb, end=find_all_cell_indices(nb, \"code\", \"grader.check('planets_list')\")[-1])\n",
    "\n",
    "nb = inject_data_structure_check(nb, 'planets_list', \"TEXT_FORMAT_ORDERED_LIST\")\n",
    "\n",
    "path_redefine = '''\n",
    "import os\n",
    "\n",
    "def new_join(*paths):\n",
    "    return '&'.join(paths)\n",
    "    \n",
    "def new_basename(path):\n",
    "    return path.split('&')[-1]\n",
    "    \n",
    "def new_dirname(path):\n",
    "    return '&'.join(path.split('&')[:-1])\n",
    "    \n",
    "def new_split(path):\n",
    "    return tuple(['&'.join(path.split('&')[:-1]), path.split('&')[-1]])'''\n",
    "\n",
    "nb = inject_code(nb, find_all_cell_indices(nb, \"markdown\", \"**Question 1:**\")[-1], path_redefine)\n",
    "nb = replace_code(nb, 'os.path.join', 'new_join')\n",
    "nb = replace_code(nb, 'os.path.basename', 'new_basename')\n",
    "nb = replace_code(nb, 'os.path.dirname', 'new_dirname')\n",
    "nb = replace_code(nb, 'os.path.split', 'new_split')\n",
    "nb = replace_code(nb, 'os.path.sep', \"'&'\")\n",
    "\n",
    "results[rubric_item] = parse_nb(run_nb(nb, os.path.join(directories[rubric_item], FILE)))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8d42eb0d",
   "metadata": {},
   "source": [
    "# END planets_list: paths are hardcoded using slashes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad55550",
   "metadata": {},
   "source": [
    "### q16: `planets_list` data structure is not used to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "6771242e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"update readme\"\"\"\n",
    "\n",
    "rubric_item = \"q16: `planets_list` data structure is not used to answer\"\n",
    "readme_text = \"\"\"You need to access the `Planet` objects in the \n",
    "`planets_list` list. The list already \n",
    "contains all the data about the planets in \n",
    "the dataset. Make sure to use the data\n",
    "from the `planets_list` list to answer the\n",
    "question. A modified version of the list is\n",
    "provided right before the answer to this question.\n",
    "If your answer does not use this modified data\n",
    "structure, you may not have used the data\n",
    "correctly.\"\"\" \n",
    "\n",
    "write_readme(readme_text, os.path.join(directories[rubric_item], \"README.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "fdf4132d",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_data(directories[rubric_item], 50)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5b1af9ea",
   "metadata": {},
   "source": [
    "# BEGIN q16: `planets_list` data structure is not used to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "d8530f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "rubric_item = \"q16: `planets_list` data structure is not used to answer\"\n",
    "nb = new_clean_nb(read_nb(os.path.join(DIRECTORY, FILE)))\n",
    "nb = truncate_nb(nb, end=find_all_cell_indices(nb, \"code\", \"grader.check('q16')\")[-1])\n",
    "\n",
    "randomized_planets_list = true_data_structures[\"planets_list\"] + '''\n",
    "import random\n",
    "\n",
    "random.seed(0)\n",
    "raw_planets = [list(planet) for planet in planets_list]\n",
    "rows_in_cols = {}\n",
    "for i in range(len(raw_planets[0])):\n",
    "    rows_in_cols[i] = []\n",
    "    for j in range(len(raw_planets)):\n",
    "        rows_in_cols[i].append(raw_planets[j][i])\n",
    "    random.shuffle(rows_in_cols[i])\n",
    "\n",
    "for j in range(len(raw_planets)):\n",
    "    for i in range(len(raw_planets[0])):\n",
    "        raw_planets[j][i] = rows_in_cols[i][j]\n",
    "planets_list = [Planet(*planet) for planet in raw_planets] * 20\n",
    "'''\n",
    "nb = replace_with_false_data_structure(nb, 'planets_list', randomized_planets_list)\n",
    "\n",
    "results[rubric_item] = parse_nb(run_nb(nb, os.path.join(directories[rubric_item], FILE)))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7669a1c6",
   "metadata": {},
   "source": [
    "# END q16: `planets_list` data structure is not used to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "7ef6d76c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"update public_tests\"\"\"\n",
    "\n",
    "gen_public_tests.gen_public_tests(os.path.join(directories[rubric_item], FILE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd41cd5d",
   "metadata": {},
   "source": [
    "### q17: incorrect comparison operator is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "5693be47",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"update readme\"\"\"\n",
    "\n",
    "rubric_item = \"q17: incorrect comparison operator is used\"\n",
    "readme_text = \"\"\"This test is checking if your code correctly\n",
    "counts the number of planets that were discovered\n",
    "in the year 2023. We have modified the dataset to\n",
    "include planets with different discovery years.\n",
    "Some planets have the discovery year set to 2023,\n",
    "while others have it set to 2022 or 2024. Make\n",
    "sure your code accurately identifies the planets\n",
    "that were discovered in 2023. Remember to output\n",
    "your answer as an integer.\"\"\" \n",
    "\n",
    "write_readme(readme_text, os.path.join(directories[rubric_item], \"README.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "fe6a7419",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_data(path):\n",
    "    for i in range(1, 6):\n",
    "        # Read the planets.csv file\n",
    "        planets_df = pd.read_csv(os.path.join(path, \"data\", 'planets_%d.csv' % (i)), encoding='utf-8')\n",
    "\n",
    "        # Modify the Discovery Year column\n",
    "        num_rows = len(planets_df)\n",
    "        num_modified_rows = int(num_rows / 10)\n",
    "        modified_indices = planets_df.sample(num_modified_rows).index\n",
    "        planets_df.loc[modified_indices, 'Discovery Year'] = 2023\n",
    "\n",
    "        other_indices = ~np.isin(np.arange(len(planets_df)), modified_indices)\n",
    "        planets_df.loc[other_indices, 'Discovery Year'] = pd.Series([2024, 2022]).sample(num_rows - num_modified_rows, replace=True).values\n",
    "\n",
    "        # Save the modified data back to planets.csv\n",
    "        planets_df.to_csv(os.path.join(path, \"data\", 'planets_%d.csv' % (i)), index=False, encoding='utf-8')\n",
    "    \n",
    "random_data(directories[rubric_item], 200)\n",
    "modify_data(directories[rubric_item])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fe6f948e",
   "metadata": {},
   "source": [
    "# BEGIN q17: incorrect comparison operator is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "0ee45346",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "rubric_item = \"q17: incorrect comparison operator is used\"\n",
    "nb = new_clean_nb(read_nb(os.path.join(DIRECTORY, FILE)))\n",
    "nb = truncate_nb(nb, end=find_all_cell_indices(nb, \"code\", \"grader.check('q17')\")[-1])\n",
    "\n",
    "results[rubric_item] = parse_nb(run_nb(nb, os.path.join(directories[rubric_item], FILE)))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "12c033ef",
   "metadata": {},
   "source": [
    "# END q17: incorrect comparison operator is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "bf9b588e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"update public_tests\"\"\"\n",
    "\n",
    "gen_public_tests.gen_public_tests(os.path.join(directories[rubric_item], FILE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467ee31b",
   "metadata": {},
   "source": [
    "### q17: incorrect logic is used to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "c22d4f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"update readme\"\"\"\n",
    "\n",
    "rubric_item = \"q17: incorrect logic is used to answer\"\n",
    "readme_text = \"\"\"The code is attempting to find the number\n",
    "of planets discovered in 2023. To test if your \n",
    "code is correctly identifying these planets, \n",
    "we have modified the dataset completely. \n",
    "Make sure your code is not just relying \n",
    "on specific values in the original dataset, \n",
    "but instead is correctly identifying planets \n",
    "discovered in 2023.\"\"\" \n",
    "\n",
    "write_readme(readme_text, os.path.join(directories[rubric_item], \"README.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "f36157d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_data(path):\n",
    "    for i in range(1, 6):\n",
    "        # Read the planets.csv file\n",
    "        planets_df = pd.read_csv(os.path.join(path, \"data\", 'planets_%d.csv' % (i)), encoding='utf-8')\n",
    "\n",
    "        # Modify the Discovery Year column\n",
    "        num_rows = len(planets_df)\n",
    "        num_modified_rows = int(num_rows / 3)\n",
    "        modified_indices = pd.Series(planets_df.sample(num_modified_rows).index)\n",
    "\n",
    "        planets_df.loc[modified_indices, 'Discovery Year'] = 2023\n",
    "\n",
    "        # Save the modified data back to planets.csv\n",
    "        planets_df.to_csv(os.path.join(path, \"data\", 'planets_%d.csv' % (i)), index=False, encoding='utf-8')\n",
    "        \n",
    "random_data(directories[rubric_item], 200)\n",
    "modify_data(directories[rubric_item])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1c7e143c",
   "metadata": {},
   "source": [
    "# BEGIN q17: incorrect logic is used to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "ba7f83d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "rubric_item = \"q17: incorrect logic is used to answer\"\n",
    "nb = new_clean_nb(read_nb(os.path.join(DIRECTORY, FILE)))\n",
    "nb = truncate_nb(nb, end=find_all_cell_indices(nb, \"code\", \"grader.check('q17')\")[-1])\n",
    "\n",
    "results[rubric_item] = parse_nb(run_nb(nb, os.path.join(directories[rubric_item], FILE)))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9e912604",
   "metadata": {},
   "source": [
    "# END q17: incorrect logic is used to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "36b20b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"update public_tests\"\"\"\n",
    "\n",
    "gen_public_tests.gen_public_tests(os.path.join(directories[rubric_item], FILE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d92ed7a",
   "metadata": {},
   "source": [
    "### q17: `planets_list` data structure is not used to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "a40823bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"update readme\"\"\"\n",
    "\n",
    "rubric_item = \"q17: `planets_list` data structure is not used to answer\"\n",
    "readme_text = \"\"\"You need to access the `Planet` objects in the \n",
    "`planets_list` list. The list already \n",
    "contains all the data about the planets in \n",
    "the dataset. Make sure to use the data\n",
    "from the `planets_list` list to answer the\n",
    "question. A modified version of the list is\n",
    "provided right before the answer to this question.\n",
    "If your answer does not use this modified data\n",
    "structure, you may not have used the data\n",
    "correctly.\"\"\"\n",
    "\n",
    "write_readme(readme_text, os.path.join(directories[rubric_item], \"README.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "949660bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_data(directories[rubric_item], 50)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f6ed68e0",
   "metadata": {},
   "source": [
    "# BEGIN q17: `planets_list` data structure is not used to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "c0dc3e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "rubric_item = \"q17: `planets_list` data structure is not used to answer\"\n",
    "nb = new_clean_nb(read_nb(os.path.join(DIRECTORY, FILE)))\n",
    "nb = truncate_nb(nb, end=find_all_cell_indices(nb, \"code\", \"grader.check('q17')\")[-1])\n",
    "\n",
    "randomized_planets_list = true_data_structures[\"planets_list\"] + '''\n",
    "import random\n",
    "\n",
    "random.seed(0)\n",
    "raw_planets = [list(planet) for planet in planets_list]\n",
    "rows_in_cols = {}\n",
    "for i in range(len(raw_planets[0])):\n",
    "    rows_in_cols[i] = []\n",
    "    for j in range(len(raw_planets)):\n",
    "        rows_in_cols[i].append(raw_planets[j][i])\n",
    "    random.shuffle(rows_in_cols[i])\n",
    "\n",
    "for j in range(len(raw_planets)):\n",
    "    for i in range(len(raw_planets[0])):\n",
    "        raw_planets[j][i] = rows_in_cols[i][j]\n",
    "planets_list = [Planet(*planet) for planet in raw_planets]\n",
    "for idx in range(len(planets_list)):\n",
    "    if planets_list[idx].discovery_year == None or planets_list[idx].discovery_year < 2015:\n",
    "        planets_list[idx] = planets_list[idx]._replace(discovery_year=2023)\n",
    "'''\n",
    "nb = replace_with_false_data_structure(nb, 'planets_list', randomized_planets_list)\n",
    "\n",
    "results[rubric_item] = parse_nb(run_nb(nb, os.path.join(directories[rubric_item], FILE)))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "57f03166",
   "metadata": {},
   "source": [
    "# END q17: `planets_list` data structure is not used to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "a6bfe0e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"update public_tests\"\"\"\n",
    "\n",
    "gen_public_tests.gen_public_tests(os.path.join(directories[rubric_item], FILE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51025b0b",
   "metadata": {},
   "source": [
    "### q18: `planets_list` and `stars_dict` data structures are not used to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "d31491ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"update readme\"\"\"\n",
    "\n",
    "rubric_item = \"q18: `planets_list` and `stars_dict` data structures are not used to answer\"\n",
    "readme_text = \"\"\"You need to access the `Planet` objects in the \n",
    "`planets_list` list and `Star` objects in the\n",
    "`stars_dict` dictionary. These data structures \n",
    "already contain all the data about the planets\n",
    "and stars in  the dataset. Make sure to use the \n",
    "data from the `planets_list` list and `stars_dict`\n",
    "dictionary to answer the question. A modified \n",
    "version of the list and dictionary are provided \n",
    "right before the answer to this question.\n",
    "If your answer does not use these modified data\n",
    "structures, you may not have used the data\n",
    "correctly.\"\"\" \n",
    "\n",
    "write_readme(readme_text, os.path.join(directories[rubric_item], \"README.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "cbb774c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_data(directories[rubric_item], 50)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d0c68b49",
   "metadata": {},
   "source": [
    "# BEGIN q18: `planets_list` and `stars_dict` data structures are not used to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "879f07f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "rubric_item = \"q18: `planets_list` and `stars_dict` data structures are not used to answer\"\n",
    "nb = new_clean_nb(read_nb(os.path.join(DIRECTORY, FILE)))\n",
    "nb = truncate_nb(nb, end=find_all_cell_indices(nb, \"code\", \"grader.check('q18')\")[-1])\n",
    "\n",
    "randomized_stars_dict = true_data_structures[\"stars_dict\"] + '''\n",
    "import random\n",
    "\n",
    "random.seed(0)\n",
    "stars_dict_keys = list(stars_dict.keys())\n",
    "stars_dict_values = list(stars_dict.values())\n",
    "random.shuffle(stars_dict_keys)\n",
    "random.shuffle(stars_dict_values)\n",
    "\n",
    "stars_dict = {}\n",
    "for i in range(len(stars_dict_keys)):\n",
    "    stars_dict[stars_dict_keys[i]] = stars_dict_values[i]\n",
    "'''\n",
    "nb = replace_with_false_data_structure(nb, 'stars_dict', randomized_stars_dict)\n",
    "\n",
    "randomized_planets_list = true_data_structures[\"planets_list\"] + '''\n",
    "import random\n",
    "\n",
    "random.seed(0)\n",
    "raw_planets = [list(planet) for planet in planets_list]\n",
    "rows_in_cols = {}\n",
    "for i in range(len(raw_planets[0])):\n",
    "    rows_in_cols[i] = []\n",
    "    for j in range(len(raw_planets)):\n",
    "        rows_in_cols[i].append(raw_planets[j][i])\n",
    "    random.shuffle(rows_in_cols[i])\n",
    "\n",
    "for j in range(len(raw_planets)):\n",
    "    for i in range(len(raw_planets[0])):\n",
    "        raw_planets[j][i] = rows_in_cols[i][j]\n",
    "planets_list = [Planet(*planet) for planet in raw_planets]\n",
    "'''\n",
    "nb = replace_with_false_data_structure(nb, 'planets_list', randomized_planets_list)\n",
    "\n",
    "results[rubric_item] = parse_nb(run_nb(nb, os.path.join(directories[rubric_item], FILE)))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4618e94f",
   "metadata": {},
   "source": [
    "# END q18: `planets_list` and `stars_dict` data structures are not used to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "c4790b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"update public_tests\"\"\"\n",
    "\n",
    "gen_public_tests.gen_public_tests(os.path.join(directories[rubric_item], FILE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfcf9bf",
   "metadata": {},
   "source": [
    "### q18: did not exit loop and instead iterated further after finding the answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "57628ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"update readme\"\"\"\n",
    "\n",
    "rubric_item = \"q18: did not exit loop and instead iterated further after finding the answer\"\n",
    "readme_text = \"\"\"Your code is searching for the Star object that\n",
    "corresponds to a specific Planet object. Make sure\n",
    "that your code correctly identifies the Planet\n",
    "object with the given name, and then uses the\n",
    "host_name attribute to find the corresponding Star\n",
    "object. Remember that you do not need to continue\n",
    "looping through the list of planets once you have\n",
    "found the required planet. The dataset is modified\n",
    "and other Planet objects with the same name but\n",
    "different hosts are added to the dataset.\"\"\" \n",
    "\n",
    "write_readme(readme_text, os.path.join(directories[rubric_item], \"README.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "4ca53a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_data(path):    \n",
    "    for i in range(1, 3): # Modify two datasets\n",
    "        planets_df = pd.read_csv(os.path.join(path, \"data\", 'planets_%d.csv' % (i)), encoding='utf-8')\n",
    "        mapping = None\n",
    "        # Choose a random row index\n",
    "        row_index = random.randint(0, len(planets_df) - 1)\n",
    "        \n",
    "        # Get the original planet name\n",
    "        original_planet_name = planets_df.iloc[row_index]['Planet Name']\n",
    "        \n",
    "        # Modify the planet name to 'TOI-2202 c'\n",
    "        planets_df.at[row_index, 'Planet Name'] = 'TOI-2202 c'\n",
    "        \n",
    "        # Modify the mapping json file\n",
    "        with open(os.path.join(path, \"data\", f'mapping_{i}.json'), 'r') as f:\n",
    "            mapping = json.load(f)\n",
    "        \n",
    "        # Replace the original planet name in mapping with 'TOI-2202 c'\n",
    "        mapping['TOI-2202 c'] = mapping.pop(original_planet_name)\n",
    "        \n",
    "        # Save the modified mapping json file\n",
    "        with open(os.path.join(path, \"data\", f'mapping_{i}.json'), 'w') as f:\n",
    "            json.dump(mapping, f)\n",
    "    \n",
    "        # Save the modified dataset csv file\n",
    "        planets_df.to_csv(os.path.join(path, \"data\", 'planets_%d.csv' % (i)), index=False, encoding='utf-8')\n",
    "        \n",
    "random_data(directories[rubric_item], 200)\n",
    "modify_data(directories[rubric_item])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4fdc0749",
   "metadata": {},
   "source": [
    "# BEGIN q18: did not exit loop and instead iterated further after finding the answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "cf3e02b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "rubric_item = \"q18: did not exit loop and instead iterated further after finding the answer\"\n",
    "nb = new_clean_nb(read_nb(os.path.join(DIRECTORY, FILE)))\n",
    "nb = truncate_nb(nb, end=find_all_cell_indices(nb, \"code\", \"grader.check('q18')\")[-1])\n",
    "\n",
    "results[rubric_item] = parse_nb(run_nb(nb, os.path.join(directories[rubric_item], FILE)))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a7f05bc2",
   "metadata": {},
   "source": [
    "# END q18: did not exit loop and instead iterated further after finding the answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "fd4e46ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"update public_tests\"\"\"\n",
    "\n",
    "gen_public_tests.gen_public_tests(os.path.join(directories[rubric_item], FILE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea8ff3a",
   "metadata": {},
   "source": [
    "### q19: incorrect comparison operator is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "7946473f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"update readme\"\"\"\n",
    "\n",
    "rubric_item = \"q19: incorrect comparison operator is used\"\n",
    "readme_text = \"\"\"The test is checking if you are correctly\n",
    "comparing the stellar radius of stars. The dataset\n",
    "has been modified to have many stars with a\n",
    "stellar radius just above the threshold. This is\n",
    "to catch cases where you are using the wrong\n",
    "comparison operator. Make sure you are comparing\n",
    "the stellar radius of stars correctly by using the\n",
    "correct comparison operator.\"\"\" \n",
    "\n",
    "write_readme(readme_text, os.path.join(directories[rubric_item], \"README.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "69d165ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_data(path):\n",
    "    for i in range(1, 5):\n",
    "        stars_df = pd.read_csv(os.path.join(path, \"data\", f'stars_{i}.csv'), encoding='utf-8')\n",
    "        planets_df = pd.read_csv(os.path.join(path, \"data\", f'planets_{i}.csv'), encoding='utf-8')\n",
    "        mapping_file = os.path.join(path, \"data\", f'mapping_{i}.json')\n",
    "\n",
    "        with open(mapping_file, 'r', encoding='utf-8') as f:\n",
    "            mapping = json.load(f)\n",
    "\n",
    "        # Modify Stellar Radius column in stars_df\n",
    "        half_rows = len(stars_df) // 2\n",
    "        half_equal_indices = pd.Series(stars_df.sample(half_rows).index)\n",
    "        stars_df.loc[half_equal_indices,'Stellar Radius [Solar Radius]'] = 10.0\n",
    "        \n",
    "        half_unequal_indices = pd.Series(stars_df.sample(half_rows).index)\n",
    "        stars_df.loc[half_unequal_indices,'Stellar Radius [Solar Radius]'] = 10.01\n",
    "\n",
    "        # Modify Planet Radius column in planets_df\n",
    "        for planet_name, star_name in mapping.items():\n",
    "            stellar_radius = stars_df.loc[stars_df['Star Name'] == star_name, 'Stellar Radius [Solar Radius]'].values[0]\n",
    "            if stellar_radius == 10.0:\n",
    "                planets_df.loc[planets_df['Planet Name'] == planet_name, 'Planet Radius [Earth Radius]'] = 100000.0\n",
    "\n",
    "        # Save the modified dataframes\n",
    "        stars_df.to_csv(os.path.join(path, \"data\", f'stars_{i}.csv'), index=False, encoding='utf-8')\n",
    "        planets_df.to_csv(os.path.join(path, \"data\", f'planets_{i}.csv'), index=False, encoding='utf-8')\n",
    "\n",
    "random_data(directories[rubric_item], 200)\n",
    "modify_data(directories[rubric_item])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f90dd8bc",
   "metadata": {},
   "source": [
    "# BEGIN q19: incorrect comparison operator is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "a86c9db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "rubric_item = \"q19: incorrect comparison operator is used\"\n",
    "nb = new_clean_nb(read_nb(os.path.join(DIRECTORY, FILE)))\n",
    "nb = truncate_nb(nb, end=find_all_cell_indices(nb, \"code\", \"grader.check('q19')\")[-1])\n",
    "\n",
    "results[rubric_item] = parse_nb(run_nb(nb, os.path.join(directories[rubric_item], FILE)))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3802f1d9",
   "metadata": {},
   "source": [
    "# END q19: incorrect comparison operator is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "1f0f8a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"update public_tests\"\"\"\n",
    "\n",
    "gen_public_tests.gen_public_tests(os.path.join(directories[rubric_item], FILE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2365c8af",
   "metadata": {},
   "source": [
    "### q19: incorrect logic is used to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "c71acc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"update readme\"\"\"\n",
    "\n",
    "rubric_item = \"q19: incorrect logic is used to answer\"\n",
    "readme_text = \"\"\"Find the average planet radius of planets that\n",
    "orbit stars with stellar radius more than 10 times\n",
    "the radius of the Sun. Be careful, there are some\n",
    "missing data. The dataset has been modified to\n",
    "test your code. Some stellar radius values are\n",
    "missing and for some stars with high stellar\n",
    "radius, the planet radius data is missing or zero.\n",
    "Double-check your logic to ensure correct results\n",
    "despite these modifications.\"\"\" \n",
    "\n",
    "write_readme(readme_text, os.path.join(directories[rubric_item], \"README.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "5bd6088a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_data(path):\n",
    "    for i in range(1, 5):\n",
    "        stars_df = pd.read_csv(os.path.join(path, \"data\", f'stars_{i}.csv'), encoding='utf-8')\n",
    "        planets_df = pd.read_csv(os.path.join(path, \"data\", f'planets_{i}.csv'), encoding='utf-8')\n",
    "        mapping_file = os.path.join(path, \"data\", f'mapping_{i}.json')\n",
    "\n",
    "        with open(mapping_file, 'r', encoding='utf-8') as f:\n",
    "            mapping = json.load(f)\n",
    "\n",
    "        # Modify Stellar Radius column in stars_df\n",
    "        half_rows = len(stars_df) // 2\n",
    "        half_equal_indices = pd.Series(stars_df.sample(half_rows).index)\n",
    "        stars_df.loc[half_equal_indices,'Stellar Radius [Solar Radius]'] = 100.0\n",
    "        \n",
    "        half_unequal_indices = pd.Series(stars_df.sample(half_rows).index)\n",
    "        stars_df.loc[half_unequal_indices,'Stellar Radius [Solar Radius]'] = None\n",
    "\n",
    "        # Modify Planet Radius column in planets_df\n",
    "        for planet_name, star_name in mapping.items():\n",
    "            stellar_radius = stars_df.loc[stars_df['Star Name'] == star_name, 'Stellar Radius [Solar Radius]'].values[0]\n",
    "            if stellar_radius == 100.0:\n",
    "                planet_radius_choice = random.randint(1, 3)\n",
    "                if planet_radius_choice == 1:\n",
    "                    planets_df.loc[planets_df['Planet Name'] == planet_name, 'Planet Radius [Earth Radius]'] = 100000.0\n",
    "                elif planet_radius_choice == 2:\n",
    "                    planets_df.loc[planets_df['Planet Name'] == planet_name, 'Planet Radius [Earth Radius]'] = None\n",
    "                elif planet_radius_choice == 3:\n",
    "                    planets_df.loc[planets_df['Planet Name'] == planet_name, 'Planet Radius [Earth Radius]'] = 0.0\n",
    "\n",
    "        # Save the modified dataframes\n",
    "        stars_df.to_csv(os.path.join(path, \"data\", f'stars_{i}.csv'), index=False, encoding='utf-8')\n",
    "        planets_df.to_csv(os.path.join(path, \"data\", f'planets_{i}.csv'), index=False, encoding='utf-8')\n",
    "\n",
    "random_data(directories[rubric_item], 200)\n",
    "modify_data(directories[rubric_item])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dfde3bc4",
   "metadata": {},
   "source": [
    "# BEGIN q19: incorrect logic is used to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "0d907e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "rubric_item = \"q19: incorrect logic is used to answer\"\n",
    "nb = new_clean_nb(read_nb(os.path.join(DIRECTORY, FILE)))\n",
    "nb = truncate_nb(nb, end=find_all_cell_indices(nb, \"code\", \"grader.check('q19')\")[-1])\n",
    "\n",
    "results[rubric_item] = parse_nb(run_nb(nb, os.path.join(directories[rubric_item], FILE)))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "419eca10",
   "metadata": {},
   "source": [
    "# END q19: incorrect logic is used to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "fe8d0cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"update public_tests\"\"\"\n",
    "\n",
    "gen_public_tests.gen_public_tests(os.path.join(directories[rubric_item], FILE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb6f76b",
   "metadata": {},
   "source": [
    "### q19: `planets_list` and `stars_dict` data structures are not used to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "03ebefb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"update readme\"\"\"\n",
    "\n",
    "rubric_item = \"q19: `planets_list` and `stars_dict` data structures are not used to answer\"\n",
    "readme_text = \"\"\"You need to access the `Planet` objects in the \n",
    "`planets_list` list and `Star` objects in the\n",
    "`stars_dict` dictionary. These data structures \n",
    "already contain all the data about the planets\n",
    "and stars in  the dataset. Make sure to use the \n",
    "data from the `planets_list` list and `stars_dict`\n",
    "dictionary to answer the question. A modified \n",
    "version of the list and dictionary are provided \n",
    "right before the answer to this question.\n",
    "If your answer does not use these modified data\n",
    "structures, you may not have used the data\n",
    "correctly.\"\"\" \n",
    "\n",
    "write_readme(readme_text, os.path.join(directories[rubric_item], \"README.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "d3625a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_data(directories[rubric_item], 50)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3c0174c4",
   "metadata": {},
   "source": [
    "# BEGIN q19: `planets_list` and `stars_dict` data structures are not used to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "7380865c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "rubric_item = \"q19: `planets_list` and `stars_dict` data structures are not used to answer\"\n",
    "nb = new_clean_nb(read_nb(os.path.join(DIRECTORY, FILE)))\n",
    "nb = truncate_nb(nb, end=find_all_cell_indices(nb, \"code\", \"grader.check('q19')\")[-1])\n",
    "\n",
    "randomized_stars_dict = true_data_structures[\"stars_dict\"] + '''\n",
    "import random\n",
    "\n",
    "random.seed(0)\n",
    "stars_dict_keys = list(stars_dict.keys())\n",
    "stars_dict_values = list(stars_dict.values())\n",
    "random.shuffle(stars_dict_keys)\n",
    "random.shuffle(stars_dict_values)\n",
    "\n",
    "stars_dict = {}\n",
    "for i in range(len(stars_dict_keys)):\n",
    "    stars_dict[stars_dict_keys[i]] = stars_dict_values[i]\n",
    "'''\n",
    "nb = replace_with_false_data_structure(nb, 'stars_dict', randomized_stars_dict)\n",
    "\n",
    "randomized_planets_list = true_data_structures[\"planets_list\"] + '''\n",
    "import random\n",
    "\n",
    "random.seed(0)\n",
    "raw_planets = [list(planet) for planet in planets_list]\n",
    "rows_in_cols = {}\n",
    "for i in range(len(raw_planets[0])):\n",
    "    rows_in_cols[i] = []\n",
    "    for j in range(len(raw_planets)):\n",
    "        rows_in_cols[i].append(raw_planets[j][i])\n",
    "    random.shuffle(rows_in_cols[i])\n",
    "\n",
    "for j in range(len(raw_planets)):\n",
    "    for i in range(len(raw_planets[0])):\n",
    "        raw_planets[j][i] = rows_in_cols[i][j]\n",
    "planets_list = [Planet(*planet) for planet in raw_planets]\n",
    "for idx in range(len(planets_list)):\n",
    "    star = stars_dict.get(planets_list[idx].host_name)\n",
    "    if star != None and star.stellar_radius != None and star.stellar_radius > 10:\n",
    "        planets_list[idx] = planets_list[idx]._replace(planet_radius=100.0)\n",
    "'''\n",
    "nb = replace_with_false_data_structure(nb, 'planets_list', randomized_planets_list)\n",
    "\n",
    "results[rubric_item] = parse_nb(run_nb(nb, os.path.join(directories[rubric_item], FILE)))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d8144243",
   "metadata": {},
   "source": [
    "# END q19: `planets_list` and `stars_dict` data structures are not used to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "07039b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"update public_tests\"\"\"\n",
    "\n",
    "gen_public_tests.gen_public_tests(os.path.join(directories[rubric_item], FILE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2180b067",
   "metadata": {},
   "source": [
    "### q20: answer does not include all Planets that orbit the Star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "feac9895",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"update readme\"\"\"\n",
    "\n",
    "rubric_item = \"q20: answer does not include all Planets that orbit the Star\"\n",
    "readme_text = \"\"\"Your output should be a list of\n",
    "planet objects that orbit the youngest star.\n",
    "There may be logical errors in your code \n",
    "that prevent you from finding all the planets\n",
    "that orbit the youngest star, so make sure\n",
    "you account for all possibilities when checking\n",
    "for the planets that orbit the youngest star.\"\"\" \n",
    "\n",
    "write_readme(readme_text, os.path.join(directories[rubric_item], \"README.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "0148a201",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_data(path):\n",
    "    min_idx = random.randint(3, 4)\n",
    "    for i in range(1, 5):\n",
    "    # Read in the original dataset\n",
    "        stars_df = pd.read_csv(os.path.join(path, \"data\", 'stars_%d.csv' % (i)), encoding='utf-8')\n",
    "\n",
    "        # Modify one row to have unique minimum value in Stellar Age column\n",
    "        min_age_idx = stars_df['Stellar Age [Gyr]'].idxmin()\n",
    "        min_age_star = stars_df.loc[min_age_idx]['Star Name']\n",
    "        \n",
    "        stars_df['Stellar Age [Gyr]'] = round(np.random.uniform(1.0, 15.0), 1)\n",
    "        \n",
    "        if i == min_idx:\n",
    "            stars_df.loc[min_age_idx, 'Stellar Age [Gyr]'] = 0.2\n",
    "\n",
    "            # Update other planets to have the youngest star as their host\n",
    "            mapping_file = os.path.join(path, \"data\", 'mapping_%d.json' % (i))\n",
    "            with open(mapping_file, 'r', encoding='utf-8') as f:\n",
    "                mapping_data = json.load(f)\n",
    "            updated_mapping_data = {}\n",
    "            for planet, star in mapping_data.items():\n",
    "                if random.randint(1, len(stars_df)) <= 5:\n",
    "                    updated_mapping_data[planet] = min_age_star\n",
    "                else:\n",
    "                    updated_mapping_data[planet] = star\n",
    "                    \n",
    "            # Update the mapping file with modified values\n",
    "            with open(mapping_file, 'w', encoding='utf-8') as f:\n",
    "                json.dump(updated_mapping_data, f)\n",
    "\n",
    "        stars_df.to_csv(os.path.join(path,  \"data\", 'stars_%d.csv' % (i)), index=False, encoding='utf-8')\n",
    "        \n",
    "random_data(directories[rubric_item], 200)\n",
    "modify_data(directories[rubric_item])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "52c75e4a",
   "metadata": {},
   "source": [
    "# BEGIN q20: answer does not include all Planets that orbit the Star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "7848f706",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "rubric_item = \"q20: answer does not include all Planets that orbit the Star\"\n",
    "nb = new_clean_nb(read_nb(os.path.join(DIRECTORY, FILE)))\n",
    "nb = truncate_nb(nb, end=find_all_cell_indices(nb, \"code\", \"grader.check('q20')\")[-1])\n",
    "\n",
    "results[rubric_item] = parse_nb(run_nb(nb, os.path.join(directories[rubric_item], FILE)))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f35eb4d9",
   "metadata": {},
   "source": [
    "# END q20: answer does not include all Planets that orbit the Star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "deb848f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"update public_tests\"\"\"\n",
    "\n",
    "gen_public_tests.gen_public_tests(os.path.join(directories[rubric_item], FILE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b71eff",
   "metadata": {},
   "source": [
    "### q20: incorrect logic is used to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "dc60800d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"update readme\"\"\"\n",
    "\n",
    "rubric_item = \"q20: incorrect logic is used to answer\"\n",
    "readme_text = \"\"\"The test is checking if your code can correctly\n",
    "find the youngest star and the planets that orbit\n",
    "it. The test modifies the dataset to have completely\n",
    "different stars and planets, so if your code fails\n",
    "to find the youngest star and its orbiting\n",
    "planets, it suggests that there is a logical error\n",
    "in your code. Make sure to review your logic and\n",
    "consider edge cases.\"\"\" \n",
    "\n",
    "write_readme(readme_text, os.path.join(directories[rubric_item], \"README.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "385e52f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_data(path):\n",
    "    min_idx = 1\n",
    "    for i in range(1, 5):\n",
    "        # Read in the original dataset\n",
    "        stars_df = pd.read_csv(os.path.join(path, \"data\", 'stars_%d.csv' % (i)), encoding='utf-8')\n",
    "\n",
    "        # Modify one row to have unique minimum value in Stellar Age column\n",
    "        min_age_idx = stars_df['Stellar Age [Gyr]'].idxmin()\n",
    "        min_age_star = stars_df.iloc[min_age_idx]['Star Name']\n",
    "        \n",
    "        stars_df['Stellar Age [Gyr]'] = round(np.random.uniform(20.0, 55.0), 1)\n",
    "        \n",
    "        if i == min_idx:\n",
    "            stars_df.loc[min_age_idx, 'Stellar Age [Gyr]'] = 0.0\n",
    "\n",
    "        stars_df.to_csv(os.path.join(path, \"data\", 'stars_%d.csv' % (i)), index=False, encoding='utf-8')\n",
    "        \n",
    "random_data(directories[rubric_item], 200)\n",
    "modify_data(directories[rubric_item])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e5839cc0",
   "metadata": {},
   "source": [
    "# BEGIN q20: incorrect logic is used to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "110bc85d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "rubric_item = \"q20: incorrect logic is used to answer\"\n",
    "nb = new_clean_nb(read_nb(os.path.join(DIRECTORY, FILE)))\n",
    "nb = truncate_nb(nb, end=find_all_cell_indices(nb, \"code\", \"grader.check('q20')\")[-1])\n",
    "\n",
    "results[rubric_item] = parse_nb(run_nb(nb, os.path.join(directories[rubric_item], FILE)))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c444d489",
   "metadata": {},
   "source": [
    "# END q20: incorrect logic is used to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "793c9ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"update public_tests\"\"\"\n",
    "\n",
    "gen_public_tests.gen_public_tests(os.path.join(directories[rubric_item], FILE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd35fd07",
   "metadata": {},
   "source": [
    "### q20: `planets_list` and `stars_dict` data structures are not used to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "123a62fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"update readme\"\"\"\n",
    "\n",
    "rubric_item = \"q20: `planets_list` and `stars_dict` data structures are not used to answer\"\n",
    "readme_text = \"\"\"You need to access the `Planet` objects in the \n",
    "`planets_list` list and `Star` objects in the\n",
    "`stars_dict` dictionary. These data structures \n",
    "already contain all the data about the planets\n",
    "and stars in  the dataset. Make sure to use the \n",
    "data from the `planets_list` list and `stars_dict`\n",
    "dictionary to answer the question. A modified \n",
    "version of the list and dictionary are provided \n",
    "right before the answer to this question.\n",
    "If your answer does not use these modified data\n",
    "structures, you may not have used the data\n",
    "correctly.\"\"\" \n",
    "\n",
    "write_readme(readme_text, os.path.join(directories[rubric_item], \"README.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "6eb53eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_data(directories[rubric_item], 50)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "04a1cb7f",
   "metadata": {},
   "source": [
    "# BEGIN q20: `planets_list` and `stars_dict` data structures are not used to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "7c7b0fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "rubric_item = \"q20: `planets_list` and `stars_dict` data structures are not used to answer\"\n",
    "nb = new_clean_nb(read_nb(os.path.join(DIRECTORY, FILE)))\n",
    "nb = truncate_nb(nb, end=find_all_cell_indices(nb, \"code\", \"grader.check('q20')\")[-1])\n",
    "\n",
    "randomized_stars_dict = true_data_structures[\"stars_dict\"] + '''\n",
    "import random\n",
    "\n",
    "random.seed(0)\n",
    "stars_dict_keys = list(stars_dict.keys())\n",
    "stars_dict_values = list(stars_dict.values())\n",
    "random.shuffle(stars_dict_keys)\n",
    "random.shuffle(stars_dict_values)\n",
    "\n",
    "stars_dict = {}\n",
    "for i in range(len(stars_dict_keys)):\n",
    "    stars_dict_values[i] = stars_dict_values[i]._replace(stellar_age=round(random.uniform(0.5, 15.0), 1))\n",
    "    stars_dict[stars_dict_keys[i]] = stars_dict_values[i]\n",
    "\n",
    "random_key = random.choice(stars_dict_keys)\n",
    "stars_dict[random_key] = stars_dict[random_key]._replace(stellar_age=0.1)\n",
    "'''\n",
    "nb = replace_with_false_data_structure(nb, 'stars_dict', randomized_stars_dict)\n",
    "\n",
    "randomized_planets_list = true_data_structures[\"planets_list\"] + '''\n",
    "import random\n",
    "\n",
    "random.seed(0)\n",
    "raw_planets = [list(planet) for planet in planets_list]\n",
    "rows_in_cols = {}\n",
    "for i in range(len(raw_planets[0])):\n",
    "    rows_in_cols[i] = []\n",
    "    for j in range(len(raw_planets)):\n",
    "        rows_in_cols[i].append(raw_planets[j][i])\n",
    "    random.shuffle(rows_in_cols[i])\n",
    "\n",
    "for j in range(len(raw_planets)):\n",
    "    for i in range(len(raw_planets[0])):\n",
    "        raw_planets[j][i] = rows_in_cols[i][j]\n",
    "planets_list = [Planet(*planet) for planet in raw_planets]\n",
    "'''\n",
    "nb = replace_with_false_data_structure(nb, 'planets_list', randomized_planets_list)\n",
    "\n",
    "results[rubric_item] = parse_nb(run_nb(nb, os.path.join(directories[rubric_item], FILE)))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "81b233cf",
   "metadata": {},
   "source": [
    "# END q20: `planets_list` and `stars_dict` data structures are not used to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "d8dbf55f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"update public_tests\"\"\"\n",
    "\n",
    "gen_public_tests.gen_public_tests(os.path.join(directories[rubric_item], FILE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9e92b7",
   "metadata": {},
   "source": [
    "### general_deductions: Outputs not visible/did not save the notebook file prior to running the cell containing \"export\". We cannot see your output if you do not save before generating the zip file."
   ]
  },
  {
   "cell_type": "raw",
   "id": "00d2754f",
   "metadata": {},
   "source": [
    "# BEGIN general_deductions: Outputs not visible/did not save the notebook file prior to running the cell containing \"export\". We cannot see your output if you do not save before generating the zip file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "20531c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rubric_item = \"general_deductions: Outputs not visible/did not save the notebook file prior to running the cell containing \\\"export\\\". We cannot see your output if you do not save before generating the zip file.\"\n",
    "nb = clean_nb(read_nb(os.path.join(DIRECTORY, FILE)))\n",
    "nb = truncate_nb(nb, end=find_all_cell_indices(nb, \"code\", \"grader.check('general_deductions')\")[-1])\n",
    "\n",
    "results[rubric_item] = {}\n",
    "results[rubric_item]['general_deductions'] = rubric_item.split(\":\")[1].strip()\n",
    "if detect_restart_and_run_all(nb):\n",
    "    results[rubric_item]['general_deductions'] = \"All test cases passed!\""
   ]
  },
  {
   "cell_type": "raw",
   "id": "0903111c",
   "metadata": {},
   "source": [
    "# END general_deductions: Outputs not visible/did not save the notebook file prior to running the cell containing \"export\". We cannot see your output if you do not save before generating the zip file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d552e5c",
   "metadata": {},
   "source": [
    "### general_deductions: Used concepts/modules such as csv.DictReader and pandas not covered in class yet. Note that built-in functions that you have been introduced to can be used."
   ]
  },
  {
   "cell_type": "raw",
   "id": "2a4da4c3",
   "metadata": {},
   "source": [
    "# BEGIN general_deductions: Used concepts/modules such as csv.DictReader and pandas not covered in class yet. Note that built-in functions that you have been introduced to can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "d231f23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rubric_item = \"general_deductions: Used concepts/modules such as csv.DictReader and pandas not covered in class yet. Note that built-in functions that you have been introduced to can be used.\"\n",
    "nb = clean_nb(read_nb(os.path.join(DIRECTORY, FILE)))\n",
    "nb = truncate_nb(nb, end=find_all_cell_indices(nb, \"code\", \"grader.check('general_deductions')\")[-1])\n",
    "\n",
    "function_calls = []\n",
    "for cell in nb['cells']:\n",
    "    if cell['cell_type'] != \"code\":\n",
    "        continue\n",
    "    for node in ast.walk(ast.parse(cell['source'])):\n",
    "        if isinstance(node, ast.Call):\n",
    "            function_calls.append(ast.unparse(node.func))\n",
    "            \n",
    "bad_function_calls = False\n",
    "for bad_function in function_calls:\n",
    "    if 'DictReader' in bad_function or 'pandas' in bad_function or 'matplotlib' in bad_function:\n",
    "        bad_function_calls = True\n",
    "        break\n",
    "\n",
    "results[rubric_item] = {}\n",
    "found_imports = set(detect_imports(nb)) - {\"otter\", \"public_tests\", \"copy\", \"csv\", \"json\", \"json.JSONDecodeError\", \"os\", \"collections.namedtuple\"}\n",
    "if found_imports  == set():\n",
    "    if bad_function_calls == False:\n",
    "        results[rubric_item]['general_deductions'] = \"All test cases passed!\"\n",
    "    else:\n",
    "        results[rubric_item]['general_deductions'] = \"found unexpected function call:\\n\" + repr(bad_function)\n",
    "        comments[rubric_item] = results[rubric_item]['general_deductions']\n",
    "else:\n",
    "    results[rubric_item]['general_deductions'] = \"found unexpected import(s):\" + repr(list(found_imports))\n",
    "    comments[rubric_item] = results[rubric_item]['general_deductions']"
   ]
  },
  {
   "cell_type": "raw",
   "id": "33aba559",
   "metadata": {},
   "source": [
    "# END general_deductions: Used concepts/modules such as csv.DictReader and pandas not covered in class yet. Note that built-in functions that you have been introduced to can be used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd1264e",
   "metadata": {},
   "source": [
    "### general_deductions: Used bare try/except blocks without explicitly specifying the type of exceptions that need to be caught"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8ff73e16",
   "metadata": {},
   "source": [
    "# BEGIN general_deductions: Used bare try/except blocks without explicitly specifying the type of exceptions that need to be caught"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "97a09eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "rubric_item = \"general_deductions: Used bare try/except blocks without explicitly specifying the type of exceptions that need to be caught\"\n",
    "nb = read_nb(os.path.join(DIRECTORY, FILE))\n",
    "nb = truncate_nb(nb, end=find_all_cell_indices(nb, \"markdown\", \"## Submission\")[-1])\n",
    "\n",
    "results[rubric_item] = {}\n",
    "results[rubric_item]['general_deductions'] = rubric_item.split(\":\")[1].strip()\n",
    "bare_excepts = detect_bare_excepts(nb)\n",
    "if bare_excepts == []:\n",
    "    results[rubric_item]['general_deductions'] = \"All test cases passed!\"\n",
    "else:\n",
    "    comments[rubric_item] = 'bare try/except blocks detected at: ' + repr(bare_excepts)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b441292d",
   "metadata": {},
   "source": [
    "# END general_deductions: Used bare try/except blocks without explicitly specifying the type of exceptions that need to be caught"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720efd7e",
   "metadata": {},
   "source": [
    "### general_deductions: Large outputs such as stars_dict or planets_list are displayed in the notebook."
   ]
  },
  {
   "cell_type": "raw",
   "id": "492ff525",
   "metadata": {},
   "source": [
    "# BEGIN general_deductions: Large outputs such as stars_dict or planets_list are displayed in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "941b7903",
   "metadata": {},
   "outputs": [],
   "source": [
    "rubric_item = \"general_deductions: Large outputs such as stars_dict or planets_list are displayed in the notebook.\"\n",
    "nb = clean_nb(read_nb(os.path.join(DIRECTORY, FILE)))\n",
    "nb = truncate_nb(nb, end=find_all_cell_indices(nb, \"code\", \"grader.check('general_deductions')\")[-1])\n",
    "\n",
    "results[rubric_item] = {}\n",
    "results[rubric_item]['general_deductions'] = 'All test cases passed!'\n",
    "\n",
    "for cell in nb['cells']:\n",
    "    if cell['cell_type'] != \"code\":\n",
    "        continue\n",
    "    output = \"\"\n",
    "    if 'outputs' not in cell:\n",
    "        continue\n",
    "    for output_cell in cell['outputs']:\n",
    "        if 'text' in output_cell:\n",
    "            output += output_cell[\"text\"]+\"\\n\"\n",
    "        elif 'data' in output_cell and 'text/plain' in output_cell['data']:\n",
    "            output += output_cell[\"data\"][\"text/plain\"] + \"\\n\"\n",
    "    if len(output) > 10**6:\n",
    "        results[rubric_item]['general_deductions'] = \"large outputs detected in notebook\"\n",
    "        break"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7cc9dc55",
   "metadata": {},
   "source": [
    "# END general_deductions: Large outputs such as stars_dict or planets_list are displayed in the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f5dede",
   "metadata": {},
   "source": [
    "### general_deductions: Import statements are not mentioned in the required cell at the top of the notebook."
   ]
  },
  {
   "cell_type": "raw",
   "id": "d63811b3",
   "metadata": {},
   "source": [
    "# BEGIN general_deductions: Import statements are not mentioned in the required cell at the top of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "61d920ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "rubric_item = \"general_deductions: Import statements are not mentioned in the required cell at the top of the notebook.\"\n",
    "nb = clean_nb(read_nb(os.path.join(DIRECTORY, FILE)))\n",
    "nb = truncate_nb(nb, start=find_all_cell_indices(nb, \"markdown\", \"### File handling:\")[0]+1, end=find_all_cell_indices(nb, \"code\", \"grader.check('general_deductions')\")[-1])\n",
    "\n",
    "results[rubric_item] = {}\n",
    "results[rubric_item]['general_deductions'] = 'All test cases passed!'\n",
    "\n",
    "found_imports = detect_imports(nb)\n",
    "if found_imports != []:\n",
    "    results[rubric_item]['general_deductions'] = \"found unexpected import(s):\" + repr(found_imports)\n",
    "    comments[rubric_item] = results[rubric_item]['general_deductions']"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5091398a",
   "metadata": {},
   "source": [
    "# END general_deductions: Import statements are not mentioned in the required cell at the top of the notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
